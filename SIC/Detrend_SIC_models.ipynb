{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a1c92aa",
   "metadata": {},
   "source": [
    "# Detrend Model SIC by its ensemble mean and individual member trends\n",
    "\n",
    "### Author: Chris Wyburn-Powell, [github](https://github.com/chrisrwp/blob/main/synthetic-ensemble/SIC/Detrend_SIC_models.ipynb)\n",
    "\n",
    "**Input**: <br>\n",
    "- CLIVAR LE Archive model output from CanESM2, CESM1, CSIRO MK3.6, GDL CM3, GFDL ESM2M, MPI ESM1\n",
    "\n",
    "**Output**: <br>\n",
    "- Reduced datasets for all members of the same model for a given month\n",
    "- Detrended data based on:\n",
    "  * Ensemble mean, i.e. the linear trend of the mean of all members\n",
    "  * Ensemble mean with adjustments so the ensemble mean trend does not reach below 0% or above 100% SIC\n",
    "  * Individual mean, i.e. the linear trend of the member which is being detrended \n",
    "  * Individual mean with adjustments to within 0-100% SIC\n",
    "  * 2 year lowpass Butterworth filter, without adjustment to physical values\n",
    "<br>\n",
    "  \n",
    "**Method**: <br>\n",
    "- Use `dask` to loop through all the model output data and reconstitute it for >30N and 1979-2020, this time by month rather than by member\n",
    "- Use a linear trend as calculated by `xarray.DataArray.polyfit` or a Butterworth filter calculated by `scipy.signal.butter` to detrend the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31e1de2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:57 UTC Wed 2021-08-04\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import scipy.signal as sig\n",
    "import datetime\n",
    "import dask\n",
    "\n",
    "print(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11ddcfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/glade/scratch/cwpowell/Synthetic_ensemble/'\n",
    "\n",
    "model_names  = ['CanESM2', 'CESM1', 'CSIRO_MK36', 'GFDL_CM3', 'GFDL_ESM2M', 'MPI_ESM1']\n",
    "mem_len      = [50,        40,      30,           20,         30,           100       ]\n",
    "\n",
    "month_names = ['January', 'February', 'March', 'April', 'May', 'June', 'July', \n",
    "               'August', 'September', 'October', 'November', 'December']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8d6cc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dask workers\n",
    "from dask_jobqueue import PBSCluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "cluster = PBSCluster(cores    = 2,\n",
    "                     memory   = '5GB',\n",
    "                     queue    = 'economy',\n",
    "                     walltime = '00:20:00')\n",
    "\n",
    "cluster.scale(8)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ae567d",
   "metadata": {},
   "source": [
    "# Compute a reduced dataset for 1979-2020 for >30N for all members\n",
    "## Define a function to load the correct model output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8a9756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_member(model, i, sic_sit, chunk_size=False, historical=False):\n",
    "    '''\n",
    "    Open a single member file of either sea ice concentration or thickness \n",
    "    from the CLIVAR LE archive using xarray.open_dataset\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : string,\n",
    "        Choose from ['CanESM2', 'CESM1', 'GFDL_CM3', GFDL_ESM2M', 'CSIRO_MK36', \n",
    "                     'MPI_ESM1']\n",
    "    i : integer,\n",
    "        Member number e.g. 1\n",
    "    sic_sit : string,\n",
    "        Variable concentration or thickness, choose from ['sic', 'sit']\n",
    "    chunk_size : integer, optional\n",
    "        Choose an int e.g. 50 to use dask chunks to open the data, defaults\n",
    "        to not use dask\n",
    "    historical : boolean\n",
    "        Only use for MPI_ESM1 to specify the time period required, defaults \n",
    "        to RCP85 time period\n",
    "    decode_bool : boolean\n",
    "        Only use for GFDL_CM3 SIT member 1\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "        xarray.DataSet object from the CLIVAR LE archive sea ice output\n",
    "    '''  \n",
    "    \n",
    "    base_path = '/glade/collections/cdg/data/CLIVAR_LE/'\n",
    "    \n",
    "    assert sic_sit in ['sic', 'sit'], 'invalid variable name'\n",
    "    \n",
    "    if np.logical_or(model=='GFDL_ESM2M', \n",
    "                     np.logical_and(model=='GFDL_CM3', sic_sit=='sit')):\n",
    "        decode_bool = False #time is not recognized by xarray so do not decode\n",
    "    else:\n",
    "        decode_bool = True\n",
    "        \n",
    "    \n",
    "    ############### generate the file path ###############\n",
    "    if model == 'CanESM2':\n",
    "        path = base_path+'canesm2_lens/OImon/{}/{}_OImon_CanESM2_historical_'\\\n",
    "            +'rcp85_r{}i1p1_195001-210012.nc'.format(sic_sit, sic_sit, i)\n",
    "        \n",
    "    elif model == 'CESM1':\n",
    "        if i == 1:\n",
    "            path = base_path+'cesm_lens/OImon/{}/{}_OImon_CESM1-CAM5_historica'\\\n",
    "                +'l_rcp85_r1i1p1_185001-210012.nc'.format(sic_sit, sic_sit, i)\n",
    "        else:\n",
    "            path = base_path+'cesm_lens/OImon/{}/{}_OImon_CESM1-CAM5_historica'\\\n",
    "                +'l_rcp85_r{}i1p1_192001-210012.nc'.format(sic_sit, sic_sit, i)\n",
    "            \n",
    "    elif model == 'GFDL_ESM2M':\n",
    "        path = base_path+'gfdl_esm2m_lens/OImon/{}/{}_OImon_GFDL-ESM2M_histori'\\\n",
    "            +'cal_rcp85_r{}i1p1_195001-210012.nc'.format(sic_sit, sic_sit, i)\n",
    "    \n",
    "    elif model == 'GFDL_CM3':\n",
    "        path = base_path+'gfdl_cm3_lens/OImon/{}/{}_OImon_GFDL-CM3_historical_'\\\n",
    "            +'rcp85_r{}i1p1_192001-210012.nc'.format(sic_sit, sic_sit, i)\n",
    "        \n",
    "    elif model == 'CSIRO_MK36':\n",
    "        path = base_path+'csiro_mk36_lens/OImon/{}/{}_OImon_CSIRO-Mk3-6-0_hist'\\\n",
    "            +'orical_rcp85_r{}i1p1_185001-210012.nc'.format(sic_sit, sic_sit, i)\n",
    "        \n",
    "    elif model == 'MPI_ESM1':\n",
    "        period = [['historical', 'rcp85'], \n",
    "                  ['1850p3_185001-200512', '2005p3_200601-209912']]\n",
    "        \n",
    "        if historical: #2005-12 or previous\n",
    "            path = base_path+'mpi_lens/OImon/{}/{}_OImon_MPI-ESM_{}_r{}i{}'\\\n",
    "                +'.nc'.format(sic_sit, sic_sit, str(period[0][0]), \n",
    "                              str(i).zfill(3), str(period[1][0]))\n",
    "        else:\n",
    "            path = base_path+'mpi_lens/OImon/{}/{}_OImon_MPI-ESM_{}_r{}i{}'\\\n",
    "                +'.nc'.format(sic_sit, sic_sit, str(period[0][1]), \n",
    "                              str(i).zfill(3), str(period[1][1]))\n",
    "    else:\n",
    "        print('invalid model name')\n",
    "       \n",
    "    ########## use the file path to open the NetCDF file using xarray ##########\n",
    "    if chunk_size:\n",
    "        data = xr.open_dataset(path, chunks={'time':(chunk_size)},\n",
    "                               decode_times=decode_bool)\n",
    "    else:\n",
    "        data = xr.open_dataset(path, decode_times=decode_bool)\n",
    "            \n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3a3552",
   "metadata": {},
   "source": [
    "## Define a function to make reduced datasets with each month being separate but for all members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9475d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_data(model_name, mem_len_, month_, start_yr, end_yr, chunk_size):\n",
    "    '''\n",
    "    Open a single member file of either sea ice concentration or thickness from \n",
    "    the CLIVAR LE archive using xarray.open_dataset\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model_name : string,\n",
    "        Choose from ['CanESM2', 'CESM1', 'GFDL_CM3', GFDL_ESM2M', 'CSIRO_MK36',\n",
    "        'MPI_ESM1']\n",
    "    mem_len_ : integer,\n",
    "        Number of members e.g. 50\n",
    "    month_ : integer,\n",
    "        Number corresponding to the month e.g. 1 is January\n",
    "    start_yr : integer\n",
    "        Calendar year of the start of required time period e.g. 1950\n",
    "    end_yr : integer\n",
    "        Calendar year of the end of required time period (inclusive) e.g. 2020\n",
    "    chunk_size : integer, optional\n",
    "        Choose an int e.g. 100 to use dask chunks to open the data, defaults to \n",
    "        not use dask\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "        xarray.DataSet object of combined data for NH (>30N) for years \n",
    "        specificed for a specific month\n",
    "    '''  \n",
    "    \n",
    "    #define chatachteristics\n",
    "    if model_name in ['CESM1', 'MPI_ESM1']:\n",
    "        lat_lon = ['j', 'i']\n",
    "    elif  model_name == 'GFDL_CM3':\n",
    "        lat_lon = ['rlat', 'rlon']\n",
    "    else:\n",
    "        lat_lon = ['lat', 'lon']\n",
    "            \n",
    "    ############################################################################\n",
    "    for member_i in np.arange(1,mem_len_+1):\n",
    "\n",
    "        #open member dataset using dask and xarray\n",
    "        #need to combine historical (pre 2005-12) and RCP8.5 to 2020-12 for MPI\n",
    "        if model_name == 'MPI_ESM1':\n",
    "            member_hist = load_member(model_name, member_i, 'sic', chunk_size, \n",
    "                                      historical=True)\n",
    "            member_fut  = load_member(model_name, member_i, 'sic', chunk_size)\n",
    "            member = xr.concat((member_hist, member_fut), dim='time')\n",
    "\n",
    "        else:\n",
    "            member = load_member(model_name, member_i, 'sic', chunk_size)\n",
    "\n",
    "        #change CESM1 dates from following month to mid-month as per CSIRO_MK36\n",
    "        #GFDL_ESM2M needs to be changed as xarray cannot decode these dates\n",
    "        if model_name in ['CESM1', 'GFDL_ESM2M']:\n",
    "            time_CSIRO = load_member('CSIRO_MK36', 1, 'sic', chunk_size)\n",
    "\n",
    "            if model_name == 'CESM1':\n",
    "                if member_i == 1:\n",
    "                    member['time'] = time_CSIRO['time'] #CESM1 mem 1 starts 1850\n",
    "                else:\n",
    "                    member['time'] = time_CSIRO['time'].sel(time=slice(\n",
    "                        '1920-01','2100-12'))       \n",
    "            else:\n",
    "                member['time'] = time_CSIRO['time'].sel(time=slice(\n",
    "                    '1950-01','2100-12'))   \n",
    "        \n",
    "        #only want northern hemisphere\n",
    "        if model_name == 'GFDL_CM3':\n",
    "            member_NH = (member.where(member['rlat']>30,drop=True))['sic']\n",
    "            #correct mem 1-8 skipping 2005-12-16 to 2006-02-21 not 2006-01-16\n",
    "            #replace with time from member 9 which doesn't have the offset\n",
    "            GFDL_CM3_mem_9 = load_member('GFDL_CM3', 9, 'sic')\n",
    "            member_NH['time'] = GFDL_CM3_mem_9['time']\n",
    "        else:\n",
    "            member_NH = (member.where(member['lat']>30,drop=True))['sic']\n",
    "        \n",
    "        #select the correct years and detrend into a detrended xarray dataarray\n",
    "        member_NH_yrs = member_NH.sel(time=member_NH['time.month']==month_).sel(\n",
    "            time=slice('{}'.format(start_yr),'{}'.format(end_yr)))\n",
    "\n",
    "        #define the shape of the reduced dataset\n",
    "        if member_i == 1: all_mem = np.empty((mem_len_, member_NH_yrs.shape[0], \n",
    "                                              member_NH_yrs.shape[1], \n",
    "                                              member_NH_yrs.shape[2]))\n",
    "        \n",
    "        #add this data to the correct position in array according to its member\n",
    "        all_mem[member_i-1] = member_NH_yrs \n",
    "\n",
    "    ############################################################################\n",
    "    #convert to xarray dataarray and save to NetCDF\n",
    "    all_mem_xr = xr.DataArray(\n",
    "        data   = all_mem,\n",
    "        coords = {'member'       : np.arange(1,mem_len_+1),\n",
    "                  'time'         : member_NH_yrs['time'],\n",
    "                  str(lat_lon[0]): member_NH_yrs[lat_lon[0]],\n",
    "                  str(lat_lon[1]): member_NH_yrs[lat_lon[1]]},\n",
    "        dims   = ['member', 'time', str(lat_lon[0]), str(lat_lon[1])]\n",
    "    )\n",
    "\n",
    "    all_mem_xr.load()\n",
    "    \n",
    "    all_mem_xr.attrs = {\n",
    "        'Description': 'Reduced dataset of sea ice concentrations (SIC) for '\\\n",
    "            +'the model {}, for all ensemble members in the month of {} for '\\\n",
    "            +'the period {}-{}'.format(model_name, month_names[month_-1], \n",
    "                                       start_yr, end_yr),\n",
    "        'Units'      : '% sea ice concentration',\n",
    "        'Timestamp'  : str(datetime.datetime.utcnow().strftime(\n",
    "            \"%H:%M UTC %a %Y-%m-%d\")),                \n",
    "        'Data source': 'CLIVAR Large Ensemble Archive '\\\n",
    "            +'(doi: 10.1038/s41558-020-0731-2)',\n",
    "        'Analysis'   : 'Python 3.7.9 - https://github.com/chrisrwp/'\\\n",
    "            +'obs-ensemble/Time_period_and_sigma.ipynb'\n",
    "    }\n",
    "\n",
    "    all_mem_xr.to_netcdf(data_path+'SIC/Reduced_datasets/{}_reduced_'\\\n",
    "                         +'{}-{}_{}.nc'.format(model_name, start_yr, end_yr, \n",
    "                                               str(month_).zfill(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8354e378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the reduced datasets\n",
    "start_yr = 1979\n",
    "end_yr   = 2020\n",
    "chunk_size = 100\n",
    "\n",
    "for month_ in np.arange(1,13):\n",
    "    print(month_)\n",
    "    for model_i, model_name in enumerate(model_names):\n",
    "        print(datetime.datetime.now(), model_name)\n",
    "        dask.compute(dask.delayed(reduce_data)(model_name, mem_len[model_i], \n",
    "                                               month_, start_yr, end_yr, \n",
    "                                               chunk_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2c6acf",
   "metadata": {},
   "source": [
    "# Use the reduced datasets to detrend relative to the ensemble mean and the individual members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4328c2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use matrix operations for both ensemble and individual\n",
    "start_yr = 1979\n",
    "end_yr   = 2020\n",
    "\n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    for month_ in np.arange(1,13):\n",
    "        print(datetime.datetime.now(), month_)\n",
    "    \n",
    "        ########################################################################   \n",
    "        #define grid chatachteristics\n",
    "        if model_name in ['CESM1', 'MPI_ESM1']:\n",
    "            lat_lon = ['j', 'i']\n",
    "        elif  model_name == 'GFDL_CM3':\n",
    "            lat_lon = ['rlat', 'rlon']\n",
    "        else:\n",
    "            lat_lon = ['lat', 'lon']\n",
    "\n",
    "        #load the reduced dataset for the model and month in question\n",
    "        month_data_ = xr.open_dataarray(\n",
    "            data_path+'SIC/Reduced_datasets/{}_reduced_1979-2020_{}'\\\n",
    "            +'.nc'.format(model_name, str(month_).zfill(2)))\n",
    "\n",
    "        #change the time to whole numbers for ease of trend calculations\n",
    "        month_data = month_data_.copy()\n",
    "        month_data['time'] = np.arange(start_yr,end_yr+1)\n",
    "        \n",
    "        #GFDL ESM2M uses fraction not % for SIC, change to % for this model\n",
    "        if model_name == 'GFDL_ESM2M': month_data = month_data * 100\n",
    "        \n",
    "        ########################################################################\n",
    "        #generate a matrix of year values for computing trend with coefficients\n",
    "        yrs_ind = np.empty((len(month_data['time']), len(month_data['member']), \n",
    "                            len(month_data[lat_lon[0]]), \n",
    "                            len(month_data[lat_lon[1]])))\n",
    "        yrs_ens = np.empty((len(month_data['time']), \n",
    "                            len(month_data[lat_lon[0]]), \n",
    "                            len(month_data[lat_lon[1]])))\n",
    "\n",
    "        for yr_i, yr in enumerate(np.arange(start_yr,end_yr+1)):\n",
    "            yrs_ind[yr_i] = np.ones((len(month_data['member']), \n",
    "                                     len(month_data[lat_lon[0]]), \n",
    "                                     len(month_data[lat_lon[1]]))) * yr\n",
    "            yrs_ens[yr_i] = np.ones((len(month_data[lat_lon[0]]), \n",
    "                                     len(month_data[lat_lon[1]]))) * yr\n",
    "\n",
    "        yrs_ind = xr.DataArray(data = yrs_ind, \n",
    "                               coords = {'time':month_data['time'], \n",
    "                                         'member':month_data['member'], \n",
    "                                         lat_lon[0]:month_data[lat_lon[0]], \n",
    "                                         lat_lon[1]:month_data[lat_lon[1]]}, \n",
    "                               dims = ['time', 'member', lat_lon[0], lat_lon[1]]\n",
    "                              )  \n",
    "\n",
    "        yrs_ens = xr.DataArray(data = yrs_ens, \n",
    "                               coords = {'time':month_data['time'], \n",
    "                                         lat_lon[0]:month_data[lat_lon[0]],\n",
    "                                         lat_lon[1]:month_data[lat_lon[1]]}, \n",
    "                               dims = ['time', lat_lon[0], lat_lon[1]]\n",
    "                              )  \n",
    "\n",
    "        ########################################################################\n",
    "        #calculate the ensemble linear trend coefs trend values\n",
    "        ens_coefs = month_data.mean('member').polyfit(dim='time', deg=1, \n",
    "                                                      skipna=True)\n",
    "        ens_trend = yrs_ens * ens_coefs.sel(degree=1) + ens_coefs.sel(degree=0)\n",
    "        \n",
    "        #now member data and trends have same time coords, compute anomalies\n",
    "        detrended_ens = month_data - ens_trend\n",
    "        detrended_ens['time'] = month_data_['time'] #revert time coords\n",
    "        detrended_ens = xr.Dataset(\n",
    "            {'SIC': detrended_ens['polyfit_coefficients']})\n",
    "\n",
    "        ####### adjust the trend, only contains physical values (0-100%) #######\n",
    "        ens_trend_adj = ens_trend.where(ens_trend>=0,0) #exclude negative SIC %\n",
    "        ens_trend_adj = ens_trend_adj.where(ens_trend_adj<=100,100) #cap at 100%\n",
    "        ens_trend_adj = ens_trend_adj.where(ens_trend) #put nan values back in\n",
    "\n",
    "        detrended_ens_adj = month_data - ens_trend_adj\n",
    "        detrended_ens_adj['time'] = month_data_['time'] #revert time coordinates\n",
    "        detrended_ens_adj = xr.Dataset(\n",
    "            {'SIC': detrended_ens_adj['polyfit_coefficients']})\n",
    "\n",
    "        ########################################################################\n",
    "        #calculate the linear trend coefs and the values for each member\n",
    "        ind_coefs = month_data.polyfit(dim='time', deg=1, skipna=True)\n",
    "        ind_trend = yrs_ind * ind_coefs.sel(degree=1) + ind_coefs.sel(degree=0)\n",
    "\n",
    "        #use the month's data with new time coords to compute detrended data\n",
    "        detrended_ind = month_data - ind_trend\n",
    "        detrended_ind['time'] = month_data_['time'] #revert time coordinates\n",
    "        detrended_ind = xr.Dataset(\n",
    "            {'SIC': detrended_ind['polyfit_coefficients']})\n",
    "\n",
    "        ####### adjust the trend, only contains physical values (0-100%) #######\n",
    "        ind_trend_adj = ind_trend.where(ind_trend>=0,0) #exclude negative SIC %\n",
    "        ind_trend_adj = ind_trend_adj.where(ind_trend_adj<=100,100) #cap 100%\n",
    "        ind_trend_adj = ind_trend_adj.where(ind_trend) #put nan values back in\n",
    "\n",
    "        detrended_ind_adj = month_data - ind_trend_adj\n",
    "        detrended_ind_adj['time'] = month_data_['time'] #revert time coordinates\n",
    "        detrended_ind_adj = xr.Dataset(\n",
    "            {'SIC': detrended_ind_adj['polyfit_coefficients']})\n",
    "\n",
    "        ########################################################################\n",
    "        #save individual and ensemble detrended data to NetCDF \n",
    "        attrs_dict = {\n",
    "            'Description': 'Detrended Arctic sea ice concentrations (SIC) the '\\\n",
    "                +'model {}. Years 1979-2020, month of {}. Detrended relative '\\\n",
    "                +'to the linear trend of the ensemble mean.'.format(model_name, \n",
    "                    month_names[month_-1]), \n",
    "            'Units'      : '%',\n",
    "            'Timestamp'  : str(datetime.datetime.utcnow().strftime(\n",
    "                \"%H:%M UTC %a %Y-%m-%d\")),\n",
    "            'Data source': 'CLIVAR Large Ensemble Archive, '\\\n",
    "                +'doi:10.1038/s41558-020-0731-2',\n",
    "            'Analysis'   : 'https://github.com/chrisrwp/synthetic-ensemble/'\\\n",
    "                +'SIC/Detrend_SIC_models.ipynb'\n",
    "        }\n",
    "\n",
    "        #detrended by the ensemble mean, without adjustment to physical values\n",
    "        detrended_ens.attrs = attrs_dict\n",
    "        detrended_ens.to_netcdf(data_path+'SIC/Detrended/{}_detrended_{}_'\\\n",
    "            +'ensemble_1979_2020.nc'.format(model_name, str(month_).zfill(2)))\n",
    "\n",
    "        #detrended by the ensemble mean, adjusted to physical values\n",
    "        detrended_ens_adj_attrs = attrs_dict.copy()\n",
    "        detrended_ens_adj_attrs['Description'] = 'Detrended Arctic sea ice '\\\n",
    "            +'concentrations (SIC) the model {}. Years 1979-2020, month of {}.'\\\n",
    "            +' Detrended relative to the linear trend of the ensemble mean. '\\\n",
    "            +'The trend in each grid cell is limited to physical values of '\\\n",
    "            +'between 0 and 100% SIC'.format(model_name, month_names[month_-1])\n",
    "        detrended_ens_adj.attrs = detrended_ens_adj_attrs\n",
    "        detrended_ens_adj.to_netcdf(data_path+'SIC/Detrended/{}_detrended_adj_'\\\n",
    "            +'{}_ensemble_1979_2020.nc'.format(model_name, str(month_).zfill(2)))\n",
    "\n",
    "        #detrended by individual memner trend, no adjustment to physical values\n",
    "        detrended_ind_attrs = attrs_dict.copy()\n",
    "        detrended_ind_attrs['Description'] = 'Detrended Arctic sea ice '\\\n",
    "            +'concentrations (SIC) the model {}. Years 1979-2020, month of {}.'\\\n",
    "            +' Detrended relative to the individual ensemble member linear '\\\n",
    "            +'trend.'.format(model_name, month_names[month_-1])\n",
    "        detrended_ind.attrs = detrended_ind_attrs\n",
    "        detrended_ind.to_netcdf(data_path+'SIC/Detrended/{}_detrended_{}_'\\\n",
    "            +'individual_1979_2020.nc'.format(model_name, str(month_).zfill(2)))  \n",
    "\n",
    "        #detrended by the individual member trend, adjusted to physical values\n",
    "        detrended_ind_adj_attrs = attrs_dict.copy()\n",
    "        detrended_ind_adj_attrs['Description'] = 'Detrended Arctic sea ice '\\\n",
    "            +'concentrations (SIC) the model {}. Years 1979-2020, month of {}.'\\\n",
    "            +' Detrended relative to the individual ensemble member linear '\\\n",
    "            +'trend. The trend in each grid cell is limited to physical values'\\\n",
    "            + 'of between 0 and 100% SIC'.format(model_name, \n",
    "                                                 month_names[month_-1])\n",
    "        detrended_ind_adj.attrs = detrended_ind_adj_attrs\n",
    "        detrended_ind_adj.to_netcdf(data_path+'SIC/Detrended/{}_detrended_adj'\\\n",
    "            +'_{}_individual_1979_2020.nc'.format(model_name, \n",
    "                                                  str(month_).zfill(2)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f481aa",
   "metadata": {},
   "source": [
    "# Compute $\\sigma_{LE}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "913bbb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_names:\n",
    "    print(datetime.datetime.now(), model_name)\n",
    "    sigma_LE_model = {}\n",
    "    for adj in ['', 'adj_']:\n",
    "        for ind_ens in ['ensemble', 'individual']:\n",
    "            sigma_LE_model_type = []\n",
    "            for month_ in np.arange(1,13):\n",
    "                month_detrended = xr.open_dataset(\n",
    "                    data_path+'SIC/Detrended/{}_detrended_{}{}_{}_1979_2020.n'\\\n",
    "                    +'c'.format(model_name, adj, str(month_).zfill(2), ind_ens))\n",
    "                sigma_LE_model_type.append(month_detrended['SIC'].std(\n",
    "                    'time').std('member'))\n",
    "                \n",
    "            sigma_LE_model_type = xr.concat((sigma_LE_model_type), dim='month') \n",
    "            sigma_LE_model_type['month'] = np.arange(1,13)\n",
    "            \n",
    "            sigma_LE_model[adj+ind_ens] = sigma_LE_model_type\n",
    "    \n",
    "    sigma_LE_model = xr.Dataset(sigma_LE_model)\n",
    "    sigma_LE_model.attrs = {\n",
    "        'Description': 'Standard deviation between ensemble members for '\\\n",
    "            +'detrended sea ice concentration (SIC). Detrended 1979-2020 '\\\n",
    "            +'relative to the ensemble or individual members, with adj '\\\n",
    "            +'meaning unphysical values of the detrended data are correct to '\\\n",
    "            +'physical bounds', \n",
    "        'Units'      : '%',\n",
    "        'Timestamp'  : str(datetime.datetime.utcnow().strftime(\n",
    "            \"%H:%M UTC %a %Y-%m-%d\")),\n",
    "        'Data source': 'CLIVAR Large Ensemble Archive '\\\n",
    "            +'(doi: 10.1038/s41558-020-0731-2)',\n",
    "        'Analysis'   : 'https://github.com/chrisrwp/synthetic-ensemble/SIC/'\\\n",
    "            +'Detrend_SIC_models.ipynb'}\n",
    "    \n",
    "    sigma_LE_model.to_netcdf(\n",
    "        data_path+'SIC/Detrended/Sigma_LE_{}.nc'.format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ef6d07-12e1-4958-90e1-3b42720b28dd",
   "metadata": {},
   "source": [
    "# Detrend relative to a 2 year lowpass Butterworth filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0704788-b5c6-4a68-8c04-3fe302c45a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data_path = '/glade/campaign/univ/ucub0084/Synthetic_ensemble/SIC/'\\\n",
    "                    +'Reduced_datasets/'\n",
    "\n",
    "for model_i, model_name in enumerate(model_names):\n",
    "    print(datetime.datetime.now(), model_name)\n",
    "    \n",
    "    for month_ in np.arange(1,13):\n",
    "        print(datetime.datetime.now(), month_)\n",
    "\n",
    "        ########################################################################\n",
    "        #load the reduced datasets, each month and model for 30N+ and 1979-2020\n",
    "        month_data = xr.open_dataarray(\n",
    "            reduced_data_path+'{}_reduced_1979-2020'\\\n",
    "            +'_{}.nc'.format(model_name, str(month_).zfill(2)))\n",
    "\n",
    "        print(np.shape(month_data)) #confirm that 42 (time) is first dimension\n",
    "\n",
    "        #GFDL ESM2M uses fraction not percentage for SIC, change to %\n",
    "        if model_name == 'GFDL_ESM2M': month_data = month_data * 100\n",
    "\n",
    "        ########################################################################            \n",
    "        #set up the Butterworth filter. cutoff freq = 0.25 the Nyquist frequency\n",
    "        #cutoff = 0.25*0.5*samp freq = 2 years. Order = 5th\n",
    "        b, a = signal.butter(5, 0.25, btype='lowpass') \n",
    "\n",
    "        #compute anomalies relative to 2 year filter (filtfilt = forward/back)\n",
    "        #apply to axis=1 which is the time dimension\n",
    "        detrended_filt = month_data - signal.filtfilt(b, a, month_data, axis=1) \n",
    "\n",
    "        ########################################################################\n",
    "        #save to NetCDF \n",
    "        detrended_filt.attrs = {\n",
    "            'Description': 'Detrended Arctic sea ice concentrations (SIC) the '\\\n",
    "                +'model {}. Years 1979-2020, month of {}. Detrended using a '\\\n",
    "                +'5th order Butterworth lowpass filter with a 2 year cutoff'\\\n",
    "                +'.'.format(model_name, month_names[month_-1]), \n",
    "            'Units'      : '%',\n",
    "            'Timestamp'  : str(datetime.datetime.utcnow().strftime(\n",
    "                \"%H:%M UTC %a %Y-%m-%d\")),\n",
    "            'Data source': 'CLIVAR Large Ensemble Archive, '\\\n",
    "                +'doi:10.1038/s41558-020-0731-2',\n",
    "            'Analysis'   : 'https://github.com/chrisrwp/synthetic-ensemble/'\\\n",
    "                +'blob/main/SIC/Detrend_filter_SIC_obs_models.ipynb'}\n",
    "\n",
    "        detrended_filt.to_netcdf(\n",
    "            '/glade/scratch/cwpowell/Synthetic_ensemble_revisions/SIC/'\\\n",
    "            +'Detrend_filter/{}_detrended_2yr_filter_1979_2020_{}'\\\n",
    "            '.nc'.format(model_name, str(month_).zfill(2)))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
