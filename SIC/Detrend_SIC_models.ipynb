{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a1c92aa",
   "metadata": {},
   "source": [
    "# Detrend Model SIC by its ensemble mean\n",
    "\n",
    "### Author: Chris Wyburn-Powell, [github](https://github.com/chrisrwp/synthetic-ensemble/SIC/Detrend_SIC_models.ipynb)\n",
    "\n",
    "**Input**: <br>\n",
    "- CLIVAR LE Archive model output from CanESM2, CESM1, CSIRO MK3.6, GDL CM3, GFDL ESM2M, MPI ESM1\n",
    "\n",
    "**Output**: <br>\n",
    "- Reduced datasets for all members of the same model for a given month\n",
    "- Detrended data based on:\n",
    "  * Ensemble mean, i.e. the linear trend of the mean of all members\n",
    "  * Ensemble mean with adjustments so the ensemble mean trend does not reach below 0% or above 100% SIC\n",
    "  * Individual mean, i.e. the linear trend of the member which is being detrended \n",
    "  * Individual mean with adjustments to within 0-100% SIC\n",
    "<br>\n",
    "  \n",
    "**Method**: <br>\n",
    "- Use `dask` to loop through all the model output data and reconstitute it for >30N and 1979-2020, this time by month rather than by member\n",
    "- Use a linear trend as calculated by `xarray.DataArray.polyfit` to detrend the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31e1de2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:57 UTC Wed 2021-08-04\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import scipy.signal as sig\n",
    "import datetime\n",
    "import dask\n",
    "\n",
    "print(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11ddcfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/glade/scratch/cwpowell/Synthetic_ensemble/'\n",
    "\n",
    "model_names  = ['CanESM2', 'CESM1', 'CSIRO_MK36', 'GFDL_CM3', 'GFDL_ESM2M', 'MPI_ESM1']\n",
    "mem_len      = [50,        40,      30,           20,         30,           100       ]\n",
    "\n",
    "month_names = ['January', 'February', 'March', 'April', 'May', 'June', 'July', \n",
    "               'August', 'September', 'October', 'November', 'December']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8d6cc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dask workers\n",
    "from dask_jobqueue import PBSCluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "cluster = PBSCluster(cores    = 2,\n",
    "                     memory   = '5GB',\n",
    "                     queue    = 'economy',\n",
    "                     walltime = '00:20:00')\n",
    "\n",
    "cluster.scale(8)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ae567d",
   "metadata": {},
   "source": [
    "# Compute a reduced dataset for 1979-2020 for >30N for all members\n",
    "## Define a function to load the correct model output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8a9756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_member(model, i, sic_sit, chunk_size=False, historical=False):\n",
    "    '''\n",
    "    Open a single member file of either sea ice concentration or thickness from the CLIVAR LE archive using xarray.open_dataset\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : string,\n",
    "        Choose from ['CanESM2', 'CESM1', 'GFDL_CM3', GFDL_ESM2M', 'CSIRO_MK36', 'MPI_ESM1']\n",
    "    i : integer,\n",
    "        Member number e.g. 1\n",
    "    sic_sit : string,\n",
    "        Variable concentration or thickness, choose from ['sic', 'sit']\n",
    "    chunk_size : integer, optional\n",
    "        Choose an int e.g. 50 to use dask chunks to open the data, defaults to not use dask\n",
    "    historical : boolean\n",
    "        Only use for MPI_ESM1 to specify the time period required, defaults to RCP85 time period\n",
    "    decode_bool : boolean\n",
    "        Only use for GFDL_CM3 SIT member 1\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "        xarray.DataSet object from the CLIVAR LE archive sea ice output\n",
    "    '''  \n",
    "    \n",
    "    base_path = '/glade/collections/cdg/data/CLIVAR_LE/'\n",
    "    \n",
    "    assert sic_sit in ['sic', 'sit'], 'invalid variable name'\n",
    "    \n",
    "    if np.logical_or(model=='GFDL_ESM2M', np.logical_and(model=='GFDL_CM3', sic_sit=='sit')): #time is not recognized by xarray\n",
    "        decode_bool = False\n",
    "    else:\n",
    "        decode_bool = True\n",
    "        \n",
    "    \n",
    "    ############### generate the file path ###############\n",
    "    if model == 'CanESM2':\n",
    "        path = base_path+'canesm2_lens/OImon/{}/{}_OImon_CanESM2_historical_rcp85_r{}i1p1_195001-210012.nc'.format(sic_sit, sic_sit, i)\n",
    "        \n",
    "    elif model == 'CESM1':\n",
    "        if i == 1:\n",
    "            path = base_path+'cesm_lens/OImon/{}/{}_OImon_CESM1-CAM5_historical_rcp85_r1i1p1_185001-210012.nc'.format(sic_sit, sic_sit, i)\n",
    "        else:\n",
    "            path = base_path+'cesm_lens/OImon/{}/{}_OImon_CESM1-CAM5_historical_rcp85_r{}i1p1_192001-210012.nc'.format(sic_sit, sic_sit, i)\n",
    "            \n",
    "    elif model == 'GFDL_ESM2M':\n",
    "        path = base_path+'gfdl_esm2m_lens/OImon/{}/{}_OImon_GFDL-ESM2M_historical_rcp85_r{}i1p1_195001-210012.nc'.format(sic_sit, sic_sit, i)\n",
    "    \n",
    "    elif model == 'GFDL_CM3':\n",
    "        path = base_path+'gfdl_cm3_lens/OImon/{}/{}_OImon_GFDL-CM3_historical_rcp85_r{}i1p1_192001-210012.nc'.format(sic_sit, sic_sit, i)\n",
    "        \n",
    "    elif model == 'CSIRO_MK36':\n",
    "        path = base_path+'csiro_mk36_lens/OImon/{}/{}_OImon_CSIRO-Mk3-6-0_historical_rcp85_r{}i1p1_185001-210012.nc'.format(sic_sit, sic_sit, i)\n",
    "        \n",
    "    elif model == 'MPI_ESM1':\n",
    "        period = [['historical', 'rcp85'], ['1850p3_185001-200512', '2005p3_200601-209912']]\n",
    "        \n",
    "        if historical: #2005-12 or previous\n",
    "            path = base_path+'mpi_lens/OImon/{}/{}_OImon_MPI-ESM_{}_r{}i{}.nc'.format(sic_sit, sic_sit, str(period[0][0]), str(i).zfill(3), str(period[1][0]))\n",
    "        else:\n",
    "            path = base_path+'mpi_lens/OImon/{}/{}_OImon_MPI-ESM_{}_r{}i{}.nc'.format(sic_sit, sic_sit, str(period[0][1]), str(i).zfill(3), str(period[1][1]))\n",
    "    else:\n",
    "        print('invalid model name')\n",
    "       \n",
    "    ############### use the file path to open the NetCDF file using xarray ###############\n",
    "    if chunk_size:\n",
    "        data = xr.open_dataset(path, chunks={'time':(chunk_size)}, decode_times=decode_bool)\n",
    "    else:\n",
    "        data = xr.open_dataset(path, decode_times=decode_bool)\n",
    "            \n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3a3552",
   "metadata": {},
   "source": [
    "## Make reduced dataset with each month being separate but for all members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9475d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_data(model_name, mem_len_, month_, start_yr, end_yr, chunk_size):\n",
    "    '''\n",
    "    Open a single member file of either sea ice concentration or thickness from the CLIVAR LE archive using xarray.open_dataset\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model_name : string,\n",
    "        Choose from ['CanESM2', 'CESM1', 'GFDL_CM3', GFDL_ESM2M', 'CSIRO_MK36', 'MPI_ESM1']\n",
    "    mem_len_ : integer,\n",
    "        Number of members e.g. 50\n",
    "    month_ : integer,\n",
    "        Number corresponding to the month e.g. 1 is January\n",
    "    start_yr : integer\n",
    "        Calendar year of the start of required time period e.g. 1950\n",
    "    end_yr : integer\n",
    "        Calendar year of the end of required time period (inclusive) e.g. 2020\n",
    "    chunk_size : integer, optional\n",
    "        Choose an int e.g. 100 to use dask chunks to open the data, defaults to not use dask\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "        xarray.DataSet object of combined data for NH (>30N) for years specificed for a specific month\n",
    "    '''  \n",
    "    \n",
    "    #define chatachteristics\n",
    "    if model_name in ['CESM1', 'MPI_ESM1']:\n",
    "        lat_lon = ['j', 'i']\n",
    "    elif  model_name == 'GFDL_CM3':\n",
    "        lat_lon = ['rlat', 'rlon']\n",
    "    else:\n",
    "        lat_lon = ['lat', 'lon']\n",
    "            \n",
    "    ##############################################################################################\n",
    "    for member_i in np.arange(1,mem_len_+1):\n",
    "\n",
    "        #open member dataset using dask and xarray\n",
    "        #need to combine historical (pre 2005-12) and RCP8.5 to 2020-12 for MPI\n",
    "        if model_name == 'MPI_ESM1':\n",
    "            member_hist = load_member(model_name, member_i, 'sic', chunk_size, historical=True)\n",
    "            member_fut  = load_member(model_name, member_i, 'sic', chunk_size)\n",
    "            member = xr.concat((member_hist, member_fut), dim='time')\n",
    "\n",
    "        else:\n",
    "            member = load_member(model_name, member_i, 'sic', chunk_size)\n",
    "\n",
    "        #need to change CESM1 dates from following month to mid-month as per CSIRO_MK36\n",
    "        #GFDL_ESM2M needs to be changed as xarray cannot decode these dates\n",
    "        if model_name in ['CESM1', 'GFDL_ESM2M']:\n",
    "            time_CSIRO = load_member('CSIRO_MK36', 1, 'sic', chunk_size)\n",
    "\n",
    "            if model_name == 'CESM1':\n",
    "                if member_i == 1:\n",
    "                    member['time'] = time_CSIRO['time'] #the first CESM1 member starts in 1850\n",
    "                else:\n",
    "                    member['time'] = time_CSIRO['time'].sel(time=slice('1920-01','2100-12'))       \n",
    "            else:\n",
    "                member['time'] = time_CSIRO['time'].sel(time=slice('1950-01','2100-12'))   \n",
    "        \n",
    "        #only want northern hemisphere\n",
    "        if model_name == 'GFDL_CM3':\n",
    "            member_NH = (member.where(member['rlat']>30,drop=True))['sic']\n",
    "            #also correct members 1-8, from skipping 2005-12-16 to 2006-02-21 not 2006-01-16\n",
    "            #replace with time from member 9 which doesn't have the offset\n",
    "            GFDL_CM3_mem_9 = load_member('GFDL_CM3', 9, 'sic')\n",
    "            member_NH['time'] = GFDL_CM3_mem_9['time']\n",
    "        else:\n",
    "            member_NH = (member.where(member['lat']>30,drop=True))['sic']\n",
    "        \n",
    "        #select the correct years and detrend into a detrended xarray dataarray\n",
    "        member_NH_yrs = member_NH.sel(time=member_NH['time.month']==month_).sel(time=slice('{}'.format(start_yr),'{}'.format(end_yr)))\n",
    "\n",
    "        #define the shape of the reduced dataset\n",
    "        if member_i == 1: all_mem = np.empty((mem_len_, member_NH_yrs.shape[0], member_NH_yrs.shape[1], member_NH_yrs.shape[2]))\n",
    "        \n",
    "        all_mem[member_i-1] = member_NH_yrs #add this data to the correct position in the array according to its member\n",
    "\n",
    "    ##############################################################################################\n",
    "    #convert to xarray dataarray and save to NetCDF\n",
    "    all_mem_xr = xr.DataArray(data   = all_mem,\n",
    "                              coords = {'member'       : np.arange(1,mem_len_+1),\n",
    "                                        'time'         : member_NH_yrs['time'],\n",
    "                                        str(lat_lon[0]): member_NH_yrs[lat_lon[0]],\n",
    "                                        str(lat_lon[1]): member_NH_yrs[lat_lon[1]]},\n",
    "                              dims   = ['member', 'time', str(lat_lon[0]), str(lat_lon[1])])\n",
    "\n",
    "    all_mem_xr.load()\n",
    "    \n",
    "    all_mem_xr.attrs = {'Description': 'Reduced dataset of sea ice concentrations (SIC) for the model {}, for all ensemble members in the month of {} for the period {}-{}'.format(model_name, month_names[month_-1], start_yr, end_yr),\n",
    "                        'Units'      : '% sea ice concentration',\n",
    "                        'Timestamp'  : str(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\")),                \n",
    "                        'Data source': 'CLIVAR Large Ensemble Archive (doi: 10.1038/s41558-020-0731-2)',\n",
    "                        'Analysis'   : 'Python 3.7.9 - https://github.com/chrisrwp/obs-ensemble/Time_period_and_sigma.ipynb'}\n",
    "\n",
    "    all_mem_xr.to_netcdf(data_path+'SIC/Reduced_datasets/{}_reduced_{}-{}_{}.nc'.format(model_name, start_yr, end_yr, str(month_).zfill(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8354e378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the reduced datasets\n",
    "start_yr = 1979\n",
    "end_yr   = 2020\n",
    "chunk_size = 100\n",
    "\n",
    "for month_ in np.arange(1,13):\n",
    "    print(month_)\n",
    "    for model_i, model_name in enumerate(model_names):\n",
    "        print(datetime.datetime.now(), model_name)\n",
    "        dask.compute(dask.delayed(reduce_data)(model_name, mem_len[model_i], month_, start_yr, end_yr, chunk_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2c6acf",
   "metadata": {},
   "source": [
    "# Use the reduced datasets to detrend relative to the ensemble mean and the individual members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4328c2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use matrix operations for both ensemble and individual\n",
    "start_yr = 1979\n",
    "end_yr   = 2020\n",
    "\n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    for month_ in np.arange(1,13):\n",
    "        print(datetime.datetime.now(), month_)\n",
    "    \n",
    "        ##############################################################################################   \n",
    "        #define grid chatachteristics\n",
    "        if model_name in ['CESM1', 'MPI_ESM1']:\n",
    "            lat_lon = ['j', 'i']\n",
    "        elif  model_name == 'GFDL_CM3':\n",
    "            lat_lon = ['rlat', 'rlon']\n",
    "        else:\n",
    "            lat_lon = ['lat', 'lon']\n",
    "\n",
    "        #load the reduced dataset for the model and month in question\n",
    "        month_data_ = xr.open_dataarray(data_path+'SIC/Reduced_datasets/{}_reduced_1979-2020_{}.nc'.format(model_name, str(month_).zfill(2)))\n",
    "\n",
    "        #change the time to whole numbers for ease of trend calculations\n",
    "        month_data = month_data_.copy()\n",
    "        month_data['time'] = np.arange(start_yr,end_yr+1)\n",
    "        \n",
    "        #GFDL ESM2M uses fraction not percentage for SIC, change to % for this model\n",
    "        if model_name == 'GFDL_ESM2M': month_data = month_data * 100\n",
    "        \n",
    "        ##############################################################################################\n",
    "        #generate a matrix of year values for computing the trend with the trend coefficients\n",
    "        yrs_ind = np.empty((len(month_data['time']), len(month_data['member']), len(month_data[lat_lon[0]]), len(month_data[lat_lon[1]])))\n",
    "        yrs_ens = np.empty((len(month_data['time']), len(month_data[lat_lon[0]]), len(month_data[lat_lon[1]])))\n",
    "\n",
    "        for yr_i, yr in enumerate(np.arange(start_yr,end_yr+1)):\n",
    "            yrs_ind[yr_i] = np.ones((len(month_data['member']), len(month_data[lat_lon[0]]), len(month_data[lat_lon[1]]))) * yr\n",
    "            yrs_ens[yr_i] = np.ones((len(month_data[lat_lon[0]]), len(month_data[lat_lon[1]]))) * yr\n",
    "\n",
    "        yrs_ind = xr.DataArray(data = yrs_ind, coords = {'time':month_data['time'], 'member':month_data['member'], \n",
    "                               lat_lon[0]:month_data[lat_lon[0]], lat_lon[1]:month_data[lat_lon[1]]}, dims = ['time', 'member', lat_lon[0], lat_lon[1]])  \n",
    "\n",
    "        yrs_ens = xr.DataArray(data = yrs_ens, coords = {'time':month_data['time'], lat_lon[0]:month_data[lat_lon[0]], \n",
    "                               lat_lon[1]:month_data[lat_lon[1]]}, dims = ['time', lat_lon[0], lat_lon[1]])  \n",
    "\n",
    "        ##############################################################################################\n",
    "        #calculate the ensemble linear trend coefficients and the coresponding values each year for that trend\n",
    "        ens_coefs = month_data.mean('member').polyfit(dim='time', deg=1, skipna=True)\n",
    "        ens_trend = yrs_ens * ens_coefs.sel(degree=1) + ens_coefs.sel(degree=0)\n",
    "        \n",
    "        #now member data and the trends are in the same time coordinates, compute anomalies\n",
    "        detrended_ens = month_data - ens_trend\n",
    "        detrended_ens['time'] = month_data_['time'] #now calculations have taken place revert to the original time coordinates\n",
    "        detrended_ens = xr.Dataset({'SIC': detrended_ens['polyfit_coefficients']})\n",
    "\n",
    "        ################ adjust the trend so that it only contains physically possible values (0-100%) ################\n",
    "        ens_trend_adj = ens_trend.where(ens_trend>=0,0) #if the trend goes negative, limit it at 0%\n",
    "        ens_trend_adj = ens_trend_adj.where(ens_trend_adj<=100,100) #cap any trend values >100% to 100%\n",
    "        ens_trend_adj = ens_trend_adj.where(ens_trend) #put any nan values back in\n",
    "\n",
    "        detrended_ens_adj = month_data - ens_trend_adj\n",
    "        detrended_ens_adj['time'] = month_data_['time'] #revert to the original time coordinates\n",
    "        detrended_ens_adj = xr.Dataset({'SIC': detrended_ens_adj['polyfit_coefficients']})\n",
    "\n",
    "        ##############################################################################################\n",
    "        #calculate the linear trend coefficients and the coresponding values for each member\n",
    "        ind_coefs = month_data.polyfit(dim='time', deg=1, skipna=True)\n",
    "        ind_trend = yrs_ind * ind_coefs.sel(degree=1) + ind_coefs.sel(degree=0)\n",
    "\n",
    "        #use the month's data with modified time coordinates to compute the detrended data\n",
    "        detrended_ind = month_data - ind_trend\n",
    "        detrended_ind['time'] = month_data_['time'] #now calculations have taken place revert to the original time coordinates\n",
    "        detrended_ind = xr.Dataset({'SIC': detrended_ind['polyfit_coefficients']})\n",
    "\n",
    "        ################ adjust the trend so that it only contains physically possible values (0-100%) ################\n",
    "        ind_trend_adj = ind_trend.where(ind_trend>=0,0) #if the trend goes negative, limit it at 0%\n",
    "        ind_trend_adj = ind_trend_adj.where(ind_trend_adj<=100,100) #cap any trend values >100% to 100%\n",
    "        ind_trend_adj = ind_trend_adj.where(ind_trend) #put any nan values back in\n",
    "\n",
    "        detrended_ind_adj = month_data - ind_trend_adj\n",
    "        detrended_ind_adj['time'] = month_data_['time'] #revert to the original time coordinates\n",
    "        detrended_ind_adj = xr.Dataset({'SIC': detrended_ind_adj['polyfit_coefficients']})\n",
    "\n",
    "        ##############################################################################################\n",
    "        #save individual and ensemble detrended data to NetCDF \n",
    "        attrs_dict = {'Description': 'Detrended Arctic sea ice concentrations (SIC) the model {}. Years 1979-2020, month of {}. Detrended relative to the linear trend of the ensemble mean.'.format(model_name, month_names[month_-1]), \n",
    "                      'Units'      : '%',\n",
    "                      'Timestamp'  : str(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\")),\n",
    "                      'Data source': 'CLIVAR Large Ensemble Archive, doi:10.1038/s41558-020-0731-2',\n",
    "                      'Analysis'   : 'https://github.com/chrisrwp/synthetic-ensemble/SIC/Detrend_SIC_models.ipynb'}\n",
    "\n",
    "        #detrended by the ensemble mean, without adjustment to physical values\n",
    "        detrended_ens.attrs = attrs_dict\n",
    "        detrended_ens.to_netcdf(data_path+'SIC/Detrended/{}_detrended_{}_ensemble_1979_2020.nc'.format(model_name, str(month_).zfill(2)))\n",
    "\n",
    "        #detrended by the ensemble mean, adjusted to physical values\n",
    "        detrended_ens_adj_attrs = attrs_dict.copy()\n",
    "        detrended_ens_adj_attrs['Description'] = 'Detrended Arctic sea ice concentrations (SIC) the model {}. Years 1979-2020, month of {}. Detrended relative to the linear trend of the ensemble mean. The trend in each grid cell is limited to physical values of between 0 and 100% SIC'.format(model_name, month_names[month_-1])\n",
    "        detrended_ens_adj.attrs = detrended_ens_adj_attrs\n",
    "        detrended_ens_adj.to_netcdf(data_path+'SIC/Detrended/{}_detrended_adj_{}_ensemble_1979_2020.nc'.format(model_name, str(month_).zfill(2)))\n",
    "\n",
    "        #detrended by the individual member trend, without adjustment to physical values\n",
    "        detrended_ind_attrs = attrs_dict.copy()\n",
    "        detrended_ind_attrs['Description'] = 'Detrended Arctic sea ice concentrations (SIC) the model {}. Years 1979-2020, month of {}. Detrended relative to the individual ensemble member linear trend.'.format(model_name, month_names[month_-1])\n",
    "        detrended_ind.attrs = detrended_ind_attrs\n",
    "        detrended_ind.to_netcdf(data_path+'SIC/Detrended/{}_detrended_{}_individual_1979_2020.nc'.format(model_name, str(month_).zfill(2)))  \n",
    "\n",
    "        #detrended by the individual member trend, adjusted to physical values\n",
    "        detrended_ind_adj_attrs = attrs_dict.copy()\n",
    "        detrended_ind_adj_attrs['Description'] = 'Detrended Arctic sea ice concentrations (SIC) the model {}. Years 1979-2020, month of {}. Detrended relative to the individual ensemble member linear trend. The trend in each grid cell is limited to physical values of between 0 and 100% SIC'.format(model_name, month_names[month_-1])\n",
    "        detrended_ind_adj.attrs = detrended_ind_adj_attrs\n",
    "        detrended_ind_adj.to_netcdf(data_path+'SIC/Detrended/{}_detrended_adj_{}_individual_1979_2020.nc'.format(model_name, str(month_).zfill(2)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f481aa",
   "metadata": {},
   "source": [
    "# Compute $\\sigma_{LE}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "913bbb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_names:\n",
    "    print(datetime.datetime.now(), model_name)\n",
    "    sigma_LE_model = {}\n",
    "    for adj in ['', 'adj_']:\n",
    "        for ind_ens in ['ensemble', 'individual']:\n",
    "            sigma_LE_model_type = []\n",
    "            for month_ in np.arange(1,13):\n",
    "                month_detrended = xr.open_dataset(data_path+'SIC/Detrended/{}_detrended_{}{}_{}_1979_2020.nc'.format(model_name, adj, str(month_).zfill(2), ind_ens))\n",
    "                sigma_LE_model_type.append(month_detrended['SIC'].std('time').std('member'))\n",
    "                \n",
    "            sigma_LE_model_type = xr.concat((sigma_LE_model_type), dim='month') \n",
    "            sigma_LE_model_type['month'] = np.arange(1,13)\n",
    "            \n",
    "            sigma_LE_model[adj+ind_ens] = sigma_LE_model_type\n",
    "    \n",
    "    sigma_LE_model = xr.Dataset(sigma_LE_model)\n",
    "    sigma_LE_model.attrs = {'Description': 'Standard deviation between ensemble members for detrended sea ice concentration (SIC). Detrended 1979-2020 relative to the ensemble or individual members, with adj meaning unphysical values of the detrended data are correct to physical bounds', \n",
    "                            'Units'      : '%',\n",
    "                            'Timestamp'  : str(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\")),\n",
    "                            'Data source': 'CLIVAR Large Ensemble Archive (doi: 10.1038/s41558-020-0731-2)',\n",
    "                            'Analysis'   : 'https://github.com/chrisrwp/synthetic-ensemble/SIC/Detrend_SIC_models.ipynb'}\n",
    "    \n",
    "    sigma_LE_model.to_netcdf(data_path+'SIC/Detrended/Sigma_LE_{}.nc'.format(model_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
