{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41d3548d-62e0-4d80-93f0-937daff2b86c",
   "metadata": {},
   "source": [
    "# Detrend Observational SIC by individual trends and jackknifed trends\n",
    "\n",
    "### Author: Chris Wyburn-Powell, [github](https://github.com/chrisrwp/synthetic-ensemble/SIC/Detrend_SIC_obs.ipynb)\n",
    "\n",
    "**Input datasets, as created in this [notebook](https://github.com/chrisrwp/synthetic-ensemble/SIA/SIA_calculations_observations.ipynb1):** <br>\n",
    "\n",
    "- **NOAA/NSIDC CDR version 4 (CDR, BT, NT)**: Pole hole is filled using the average SIC of the surrounding grid cells (built in). Missing months (1984-07 1987-12, 1988-01) are filled by looking at the closest valid months for SIA (CDR), idenfitying whether the previous or following year's SIA for those valid months are closets to that year with missing data, then selecting the previous or following SIC data to fill the missing data. E.g. For 1984-07: SIA for 1983-06 and 1985-06 are compared with 1984-06 and 1983-08 and 1985-08 are compared with 1984-08. 1985 is found to be closer to 1984 than 1983 was with 1984 so to fill 1984-07, 1985-07 is copied. Similarly SIC values for 1988-12 and 1989-01 are used to fill 1987-12 and 1988-01.\n",
    "- **HadISST1**: Discontinuities for months 2009-03 and 2009-04 were found with extreme negative anomalies which do not appear in other datasets. SIC from 2007-03 is used for 2009-03 and 2008-04 are used for 2009-04.\n",
    "- **Merged Hadley OI**: Data interpolated over land is masked using the land mask for HadISST1. 2009-03 and 2009-04 are filled with data from 2007-03 and 2008-04 respectively similarly to HadISST1. 2009-02 and 2009-05 are filled with 2010-02 and 2010-05 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6fe8e78-1003-4c85-9d9f-114bd4c70846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:40 UTC Sat 2021-08-14\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import datetime\n",
    "\n",
    "print(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e51f167d-c8d7-429f-af85-08a3428178a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/glade/scratch/cwpowell/Synthetic_ensemble/'\n",
    "\n",
    "month_names = ['January', 'February', 'March', 'April', 'May', 'June', 'July', \n",
    "               'August', 'September', 'October', 'November', 'December']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef9fc61-0774-4ecb-987b-2e9f794038f8",
   "metadata": {},
   "source": [
    "# Detrend HadISST1 relative to each cell's trend and 50 jackknifed trends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede8b746-87e6-4dc5-bd09-b0ee0bb7a6af",
   "metadata": {},
   "source": [
    "## Detrend HadISST1 on individual cell trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b3ded34-66f9-454e-886d-966650d71c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-14 17:46:19.767859 1\n",
      "2021-08-14 17:47:28.666549 2\n",
      "2021-08-14 17:48:35.689070 3\n",
      "2021-08-14 17:49:43.816294 4\n",
      "2021-08-14 17:50:51.415648 5\n",
      "2021-08-14 17:51:58.229470 6\n",
      "2021-08-14 17:53:04.762056 7\n",
      "2021-08-14 17:54:11.641346 8\n",
      "2021-08-14 17:55:18.706962 9\n",
      "2021-08-14 17:56:25.485116 10\n",
      "2021-08-14 17:57:36.559625 11\n",
      "2021-08-14 17:58:57.160713 12\n"
     ]
    }
   ],
   "source": [
    "start_yr = 1979\n",
    "end_yr   = 2020\n",
    "\n",
    "jackknife_n = 50\n",
    "len_rand = 32 #number of randomly chosen elements to be deleted\n",
    "\n",
    "# data = xr.open_dataset(data_path+'Raw_data/observations/HadISST/HadISST1_NH_79-20_filled.nc')\n",
    "# data = xr.open_dataset(data_path+'Raw_data/observations/NSIDC_CDR_v4/SIC_CDR_BT_NT_79-20_filled.nc')\n",
    "data = xr.open_dataset(data_path+'Raw_data/observations/merged_Hadley_OI/merged_Hadley_OI_SIC_79-20.nc')\n",
    "\n",
    "# for var_name in ['CDR', 'BT', 'NT']:\n",
    "# dataset_name = 'HadISST1' #HadISST1\n",
    "# dataset_name = 'NSIDC_{}'.format(var_name) #NSIDC CDR version 4 (CDR)\n",
    "dataset_name = 'Merged_Hadley_OI'\n",
    "\n",
    "var_name = 'sic' #HadISST1 and Merged\n",
    "# var_name = 'CDR' #NSIDC CDR, or replace CDR with NT or BT\n",
    "\n",
    "# data_doi = 'doi:10.1029/2002JD002670' #HadISST1\n",
    "#     data_doi = 'doi:10.7265/efmz-2t65' #NSIDC CDR version 4\n",
    "data_doi = 'doi:10.5065/r33v-sv91' #Merged\n",
    "\n",
    "lat_lon = ['latitude', 'longitude'] #for HadISST1 and merged\n",
    "#     lat_lon = ['ygrid', 'xgrid'] #for CDR, NT, BT\n",
    "\n",
    "ind     = []\n",
    "ind_adj = []\n",
    "jak     = []\n",
    "jak_adj = []\n",
    "\n",
    "for month_ in np.arange(1,13):\n",
    "    print(datetime.datetime.now(), month_)\n",
    "\n",
    "    #change the time to whole numbers for ease of trend calculations\n",
    "    month_data_ = data.sel(time=data['time.month']==month_).sel(time=slice(str(start_yr), str(end_yr)))\n",
    "    if var_name in ['CDR', 'BT', 'NT']:\n",
    "        month_data = month_data_.copy()\n",
    "        for var_ in ['CDR', 'BT', 'NT']:\n",
    "            if var_ != var_name:\n",
    "                month_data  = month_data.drop(var_)\n",
    "    else:\n",
    "        month_data = month_data_.copy() #create a copy to preseve original variable's time dimension\n",
    "    month_data['time'] = np.arange(start_yr,end_yr+1)\n",
    "\n",
    "    ##############################################################################################\n",
    "    #generate a matrix of year values for computing the trend with the trend coefficients\n",
    "    yrs_ind = np.empty((len(month_data['time']), len(month_data[lat_lon[0]]), len(month_data[lat_lon[1]])))\n",
    "    yrs_jak = np.empty((len(month_data['time']), jackknife_n, len(month_data[lat_lon[0]]), len(month_data[lat_lon[1]])))\n",
    "\n",
    "    for yr_i, yr in enumerate(np.arange(start_yr,end_yr+1)):\n",
    "        yrs_ind[yr_i] = np.ones((len(month_data[lat_lon[0]]), len(month_data[lat_lon[1]]))) * yr\n",
    "        yrs_jak[yr_i] = np.ones((len(month_data[lat_lon[0]]), len(month_data[lat_lon[1]]))) * yr\n",
    "\n",
    "    yrs_ind = xr.DataArray(data = yrs_ind, coords = {'time':month_data['time'], lat_lon[0]:month_data[lat_lon[0]], \n",
    "                           lat_lon[1]:month_data[lat_lon[1]]}, dims = ['time', lat_lon[0], lat_lon[1]])  \n",
    "\n",
    "    yrs_jak = xr.DataArray(data = yrs_jak, coords = {'time':month_data['time'], 'jackknife':np.arange(1,jackknife_n+1), \n",
    "                           lat_lon[0]:month_data[lat_lon[0]], lat_lon[1]:month_data[lat_lon[1]]}, \n",
    "                           dims = ['time', 'jackknife', lat_lon[0], lat_lon[1]])  \n",
    "\n",
    "    ##############################################################################################\n",
    "    #calculate the linear trend coefficients and the coresponding values each year for the individual trend\n",
    "    ind_coefs = month_data.polyfit(dim='time', deg=1, skipna=True)\n",
    "    ind_trend = yrs_ind * ind_coefs.sel(degree=1) + ind_coefs.sel(degree=0)\n",
    "\n",
    "    #now member data and the trends are in the same time coordinates, compute anomalies\n",
    "    detrended_ind = month_data[var_name] - ind_trend\n",
    "    detrended_ind['time'] = month_data_['time'] #now calculations have taken place revert to the original time coordinates\n",
    "\n",
    "    ################ adjust the trend so that it only contains physically possible values (0-100%) ################\n",
    "    ind_trend_adj = ind_trend.where(ind_trend['{}_polyfit_coefficients'.format(var_name)]>=0,0) #if the trend goes negative, limit it at 0%\n",
    "    ind_trend_adj = ind_trend_adj.where(ind_trend_adj<=100,100) #cap any trend values >100% to 100%\n",
    "    ind_trend_adj = ind_trend_adj.where(ind_trend['{}_polyfit_coefficients'.format(var_name)]) #put any nan values back in\n",
    "\n",
    "    detrended_ind_adj = month_data - ind_trend_adj['{}_polyfit_coefficients'.format(var_name)]\n",
    "    detrended_ind_adj['time'] = month_data_['time'] #revert to the original time coordinates\n",
    "\n",
    "    ##############################################################################################\n",
    "    #compute a jackknife of each grid cell, note all grid cells in the month have the same years deleted    \n",
    "    jackknife_data = []\n",
    "    for i in range(jackknife_n):\n",
    "        rand_yrs = np.sort(np.random.choice(np.arange(1979,2021),size=len(month_data['time'])-len_rand, replace=False))\n",
    "        jackknife_data.append(month_data.sel(time=rand_yrs))\n",
    "\n",
    "    jackknife_data = xr.concat((jackknife_data), dim='jackknife')\n",
    "    jackknife_data['jackknife'] = np.arange(1, jackknife_n+1)\n",
    "\n",
    "    #calculate the linear trends\n",
    "    jak_coefs = jackknife_data.polyfit(dim='time', deg=1, skipna=True)\n",
    "    jak_trend = yrs_jak * jak_coefs.sel(degree=1) + jak_coefs.sel(degree=0)\n",
    "\n",
    "    #now member data and the trends are in the same time coordinates, compute anomalies\n",
    "    detrended_jak = month_data[var_name] - jak_trend\n",
    "    detrended_jak['time'] = month_data_['time'] #now calculations have taken place revert to the original time coordinates\n",
    "\n",
    "    ################ adjust the trend so that it only contains physically possible values (0-100%) ################\n",
    "    jak_trend_adj = jak_trend.where(jak_trend['{}_polyfit_coefficients'.format(var_name)]>=0,0) #if the trend goes negative, limit it at 0%\n",
    "    jak_trend_adj = jak_trend_adj.where(jak_trend_adj<=100,100) #cap any trend values >100% to 100%\n",
    "    jak_trend_adj = jak_trend_adj.where(jak_trend['{}_polyfit_coefficients'.format(var_name)]) #put any nan values back in\n",
    "\n",
    "    detrended_jak_adj = month_data - jak_trend_adj['{}_polyfit_coefficients'.format(var_name)]\n",
    "    detrended_jak_adj['time'] = month_data_['time'] #revert to the original time coordinates\n",
    "\n",
    "    ##############################################################################################\n",
    "    #make a xarray dataarrays for the 4 types of detrending\n",
    "    ind.append(detrended_ind)\n",
    "    ind_adj.append(detrended_ind_adj)\n",
    "    jak.append(detrended_jak)\n",
    "    jak_adj.append(detrended_jak_adj)\n",
    "\n",
    "ind     = xr.concat((ind), dim='time')\n",
    "ind_adj = xr.concat((ind_adj), dim='time')\n",
    "jak     = xr.concat((jak), dim='time')\n",
    "jak_adj = xr.concat((jak_adj), dim='time')\n",
    "\n",
    "##############################################################################################\n",
    "#concatenate all months together and save to NetCDF\n",
    "######### CHANGE BACK TO ALL MONTHS WHEN CHANGING MONTHS #########\n",
    "attrs_dict = {'Description': 'Detrended Arctic sea ice concentrations (SIC) for the observational dataset {}. Years 1979-2020, March and September. Detrended relative to the linear trend of the each month.'.format(dataset_name), \n",
    "              'Units'      : '%',\n",
    "              'Timestamp'  : str(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\")),\n",
    "              'Data source': '{}, {}'.format(dataset_name, data_doi),\n",
    "              'Analysis'   : 'https://github.com/chrisrwp/synthetic-ensemble/SIC/Detrend_SIC_obs.ipynb'}\n",
    "\n",
    "#detrended by the lienar trend, without adjustment to physical values\n",
    "ind.attrs = attrs_dict\n",
    "ind = ind.rename({'{}_polyfit_coefficients'.format(var_name):'SIC'})\n",
    "ind.to_netcdf(data_path+'SIC/Detrended/{}_detrended_individual_1979_2020_03_09.nc'.format(dataset_name))\n",
    "\n",
    "#detrended by the linear trend, adjusted to physical values\n",
    "ind_adj_attrs = attrs_dict.copy()\n",
    "ind_adj_attrs['Description'] = 'Detrended Arctic sea ice concentrations (SIC) for the observational dataset {}. Years 1979-2020, March and September. Detrended relative to the linear trend of the each month. The trend in each grid cell is limited to physical values of between 0 and 100% SIC'.format(dataset_name)\n",
    "ind_adj.attrs = ind_adj_attrs\n",
    "ind_adj = ind_adj.rename({var_name:'SIC'})\n",
    "ind_adj.to_netcdf(data_path+'SIC/Detrended/{}_detrended_adj_individual_1979_2020_03_09.nc'.format(dataset_name))\n",
    "\n",
    "# #detrended by the jackknife trends, without adjustment to physical values\n",
    "jak_attrs = attrs_dict.copy()\n",
    "jak_attrs['Description'] = 'Detrended Arctic sea ice concentrations (SIC) the model {}. Years 1979-2020, March and September. Detrended relative to the {} jackknifed trends, computed by removing {} data points for each grid cell.'.format(dataset_name, jackknife_n, len_rand)\n",
    "jak.attrs = jak_attrs\n",
    "jak = jak.rename({'{}_polyfit_coefficients'.format(var_name):'SIC'})\n",
    "jak.to_netcdf(data_path+'SIC/Detrended/{}_detrended_jackknife_1979_2020_03_09.nc'.format(dataset_name))  \n",
    "\n",
    "#detrended by the individual member trend, adjusted to physical values\n",
    "jak_adj_attrs = attrs_dict.copy()\n",
    "jak_adj_attrs['Description'] = 'Detrended Arctic sea ice concentrations (SIC) the model {}. Years 1979-2020, March and September. Detrended relative to the {} jackknifed trends, computed by removing {} data points for each grid cell. The trend in each grid cell is limited to physical values of between 0 and 100% SIC'.format(dataset_name, jackknife_n, len_rand)\n",
    "jak_adj.attrs = jak_adj_attrs\n",
    "jak_adj = jak_adj.rename({var_name:'SIC'})\n",
    "jak_adj.to_netcdf(data_path+'SIC/Detrended/{}_detrended_adj_jackknife_1979_2020_03_09.nc'.format(dataset_name))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3221c627-b0ef-4d5b-94d5-f2c32466c546",
   "metadata": {},
   "source": [
    "# Use Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4c0b48-d517-40fe-b7c6-451f85e520a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIC_detrend_obs(data, month_, dataset_name, data_doi, var_name, lat_lon, jackknife_n, len_rand):\n",
    "    '''\n",
    "    Detrend a 3D relative to , with and without adjusting to physical limits of 0 and 100% SIC\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : integer,\n",
    "        For 1979-2020 use 42 as the total number of years in that time period\n",
    "    data : 1 dimensional xarray dataarray,\n",
    "        For 1979-2020 this is an array of shape [42] \n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        2D xarray dataarray object of 1000 resamplings of the input data, shape: (time_period, 1000)\n",
    "    '''  \n",
    "    \n",
    "    start_yr = 1979\n",
    "    end_yr   = 2020\n",
    "\n",
    "    #change the time to whole numbers for ease of trend calculations\n",
    "    month_data_ = data.sel(time=data['time.month']==month_).sel(time=slice(str(start_yr), str(end_yr)))\n",
    "    if var_name in ['CDR', 'BT', 'NT']:\n",
    "        month_data = month_data_.copy()\n",
    "        for var_ in ['CDR', 'BT', 'NT']:\n",
    "            if var_ != var_name:\n",
    "                month_data  = month_data.drop(var_)\n",
    "    else:\n",
    "        month_data = month_data_.copy() #create a copy to preseve original variable's time dimension\n",
    "    month_data['time'] = np.arange(start_yr,end_yr+1)\n",
    "    \n",
    "    ##############################################################################################\n",
    "    #generate a matrix of year values for computing the trend with the trend coefficients\n",
    "    yrs_ind = np.empty((len(month_data['time']), len(month_data[lat_lon[0]]), len(month_data[lat_lon[1]])))\n",
    "    yrs_jak = np.empty((len(month_data['time']), jackknife_n, len(month_data[lat_lon[0]]), len(month_data[lat_lon[1]])))\n",
    "\n",
    "    for yr_i, yr in enumerate(np.arange(start_yr,end_yr+1)):\n",
    "        yrs_ind[yr_i] = np.ones((len(month_data[lat_lon[0]]), len(month_data[lat_lon[1]]))) * yr\n",
    "        yrs_jak[yr_i] = np.ones((len(month_data[lat_lon[0]]), len(month_data[lat_lon[1]]))) * yr\n",
    "\n",
    "    yrs_ind = xr.DataArray(data = yrs_ind, coords = {'time':month_data['time'], lat_lon[0]:month_data[lat_lon[0]], \n",
    "                           lat_lon[1]:month_data[lat_lon[1]]}, dims = ['time', lat_lon[0], lat_lon[1]])  \n",
    "\n",
    "    yrs_jak = xr.DataArray(data = yrs_jak, coords = {'time':month_data['time'], 'jackknife':np.arange(1,jackknife_n+1), \n",
    "                           lat_lon[0]:month_data[lat_lon[0]], lat_lon[1]:month_data[lat_lon[1]]}, \n",
    "                           dims = ['time', 'jackknife', lat_lon[0], lat_lon[1]])  \n",
    "\n",
    "    ##############################################################################################\n",
    "    #calculate the linear trend coefficients and the coresponding values each year for the individual trend\n",
    "    ind_coefs = month_data.polyfit(dim='time', deg=1, skipna=True)\n",
    "    ind_trend = yrs_ind * ind_coefs.sel(degree=1) + ind_coefs.sel(degree=0)\n",
    "\n",
    "    #now member data and the trends are in the same time coordinates, compute anomalies\n",
    "    detrended_ind = month_data[var_name] - ind_trend\n",
    "    detrended_ind['time'] = month_data_['time'] #now calculations have taken place revert to the original time coordinates\n",
    "\n",
    "    ################ adjust the trend so that it only contains physically possible values (0-100%) ################\n",
    "    ind_trend_adj = ind_trend.where(ind_trend['{}_polyfit_coefficients'.format(var_name)]>=0,0) #if the trend goes negative, limit it at 0%\n",
    "    ind_trend_adj = ind_trend_adj.where(ind_trend_adj<=100,100) #cap any trend values >100% to 100%\n",
    "    ind_trend_adj = ind_trend_adj.where(ind_trend['{}_polyfit_coefficients'.format(var_name)]) #put any nan values back in\n",
    "\n",
    "    detrended_ind_adj = month_data - ind_trend_adj['{}_polyfit_coefficients'.format(var_name)]\n",
    "    detrended_ind_adj['time'] = month_data_['time'] #revert to the original time coordinates\n",
    "\n",
    "    ##############################################################################################\n",
    "    #compute a jackknife of each grid cell, note all grid cells in the month have the same years deleted    \n",
    "    jackknife_data = []\n",
    "    for i in range(jackknife_n):\n",
    "        rand_yrs = np.sort(np.random.choice(np.arange(1979,2021),size=len(month_data['time'])-len_rand, replace=False))\n",
    "        jackknife_data.append(month_data.sel(time=rand_yrs))\n",
    "    \n",
    "    jackknife_data = xr.concat((jackknife_data), dim='jackknife')\n",
    "    jackknife_data['jackknife'] = np.arange(1, jackknife_n+1)\n",
    "    \n",
    "    #calculate the linear trends\n",
    "    jak_coefs = jackknife_data.polyfit(dim='time', deg=1, skipna=True)\n",
    "    jak_trend = yrs_jak * jak_coefs.sel(degree=1) + jak_coefs.sel(degree=0)\n",
    "    \n",
    "    #now member data and the trends are in the same time coordinates, compute anomalies\n",
    "    detrended_jak = month_data[var_name] - jak_trend\n",
    "    detrended_jak['time'] = month_data_['time'] #now calculations have taken place revert to the original time coordinates\n",
    "\n",
    "    ################ adjust the trend so that it only contains physically possible values (0-100%) ################\n",
    "    jak_trend_adj = jak_trend.where(jak_trend['{}_polyfit_coefficients'.format(var_name)]>=0,0) #if the trend goes negative, limit it at 0%\n",
    "    jak_trend_adj = jak_trend_adj.where(jak_trend_adj<=100,100) #cap any trend values >100% to 100%\n",
    "    jak_trend_adj = jak_trend_adj.where(jak_trend['{}_polyfit_coefficients'.format(var_name)]) #put any nan values back in\n",
    "\n",
    "    detrended_jak_adj = month_data - jak_trend_adj['{}_polyfit_coefficients'.format(var_name)]\n",
    "    detrended_jak_adj['time'] = month_data_['time'] #revert to the original time coordinates\n",
    "    \n",
    "    ################\n",
    "    return(detrended_ind, detrended_ind_adj, detrended_jak, detrended_jak_adj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL-3.7.9",
   "language": "python",
   "name": "npl-3.7.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
