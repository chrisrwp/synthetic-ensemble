{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CESM subsampling pi control with different 'ensemble' time periods\n",
    "\n",
    "### Author: Chris Wyburn-Powell, [github](https://github.com/chrisrwp/synthetic-ensemble/SIA/CESM_pi_control.ipynb)\n",
    "\n",
    "**Input:** <br>\n",
    "CESM Large Ensemble preindustrial control, [website](https://www.cesm.ucar.edu/projects/community-projects/LENS/instructions.html#ESG), [CESM LE doi](https://doi.org/10.1175/BAMS-D-13-00255.1)\n",
    "- Coupled (years 0400-2200): `b.e11.B1850C5CN.f09_g16.005.cice.h.aice_nh*.nc` \n",
    "- Slab-ocean (years 0100-1001): `e.e11.E1850C5CN.f09_g16.001.cice.h.aice_nh*.nc` <br>\n",
    "\n",
    "CESM Large Ensemble, historical and RCP8.5\n",
    "- 1920???-1990?????, little trend during that time (20th century near constant - 20C)\n",
    "- 1995???-2045???, approx linear trend for that time (21th century near linear trend - 21C)\n",
    "\n",
    "**Output:** <br>\n",
    "- SIA time series for coupled and slab-ocean preindustrial controls\n",
    "- Detrended SIA time series\n",
    "- Standard deviation of resampled time series for all time period lengths\n",
    "\n",
    "**Method:** <br>\n",
    "- Use the 40 emsemble members from LE or 'simulate' 40 ensemble members in the preindustrial control by using randomly chosen start dates for 40 time series. **Use the same random start dates for all time period lengths**\n",
    "- Allow the time series to be of length between 6 and 298 years with an interval of 4 years\n",
    "- Detrend either by each time series or from the mean trend from the 40 'ensemble' members for each time period\n",
    "- Resample 1000 times with a 2 year block boostrap size \n",
    "- Repeat the analysis for the preindustrial control 10 times to select different randomly chosen start years and average the results\n",
    "\n",
    "**TO DO:** <br>\n",
    "- Decide on start/end dates for 20C and 21C. Make reduced dataset files for those. Should be easy to resample these and detrend based on ensemble or individual trend \n",
    "- Redo the code to select the same random start years for all time periods\n",
    "- Also look at Atmosphere-only control run, f.e11.F1850C5CN.f09_f09.001, years 1-2600 availible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:54 UTC Fri 2021-07-02\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.path as mpath\n",
    "# from matplotlib.patches import Patch\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import datetime\n",
    "import dask\n",
    "# from cftime import num2date, DatetimeNoLeap\n",
    "print(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\"))\n",
    "\n",
    "data_path = '/glade/scratch/cwpowell/Synthetic_ensemble/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_jobqueue import PBSCluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "cluster = PBSCluster(cores    = 8,\n",
    "                     memory   = '4GB',\n",
    "                     queue    = 'regular',\n",
    "                     walltime = '00:44:00')\n",
    "\n",
    "cluster.scale(8)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CESM LE 1920-1990 and 1985-2045\n",
    "## Make a reduced dataset for the 20C and 21C time periods of the CESM LE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample the two eras with 6-70 or 6-60 year length time series, interval of 2 years "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare with existing data from the 1979-2020 resampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CESM Preindustrial Control\n",
    "## Make reduced datast of SIA for whole of PI control (slab-ocean and coupled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the pi_control files\n",
    "pi_control = xr.open_mfdataset('/glade/collections/cdg/data/cesmLE/CESM-CAM5-BGC-LE/ice/proc/tseries/monthly/aice/b.e11.B1850C5CN.f09_g16.005.cice.h.aice_nh*', concat_dim='time', chunks=104)\n",
    "pi_control_slab = xr.open_mfdataset('/glade/collections/cdg/data/cesmLE/CESM-CAM5-BGC-LE/ice/proc/tseries/monthly/aice/e.e11.E1850C5CN.f09_g16.001.cice.h.aice_nh*', concat_dim='time', chunks=104)\n",
    "#open the corresponding area file\n",
    "CESM_area_file = xr.open_dataset('/glade/collections/cdg/data/CLIVAR_LE/cesm_lens/fx/areacello/areacello_fx_CESM1-CAM5_historical_r0i0p0.nc')\n",
    "area_truc = CESM_area_file['areacello'].where(CESM_area_file['lat']>35,drop=True) #drop the latitudes below 35N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight the grid cells\n",
    "pi_weighted      = pi_control['aice'] * area_truc.values\n",
    "pi_slab_weighted = pi_control_slab['aice'] * area_truc.values\n",
    "#sum up the SIA\n",
    "pi_SIA      = pi_weighted.sum('nj').sum('ni')\n",
    "pi_slab_SIA = pi_slab_weighted.sum('nj').sum('ni')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save coupled SIA to NetCDF\n",
    "pi_SIA.load()\n",
    "pi_SIA = pi_SIA/1e14\n",
    "\n",
    "pi_SIA.attrs = {'Description': 'SIA for CESM 1 pre-industrial control (1850) coupled runs, northern hemisphere, time 0400-2200.', \n",
    "                'Units'      : 'Million square km',\n",
    "                'Timestamp'  : str(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\")),\n",
    "                'Data source': '/glade/collections/cdg/data/cesmLE/CESM-CAM5-BGC-LE/ice/proc/tseries/monthly/aice/b.e11.B1850C5CN.f09_g16.005.cice.h.aice_nh.*.nc (doi:10.1175/BAMS-D-13-00255.1)',\n",
    "                'Analysis'   : 'Python 3.7.9 - https://github.com/chrisrwp/synthetic-ensemble/SIA/CESM_pi_control.ipynb'}\n",
    "\n",
    "pi_SIA.to_netcdf(data_path+'Raw_data/CESM_pi_control/CESM_pi_control_1850_coupled_SIA_0400_2200.nc')\n",
    "\n",
    "#save slab SIA to NetCDF\n",
    "pi_slab_SIA.load()\n",
    "pi_slab_SIA = pi_slab_SIA/1e14\n",
    "\n",
    "pi_slab_SIA.attrs = {'Description': 'SIA for CESM 1 pre-industrial control (1850) slab-ocean runs, northern hemisphere, time 0100-1001.', \n",
    "                     'Units'      : 'Million square km',\n",
    "                     'Timestamp'  : str(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\")),\n",
    "                     'Data source': '/glade/collections/cdg/data/cesmLE/CESM-CAM5-BGC-LE/ice/proc/tseries/monthly/aice/e.e11.E1850C5CN.f09_g16.001.cice.h.aice_nh*.nc (doi:10.1175/BAMS-D-13-00255.1)',\n",
    "                     'Analysis'   : 'Python 3.7.9 - https://github.com/chrisrwp/synthetic-ensemble/SIA/CESM_pi_control.ipynb'}\n",
    "\n",
    "pi_slab_SIA.to_netcdf(data_path+'Raw_data/CESM_pi_control/CESM_pi_control_1850_slab_SIA_0100_1001.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CORRECT THE MONTH??????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample the Preindustrial control data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make 40 ensembles like the CESM1 LE <br>\n",
    "The total length of time of the control runs are 900 or 1800 years <br>\n",
    "We want to test resampling of 40 time series of length 6-250 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the SIA from computations\n",
    "pi_SIA      = xr.open_dataarray(data_path+'Raw_data/CESM_pi_control/CESM_pi_control_1850_coupled_SIA_0400_2200.nc')\n",
    "pi_slab_SIA = xr.open_dataarray(data_path+'Raw_data/CESM_pi_control/CESM_pi_control_1850_slab_SIA_0100_1001.nc')\n",
    "\n",
    "month_names = ['January', 'February', 'March', 'April', 'May', 'June', 'July', \n",
    "               'August', 'September', 'October', 'November', 'December']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_boot2(time_period, data):\n",
    "    boot_2_first_ind = xr.DataArray(data   = np.random.randint(0,time_period-2, (1000,int(time_period/2))), \n",
    "                                    coords = {'resampling':np.arange(1,1001,1), 'year_i':np.arange(1,time_period+1,2)},\n",
    "                                    dims   = ['resampling', 'year_i'])\n",
    "\n",
    "    boot_2_second_ind = (boot_2_first_ind+1).copy()\n",
    "    boot_2_second_ind['year_i'] = np.arange(2,time_period+2,2)\n",
    "\n",
    "    all_boot_2_ind = xr.concat((boot_2_first_ind, boot_2_second_ind), dim='year_i').sortby('year_i')\n",
    "    \n",
    "    ind_base = np.repeat(np.arange(0,time_period*1000,time_period),time_period)\n",
    "    \n",
    "    ind_1_d = np.ravel(all_boot_2_ind) + ind_base\n",
    "\n",
    "    SIA_mem_1000 = np.ravel(np.tile(data,(time_period,1000)))\n",
    "\n",
    "    resample_boot_2 = xr.DataArray(data = np.reshape(SIA_mem_1000[ind_1_d], (time_period,1000)),\n",
    "                                   coords = {'year_i':np.arange(1,time_period+1,1), 'resampling':np.arange(1,1001,1)},\n",
    "                                   dims   = ['year_i', 'resampling'])\n",
    "\n",
    "    return(resample_boot_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_boot1(time_period, data):\n",
    "    boot_1_ind = xr.DataArray(data   = np.random.randint(0,time_period-1, (1000,int(time_period))), \n",
    "                              coords = {'resampling':np.arange(1,1001,1), 'year_i':np.arange(1,time_period+1,1)},\n",
    "                              dims   = ['resampling', 'year_i'])\n",
    "    \n",
    "    ind_base = np.repeat(np.arange(0,time_period*1000,time_period),time_period)\n",
    "    ind_1_d = np.ravel(boot_1_ind) + ind_base\n",
    "    \n",
    "    SIA_mem_1000 = np.ravel(np.tile(data,(time_period,1000)))\n",
    "\n",
    "    resample_boot_1 = xr.DataArray(data = np.reshape(SIA_mem_1000[ind_1_d], (time_period,1000)),\n",
    "                                   coords = {'year_i':np.arange(1,time_period+1,1), 'resampling':np.arange(1,1001,1)},\n",
    "                                   dims   = ['year_i', 'resampling'])\n",
    "\n",
    "    return(resample_boot_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function computes resamplings for ONE TIME PERIOD and ONE MONTH\n",
    "#THIS funtion runs a lot faster as it uses indexing rather than nested for loops\n",
    "def resample_1period_1month_matrix(SIA, month_, resample_n, time_period, max_t):      \n",
    "    \n",
    "    #initialize arrays, shape [time period, member, resampling or largest time series]\n",
    "    sd_resamp1        = np.empty((40, int(resample_n)))*np.nan\n",
    "    sd_resamp_no_det1 = np.empty((40, int(resample_n)))*np.nan\n",
    "    sd_resamp2        = np.empty((40, int(resample_n)))*np.nan\n",
    "    sd_resamp_no_det2 = np.empty((40, int(resample_n)))*np.nan\n",
    "    SIA_mem           = np.empty((40, max_t))*np.nan\n",
    "    mem_anom          = np.empty((40, max_t))*np.nan\n",
    "    mem_coefs         = np.empty((40, 2))*np.nan\n",
    "    \n",
    "    #define the starting years by random\n",
    "    if str(SIA['time'][0].values)[1] == '4': #then it's the coupled dataset\n",
    "        start_yrs = np.random.randint(400, 2200-time_period, 40) #generate random start dates\n",
    "    else:\n",
    "        start_yrs = np.random.randint(101, 1001-time_period, 40) #generate random start dates\n",
    "\n",
    "    #################### loop through all the 'members' ###################\n",
    "    for mem_i in range(40): \n",
    "        #define the years to select from the random start date\n",
    "        yr_list = np.arange(start_yrs[mem_i], start_yrs[mem_i]+time_period, 1)\n",
    "\n",
    "        #select the years from the SIA time series\n",
    "        SIA_mem[mem_i][:time_period] = SIA.sel(time=SIA['time.month']==month_).sel(time=slice(str(yr_list[0]).zfill(4),str(yr_list[-1]).zfill(4))).values\n",
    "        \n",
    "        #calculate the linear trend coefficients and compute the anomalies from the lienar trend\n",
    "        mem_coefs[mem_i] = np.polyfit(yr_list, SIA_mem[mem_i][:time_period], 1)\n",
    "        mem_anom[mem_i][:time_period] = SIA_mem[mem_i][:time_period] - (mem_coefs[mem_i][0] * yr_list + mem_coefs[mem_i][1])\n",
    "\n",
    "        ###################### compute the resamplings #########################            \n",
    "        sd_resamp1[mem_i]        = resample_boot1(time_period, mem_anom[mem_i][:time_period]).std('year_i')\n",
    "        sd_resamp_no_det1[mem_i] = resample_boot1(time_period, SIA_mem[mem_i][:time_period]).std('year_i')\n",
    "        sd_resamp2[mem_i]        = resample_boot2(time_period, mem_anom[mem_i][:time_period]).std('year_i')\n",
    "        sd_resamp_no_det2[mem_i] = resample_boot2(time_period, SIA_mem[mem_i][:time_period]).std('year_i')\n",
    "\n",
    "    output = xr.Dataset(data_vars={'sd_resamp1'        : (('member','resampling'), sd_resamp1),\n",
    "                                   'sd_resamp_no_det1' : (('member','resampling'), sd_resamp_no_det1),\n",
    "                                   'sd_resamp2'        : (('member','resampling'), sd_resamp2),\n",
    "                                   'sd_resamp_no_det2' : (('member','resampling'), sd_resamp_no_det2),\n",
    "                                   'SIA_mem'           : (('member','year_i'), SIA_mem),\n",
    "                                   'mem_anom'          : (('member','year_i'), mem_anom),\n",
    "                                   'mem_coefs'         : (('member', 'coef'), mem_coefs),\n",
    "                                   'start_yrs'        : (('member'), start_yrs)},\n",
    "                           \n",
    "                           coords={'member'     : np.arange(1,41,1), \n",
    "                                   'resampling' : np.arange(1,resample_n+1,1), \n",
    "                                   'year_i'     : np.arange(1,max_t+1,1),\n",
    "                                   'coef'       : ['gradient','intercept']})\n",
    "    \n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Dask to compute the resampling for all months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-10 17:47:12.226544 1\n",
      "2021-06-10 17:51:38.702983 2\n",
      "2021-06-10 17:56:06.151409 3\n",
      "2021-06-10 18:00:23.517518 4\n",
      "2021-06-10 18:05:04.253485 5\n",
      "2021-06-10 18:09:15.912360 6\n",
      "2021-06-10 18:13:57.209075 7\n",
      "2021-06-10 18:17:59.071629 8\n",
      "2021-06-10 18:22:28.026551 9\n",
      "2021-06-10 18:26:29.918819 10\n"
     ]
    }
   ],
   "source": [
    "#now try with dask for all months #N.B need to change the function, description, data source, and save path with slab verses coupled\n",
    "bootsize = 2\n",
    "resamp_n = 1000\n",
    "start_t = 6\n",
    "end_t = 300\n",
    "inc_t = 4\n",
    "\n",
    "month_ = 10 \n",
    "\n",
    "for run_ in np.arange(1,11,1):\n",
    "    print(datetime.datetime.now(), run_)\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "    for t_period in np.arange(start_t, end_t, inc_t):                  #pi_SIA pi_slab_SIA\n",
    "        result_list.append(dask.delayed(resample_1period_1month_matrix)(pi_slab_SIA, month_, resamp_n, t_period, end_t))\n",
    "        \n",
    "    results_computed = dask.compute(*result_list)\n",
    "    \n",
    "    results_computed = xr.concat((results_computed), dim='time_period')\n",
    "    results_computed['time_period'] = np.arange(start_t, end_t, inc_t) \n",
    "    \n",
    "    results_computed['sd_resamp1'].attrs        = {'Description': 'Standard deviation with respect to time for each detrended resampling, bootstrap size of 1 year'}\n",
    "    results_computed['sd_resamp_no_det1'].attrs = {'Description': 'Standard deviation with respect to time for each resampling without detrending, bootstrap size of 1 year'}\n",
    "    results_computed['sd_resamp2'].attrs        = {'Description': 'Standard deviation with respect to time for each detrended resampling, bootstrap size of 2 years'}\n",
    "    results_computed['sd_resamp_no_det2'].attrs = {'Description': 'Standard deviation with respect to time for each resampling without detrending, bootstrap size of 2 years'}\n",
    "    results_computed['SIA_mem'].attrs           = {'Description': 'The original ramdonly chosen SIA time series for each member without detrending or resampling'}\n",
    "    results_computed['mem_anom'].attrs          = {'Description': 'Anomalies of the SIA time series relative to a linear trend'}\n",
    "    results_computed['mem_coefs'].attrs         = {'Description': 'Gradient and y-intercept of the linear trend for each SIA time series'}\n",
    "    results_computed['start_yrs'].attrs         = {'Description': 'Randomly chosen start years for the SIA time series'}\n",
    "\n",
    "                                                                                   #coupled slab-ocean      \n",
    "    results_computed.attrs = {'Description': 'CESM 1 pre-industrial control (1850) slab-ocean run, northern hemisphere sea ice area, month of {}. 40 - so called - members are chosen from random start dates. The length of the times series used varies 6,10,14..298 years. 1000 resamplings are taken for each member'.format(month_names[month_-2]), \n",
    "                              'Units'      : 'Million square km',\n",
    "                              'Timestamp'  : str(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\")),                #b.e11.B1850C5CN.f09_g16.005 e.e11.E1850C5CN.f09_g16.001\n",
    "                              'Data source': '/glade/collections/cdg/data/cesmLE/CESM-CAM5-BGC-LE/ice/proc/tseries/monthly/aice/e.e11.E1850C5CN.f09_g16.001.cice.h.aice_nh.*.nc (doi:10.1175/BAMS-D-13-00255.1)',\n",
    "                              'Analysis'   : 'Python 3.7.9 - https://github.com/chrisrwp/obs-ensemble/CESM_pi_control.ipynb'}\n",
    "    \n",
    "    if month_ == 1:\n",
    "        true_month = '12'\n",
    "    else:\n",
    "        true_month = str(month_-1)\n",
    "                                                                                         #coupled slab                  \n",
    "    results_computed.to_netcdf('/glade/work/cwpowell/CLIVAR_area_extent_files/pi_control_slab_CESM_SD_time_month_{}_resampling_1000_run_{}.nc'.format(true_month.zfill(2), run_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL-3.7.9",
   "language": "python",
   "name": "npl-3.7.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
