{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "801af8ef-2e79-45b6-9097-12cd15cbd0f1",
   "metadata": {},
   "source": [
    "# Detrended SIA data, observations and models\n",
    "\n",
    "### Author: Chris Wyburn-Powell, [github](https://github.com/chrisrwp/synthetic-ensemble/SIA/SIA_calculations_observations.ipynb)\n",
    "\n",
    "**Input**: <br>\n",
    "Models:\n",
    "- SIA from CLIVAR LE archive `CLIVAR_SIA_1850_2100_RCP85.nc` <br>\n",
    "<br>\n",
    "Observations:\n",
    "- NSIDC CDR SIA (as interpolated and \n",
    "- Trends from NSIDC CDR SIA and mean trend for all datasets\n",
    "\n",
    "**Output**: <br>\n",
    "- **$\\sigma_{LE}$**  : Standard deviations of detrended models without resampling\n",
    "- **$\\sigma_{mem}$** : Standard deviations of detrended resampled models\n",
    "- **$\\sigma_{obs}$** : Standard deivations of detrended resampled observations\n",
    "\n",
    "\n",
    "**TO DO:** <br>\n",
    "- Select what observational data to detrend and resample. Look at variance between model ensemble members and see if using the average of the 5 obs datasets produces a similar uncertainty to the actual observed linear trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c7df4a0f-c26e-41b1-a60d-360be5b7404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "058465aa-1d04-4910-b91a-9a1d5d3d67aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/glade/scratch/cwpowell/Synthetic_ensemble/'\n",
    "\n",
    "model_names  = ['CanESM2', 'CESM1', 'CSIRO_MK36', 'GFDL_CM3', 'GFDL_ESM2M', 'MPI_ESM1' ]\n",
    "mem_len      = [50,        40,      30,           20,         30,           100        ]\n",
    "model_starts = [1950,      1920,    1850,         1920,       1950,         1850       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "982b3c6a-34e4-4115-8564-1fb71b6a38e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load observational data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#load model data\n",
    "SIA = xr.open_dataset(data_path+'SIA/SIA_SIE_SIV/CLIVAR_SIA_1850_2100_RCP85.nc')\n",
    "# SIE = xr.open_dataset(data_path+'SIA/SIA_SIE_SIV/CLIVAR_SIE_1850_2100_RCP85.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbe1bfe-4f49-4d57-b1ed-ccbdbe32dff9",
   "metadata": {},
   "source": [
    "# Define resampling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b370ec10-3a1e-4cbb-bebc-834f6b4c3e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_boot1(time_period, data):\n",
    "    '''\n",
    "    Resample a 1D time series using a 2 year block boostrap size\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    time_period : integer,\n",
    "        For 1979-2020 use 42 as the total number of years in that time period\n",
    "    data : 1 dimensional xarray dataarray,\n",
    "        For 1979-2020 this is an array of shape [42] \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "        2D xarray dataarray object of 1000 resamplings of the input data, shape: (time_period, 1000)\n",
    "    ''' \n",
    "    \n",
    "    resampled = np.random.choice(data, (time_period, 1000), replace=True)\n",
    "    \n",
    "    return(resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "66321625-777a-4bde-a4ae-1c9d496df3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_boot2(time_period, data):\n",
    "    '''\n",
    "    Resample a 1D time series using a 2 year block boostrap size with replacement\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    time_period : integer,\n",
    "        For 1979-2020 use 42 as the total number of years in that time period\n",
    "    data : 1 dimensional xarray dataarray,\n",
    "        For 1979-2020 this is an array of shape [42] \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "        2D xarray dataarray object of 1000 resamplings of the input data, shape: (time_period, 1000)\n",
    "    '''  \n",
    "    #create an xarray dataarray of indexes for half the length of the time period, year_i coordinates 1,3,5...\n",
    "    boot_2_first_ind = xr.DataArray(data   = np.random.randint(0,time_period-2, (1000,int(time_period/2))), \n",
    "                                    coords = {'resampling':np.arange(1,1001,1), 'year_i':np.arange(1,time_period+1,2)},\n",
    "                                    dims   = ['resampling', 'year_i'])\n",
    "\n",
    "    #create an identical dataarray but with each element incremented by 1, year_i coordinates 2,4,6....\n",
    "    boot_2_second_ind = (boot_2_first_ind+1).copy()\n",
    "    boot_2_second_ind['year_i'] = np.arange(2,time_period+2,2)\n",
    "\n",
    "    #concatenate the two arrays with the coordinates in order, this allows a 2 year block boostrap size\n",
    "    all_boot_2_ind = xr.concat((boot_2_first_ind, boot_2_second_ind), dim='year_i').sortby('year_i')\n",
    "    \n",
    "    #create an array with the starting element of the flattened array for each resampling 0, 42, 84...\n",
    "    ind_base = np.repeat(np.arange(0,time_period*1000,time_period),time_period)\n",
    "    \n",
    "    #add together the base indexes (0,42,84...) with the randomly chosen indexes within the original data\n",
    "    ind_1_d = np.ravel(all_boot_2_ind) + ind_base\n",
    "    \n",
    "    #copy the original data 1000 times as a 1D array so it will have the same indexes as we just made for ind_1_d\n",
    "    data_1000 = np.ravel(np.tile(data,(time_period,1000)))\n",
    "    \n",
    "    #select the randomly generated indexes from the flattened copied original data, reshape and save to xarray dataarray\n",
    "    resampled_boot_2 = xr.DataArray(data = np.reshape(data_1000[ind_1_d], (time_period,1000)),\n",
    "                                    coords = {'year_i':np.arange(1,time_period+1,1), 'resampling':np.arange(1,1001,1)},\n",
    "                                    dims   = ['year_i', 'resampling'])\n",
    "\n",
    "    return(resampled_boot_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfab5d94-c7d0-4a96-b525-06bb1acc9779",
   "metadata": {},
   "source": [
    "# Observations\n",
    "## Detrend all observational data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499e5ea8-219b-4c41-b6e6-1923628881af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#detrend based on own trend\n",
    "\n",
    "\n",
    "\n",
    "#detrend based on average trend from all observational data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807b364e-9f6f-47eb-93cb-cddb01009bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the detrended data to NetCDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db55ce73-0b5f-447f-9636-d3e986910305",
   "metadata": {},
   "source": [
    "## Resample all detrended observational data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd74c369-d65c-4e1c-b316-5d8422300eee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11872d7-d1e9-406a-bb08-77e7d93dcb41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c443f1b-db7b-463e-9f34-0aeecc340455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the resampled data to NetCDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e1041b-6df5-4db5-b359-5835c11bfba5",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "## Detrend model data using ensemble mean trends and individual member trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c8f7acf9-a727-478b-9921-1200a859ae39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-23 12:12:26.290036 CanESM2\n",
      "2021-06-23 12:12:26.418453 CESM1\n",
      "2021-06-23 12:12:26.551278 CSIRO_MK36\n",
      "2021-06-23 12:12:26.683126 GFDL_CM3\n",
      "2021-06-23 12:12:26.815022 GFDL_ESM2M\n",
      "2021-06-23 12:12:26.946902 MPI_ESM1\n"
     ]
    }
   ],
   "source": [
    "start_yr = 1979\n",
    "end_yr   = 2020\n",
    "\n",
    "all_model_detrend_ensemble   = {}\n",
    "all_model_detrend_individual = {}\n",
    "\n",
    "for model_i, model_name in enumerate(model_names):\n",
    "    print(datetime.datetime.now(), model_name)\n",
    "    \n",
    "    detrend_ensemble_list  = []\n",
    "    detrend_individual_list = []\n",
    "    \n",
    "    for month_ in np.arange(1,13):\n",
    "        \n",
    "        if model_name == 'MPI_ESM1': #100 elements in member dimension so can't select all of those for MPI ESM1\n",
    "            model_month = SIA[model_name].sel(time=SIA['time.month']==month_).sel(time=slice(str(start_yr),str(end_yr)))\n",
    "        else:\n",
    "            model_month = SIA[model_name].sel(time=SIA['time.month']==month_).sel(time=slice(str(start_yr),str(end_yr))).sel(member=slice('1',str(mem_len[model_i])))\n",
    "\n",
    "        #detrend all members by the ensemble mean trend\n",
    "        ensemble_coefs = np.polyfit(np.arange(start_yr, end_yr+1), model_month.mean('member').values, 1)\n",
    "        detrend_ensemble_list.append(model_month - (ensemble_coefs[0]*np.arange(start_yr, end_yr+1) + ensemble_coefs[1]))\n",
    "\n",
    "\n",
    "        #detrend the individual members with their own trend\n",
    "        yr_list = xr.DataArray(data = np.arange(1979,2021,1), coords={'time':model_month['time']}, dims=['time'])\n",
    "        \n",
    "        mem_coefs  = np.polyfit(np.arange(start_yr, end_yr+1), model_month.transpose().values, 1)\n",
    "        mem_coefs  = xr.DataArray(data = mem_coefs, coords={'coef':['grad', 'intercept'], 'member':np.arange(1,mem_len[model_i]+1)}, dims=['coef', 'member'])\n",
    "\n",
    "        detrend_individual_list.append(model_month - mem_coefs.sel(coef='grad')*yr_list + mem_coefs.sel(coef='intercept'))\n",
    "        \n",
    "    all_model_detrend_ensemble[model_name]   = xr.concat((detrend_ensemble_list), dim='time')\n",
    "    all_model_detrend_individual[model_name] = xr.concat((detrend_individual_list), dim='time')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "47b1cbbd-e610-48f7-94a6-f5a4caf7bc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save detrended SIA using ensemble trends\n",
    "all_model_detrend_ensemble   = xr.Dataset(all_model_detrend_ensemble)\n",
    "\n",
    "dict_attrs = {'Description': 'Detrended Arctic sea ice area (SIA) for the large ensemble models: CanESM2, CESM1, CSIRO MK3.6, GFDL CM3, GFDL ESM2M, MPI ESM1, 1979-2020. Ensemble mean trend is used to detrend each member', \n",
    "              'Units'      : 'million square km',\n",
    "              'Timestamp'  : str(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\")),\n",
    "              'Data source': 'CLIVAR Large Ensemble Archive, doi:10.1038/s41558-020-0731-2',\n",
    "              'Analysis'   : 'https://github.com/chrisrwp/synthetic-ensemble/SIA/SIC_detrending.ipynb'}\n",
    "\n",
    "all_model_detrend_ensemble.attrs = dict_attrs\n",
    "all_model_detrend_ensemble.to_netcdf(data_path+'SIA/SIA_detrended/CLIVAR_SIA_detrended_ensemble_79-20.nc')\n",
    "\n",
    "#save detrended SIA using individual trends\n",
    "all_model_detrend_individual = xr.Dataset(all_model_detrend_individual)\n",
    "individual_attrs = dict_attrs.copy()\n",
    "individual_attrs['Description'] = 'Detrended Arctic sea ice area (SIA) for the large ensemble models: CanESM2, CESM1, CSIRO MK3.6, GFDL CM3, GFDL ESM2M, MPI ESM1, 1979-2020. Each individual member trend is used to detrend'\n",
    "all_model_detrend_individual.attrs = individual_attrs\n",
    "all_model_detrend_ensemble.to_netcdf(data_path+'SIA/SIA_detrended/CLIVAR_SIA_detrended_individual_79-20.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5b5c23-c093-49bc-b450-51fa54264b55",
   "metadata": {},
   "source": [
    "## Resample models, 2 year bootstrap size, 1000 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c77eb6f-3632-4e98-a644-05400fdf8b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import detrended data\n",
    "detrend_ensemble   = xr.open_dataset(data_path+'SIA/SIA_detrended/CLIVAR_SIA_detrended_ensemble_79-20.nc')\n",
    "detrend_individual = xr.open_dataset(data_path+'SIA/SIA_detrended/CLIVAR_SIA_detrended_individual_79-20.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1882e9a4-0105-4a1b-80c2-cf76afd676ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the resamplings of all models and months\n",
    "#to change the bootstrap size, change the function names: [resample_boot2, resample_boot1]\n",
    "resampled_ensemble_model   = {}\n",
    "resampled_individual_model = {} \n",
    "\n",
    "for model_i, model_name in enumerate(model_names):\n",
    "    print(datetime.datetime.now(), model_name)\n",
    "    \n",
    "    resampled_ensemble_month   = []\n",
    "    resampled_individual_month = [] \n",
    "    \n",
    "    for month_ in np.arange(1,13):\n",
    "        \n",
    "        resampled_ensemble_member   = []\n",
    "        resampled_individual_member = [] \n",
    "        \n",
    "        for mem_ in np.arange(1,mem_len[model_i]+1):\n",
    "            #select a 1D array of detrended anomalies, resample these 1000 times for each member\n",
    "            resampled_ensemble_member.append(resample_boot2(42, detrend_ensemble[model_name].sel(time=detrend_ensemble['time.month']==month_).sel(member=mem_)))\n",
    "            resampled_individual_member.append(resample_boot2(42, detrend_individual[model_name].sel(time=detrend_ensemble['time.month']==month_).sel(member=mem_)))\n",
    "        \n",
    "        #concatenate all the member output data and append it to the list containing data for all months\n",
    "        resampled_ensemble_month.append(xr.concat((resampled_ensemble_member), dim='member'))\n",
    "        resampled_individual_month.append(xr.concat((resampled_individual_member), dim='member'))\n",
    "            \n",
    "    resampled_ensemble_model[model_name] = xr.concat((resampled_ensemble_month), dim='month')\n",
    "    resampled_individual_model[model_name] = xr.concat((resampled_individual_month), dim='month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e442c0c-f796-4034-bfeb-cc985a5861a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the resampled data to NetCDF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL-3.7.9",
   "language": "python",
   "name": "npl-3.7.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
