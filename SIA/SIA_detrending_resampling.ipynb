{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "380a2761-da4e-43a6-81d1-b1d47442af5c",
   "metadata": {},
   "source": [
    "# Detrending and resampling SIA data, observations and models\n",
    "\n",
    "### Author: Chris Wyburn-Powell, [github](https://github.com/chrisrwp/synthetic-ensemble/blob/main/SIA/SIA_detrending_resampling.ipynb)\n",
    "\n",
    "**Input**: <br>\n",
    "- Models: Arctic SIA from six models of the CLIVAR Large Ensemble archive (CanESM2, CESM1, CSIRO MK3.6, GFDL CM3, GFDL ESM2M, MPI ESM1), as computed in [another notebook](https://github.com/chrisrwp/synthetic-ensemble/blob/main/SIA/SIC_to_SIA_models.ipynb)\n",
    "- Observations: Arctic SIA from four observational datasets: Climate Data Record (CDR), NASA Bootstrap (BT), NASA Team (NT), Hadley Centre Sea Ice (HadISST1), as computed in  [another notebook](https://github.com/chrisrwp/synthetic-ensemble/blob/main/SIA/SIA_calculations_observations.ipynb)\n",
    "\n",
    "**Output**: <br>\n",
    "- Detrended SIA for models and observations using the individual datasets. For detrending relative to the average of all datasets for by using a jackknife analysis see a previous version of this notebook.\n",
    "- Resampled SIA 10,000 times wiht a 2 year bootstrap size\n",
    "- **$\\sigma_{LE}$**  : Standard deviations of detrended models without resampling\n",
    "- **$\\sigma_{mem}$** : Standard deviations of detrended resampled models\n",
    "- **$\\sigma_{obs}$** : Standard deivations of detrended resampled observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7df4a0f-c26e-41b1-a60d-360be5b7404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "058465aa-1d04-4910-b91a-9a1d5d3d67aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = '/glade/scratch/cwpowell/Synthetic_ensemble/'\n",
    "data_path = '/glade/campaign/univ/ucub0084/Synthetic_ensemble/'\n",
    "\n",
    "model_names  = ['CanESM2', 'CESM1', 'CSIRO_MK36', 'GFDL_CM3', 'GFDL_ESM2M', 'MPI_ESM1' ]\n",
    "mem_len      = [50,        40,      30,           20,         30,           100        ]\n",
    "model_starts = [1950,      1920,    1850,         1920,       1950,         1850       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "982b3c6a-34e4-4115-8564-1fb71b6a38e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load observational data\n",
    "CDR  = xr.open_dataset(data_path+'Raw_data/observations/NSIDC_CDR_v4/'\\\n",
    "                       +'SIA_SIE_CDR_BT_NT_79-20_filled.nc')\n",
    "HadISST1 = xr.open_dataset(data_path+'Raw_data/observations/HadISST/'\\\n",
    "                           +'HadISST1_SIA_SIE_79-20_filled.nc')\n",
    "\n",
    "obs_SIA = xr.Dataset({'CDR':CDR['CDR_SIA'].copy(), 'BT':CDR['BT_SIA'].copy(), \n",
    "                      'NT':CDR['NT_SIA'].copy(), \n",
    "                      'HadISST1':HadISST1['SIA'].copy()})\n",
    "\n",
    "obs_SIA_keys = list(obs_SIA.keys())\n",
    "\n",
    "#load model data\n",
    "SIA = xr.open_dataset(data_path+'SIA/SIA_SIE_SIV/CLIVAR_SIA_1850_2100_RCP85.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbe1bfe-4f49-4d57-b1ed-ccbdbe32dff9",
   "metadata": {},
   "source": [
    "# Define resampling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b370ec10-3a1e-4cbb-bebc-834f6b4c3e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_boot1(time_period, data):\n",
    "    '''\n",
    "    Resample a 1D time series using a 2 year block boostrap size \n",
    "    with replacement\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    time_period : integer,\n",
    "        For 1979-2020 use 42 as the total number of years in that time period\n",
    "    data : 1 dimensional xarray dataarray,\n",
    "        For 1979-2020 this is an array of shape [42] \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "        2D xarray dataarray object of 1000 resamplings of the input data, \n",
    "        shape: (time_period, 1000)\n",
    "    ''' \n",
    "    \n",
    "    resampled = np.random.choice(data, (time_period, 1000), replace=True)\n",
    "    \n",
    "    resampled = xr.DataArray(data = np.reshape(resampled, (1000, time_period)),\n",
    "                             coords = {'resampling':np.arange(1,1001,1), \n",
    "                                       'year_i':np.arange(1,time_period+1,1)},\n",
    "                             dims   = ['resampling', 'year_i'])\n",
    "    \n",
    "    return(resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66321625-777a-4bde-a4ae-1c9d496df3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_boot2(time_period, data):\n",
    "    '''\n",
    "    Resample a 1D time series using a 2 year block boostrap size \n",
    "    with replacement\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    time_period : integer,\n",
    "        For 1979-2020 use 42 as the total number of years in that time period\n",
    "    data : 1 dimensional xarray dataarray,\n",
    "        For 1979-2020 this is an array of shape [42] \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "        2D xarray dataarray object of 1000 resamplings of the input data, \n",
    "        shape: (time_period, 1000)\n",
    "    '''  \n",
    "    #create an xarray dataarray of indexes for half the length of the \n",
    "    #time period, year_i coordinates 1,3,5...\n",
    "    boot_2_first_ind = xr.DataArray(\n",
    "        data   = np.random.randint(0,time_period-2, (1000,int(time_period/2))), \n",
    "        coords = {'resampling':np.arange(1,1001,1), \n",
    "                  'year_i':np.arange(1,time_period+1,2)},\n",
    "        dims   = ['resampling', 'year_i'],\n",
    "    )\n",
    "\n",
    "    #create an identical dataarray but with each element incremented by 1,\n",
    "    #year_i coordinates 2,4,6....\n",
    "    boot_2_second_ind = (boot_2_first_ind+1).copy()\n",
    "    boot_2_second_ind['year_i'] = np.arange(2,time_period+2,2)\n",
    "\n",
    "    #concatenate the two arrays with the coordinates in order,\n",
    "    #this allows a 2 year block boostrap size\n",
    "    all_boot_2_ind = xr.concat((boot_2_first_ind, boot_2_second_ind), \n",
    "                               dim='year_i').sortby('year_i')\n",
    "    \n",
    "    #create an array with the starting element of the flattened array \n",
    "    #for each resampling 0, 42, 84...\n",
    "    ind_base = np.repeat(np.arange(0,time_period*1000,time_period),time_period)\n",
    "    \n",
    "    #add together the base indexes (0,42,84...) with the randomly chosen \n",
    "    #indexes within the original data\n",
    "    ind_1_d = np.ravel(all_boot_2_ind) + ind_base\n",
    "    \n",
    "    #copy the original data 1000 times as a 1D array so it will have the \n",
    "    #same indexes as we just made for ind_1_d\n",
    "    data_1000 = np.ravel(np.tile(data,(time_period,1000)))\n",
    "    \n",
    "    #select the randomly generated indexes from the flattened copied \n",
    "    #original data, reshape and save to xarray dataarray\n",
    "    resampled_boot_2 = xr.DataArray(\n",
    "        data = np.reshape(data_1000[ind_1_d], (1000, time_period)),\n",
    "        coords = {'resampling':np.arange(1,1001,1), \n",
    "                  'year_i':np.arange(1,time_period+1,1)},\n",
    "        dims   = ['resampling', 'year_i'],\n",
    "    )\n",
    "\n",
    "    return(resampled_boot_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfab5d94-c7d0-4a96-b525-06bb1acc9779",
   "metadata": {},
   "source": [
    "# Observations\n",
    "## Detrend all observational datasets using average observational trend and individual dataset trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "499e5ea8-219b-4c41-b6e6-1923628881af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#detrend observations based on own trend and the mean trend of the 6 datasets\n",
    "obs_detrend_individual = {}\n",
    "\n",
    "for key in obs_SIA_keys:   \n",
    "    detrend_individual_list = []\n",
    "    \n",
    "    for month_ in np.arange(1,13):\n",
    "        coefs = np.polyfit(np.arange(start_yr, end_yr+1), \n",
    "                           obs_SIA[key].sel(time=obs_SIA['time.month']==month_), 1)\n",
    "        detrend_individual_list.append(-1*(coefs[0]*np.arange(start_yr, end_yr+1) + coefs[1]) \n",
    "                                       + obs_SIA[key].sel(time=obs_SIA['time.month']==month_))\n",
    "        \n",
    "    obs_detrend_individual[key] = xr.concat((detrend_individual_list), dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1be3517d-0b5e-46ba-b69c-c7713148e914",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save detrended observations to NetCDF\n",
    "dict_attrs = {'Description': 'Detrended Arctic sea ice area (SIA) for six observational '\\\n",
    "                  +'datasets 1979-2020: Climate Data Record (CDR), NASA Bootstrap (BT),'\\\n",
    "                  +'NASA Team (NT), NSIDC Sea Ice Index (SII), Hadley Centre Sea Ice '\\\n",
    "                  +'(HadISST1), Merged Hadley NOAA Optimal Interpolation (Merged). '\\\n",
    "                  +'The trend for each month of each dataset is used for detrending.', \n",
    "              'Units'      : 'million square km',\n",
    "              'Timestamp'  : str(datetime.datetime.utcnow().strftime(\n",
    "                  \"%H:%M UTC %a %Y-%m-%d\")),\n",
    "              'Data source': 'DOIs - CRD, BT, NT:10.7265/efmz-2t65, '\\\n",
    "                  +'HadISST1:10.1029/2002JD002670',\n",
    "              'Analysis'   : 'https://github.com/chrisrwp/synthetic-ensemble/SIA/'\\\n",
    "                  +'SIA_detrending_resampling.ipynb'}\n",
    "\n",
    "#save detrended observations by individual trends\n",
    "obs_detrend_individual = xr.Dataset(obs_detrend_individual)\n",
    "obs_detrend_individual.attrs = dict_attrs\n",
    "obs_detrend_individual.to_netcdf(data_path+'SIA/SIA_detrended/Obs_SIA_detrended_individual_79-20.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db55ce73-0b5f-447f-9636-d3e986910305",
   "metadata": {},
   "source": [
    "## Resample all detrended observational data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd74c369-d65c-4e1c-b316-5d8422300eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import detrended data\n",
    "obs_detrend_individual  = xr.open_dataset(data_path+'SIA/SIA_detrended/Obs_SIA_detrended_individual_79-20.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d11872d7-d1e9-406a-bb08-77e7d93dcb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the resamplings of all observational datasets and months\n",
    "#to change the bootstrap size, change the function names: [resample_boot2, resample_boot1]\n",
    "\n",
    "for run in np.arange(1,11): #make repeated runs to add to randomness\n",
    "    print(datetime.datetime.now(), run)\n",
    "\n",
    "    obs_resample_individual = {}\n",
    "\n",
    "    for key in obs_SIA_keys:           \n",
    "        resampled_individual_month = []\n",
    "\n",
    "        for month_ in np.arange(1,13): #N.B. remember to change boot1 or boot2\n",
    "            resampled_individual_month.append(\n",
    "                resample_boot1(42, obs_detrend_individual[key].sel(\n",
    "                    time=obs_detrend_individual['time.month']==month_))\n",
    "            )\n",
    "\n",
    "        obs_resample_individual[key] = xr.concat((resampled_individual_month), dim='month')\n",
    "\n",
    "    obs_resample_individual = xr.Dataset(obs_resample_individual)\n",
    "    obs_resample_individual['month'] = np.arange(1,13)\n",
    "\n",
    "    #save the resampled data to NetCDF\n",
    "    dict_attrs = {'Description': 'Resampled Arctic sea ice area 1979-2020 for six datasets: '\\\n",
    "                      +'Climate Data Record (CDR), NASA Bootstrap (BT), NASA Team (NT), '\\\n",
    "                      +'Hadley Centre Sea Ice (HadISST1), The trend for each month for each '\n",
    "                      +'dataset is used for detrending, resampling is done 1000 times with a 1 year bootstrap size.', \n",
    "                  'Units'      : 'million square km',\n",
    "                  'Timestamp'  : str(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\")),\n",
    "                  'Data source': 'DOIs - CRD, BT, NT:10.7265/efmz-2t65, HadISST1:10.1029/2002JD002670',\n",
    "                  'Analysis'   : 'https://github.com/chrisrwp/synthetic-ensemble/SIA/'\\\n",
    "                      +'SIA_detrending_resampling.ipynb'}\n",
    "\n",
    "    #save resampled SIA using individual trends\n",
    "    obs_resample_individual = xr.Dataset(obs_resample_individual)\n",
    "    obs_resample_individual.attrs = dict_attrs\n",
    "    obs_resample_individual.to_netcdf(\n",
    "        '/glade/scratch/cwpowell/Synthetic_ensemble_revisions/SIA/SIA_resample'\\\n",
    "        +'d/Obs_SIA_resampled_individual_79-20_boot1_run{}.nc'.format(run))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e1041b-6df5-4db5-b359-5835c11bfba5",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "## Detrend model data using ensemble mean trends and individual member trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8f7acf9-a727-478b-9921-1200a859ae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_yr = 1979\n",
    "end_yr   = 2020\n",
    "\n",
    "all_model_detrend_ensemble   = {}\n",
    "all_model_detrend_individual = {}\n",
    "\n",
    "for model_i, model_name in enumerate(model_names):\n",
    "    \n",
    "    detrend_ensemble_list  = []\n",
    "    detrend_individual_list = []\n",
    "    \n",
    "    for month_ in np.arange(1,13):\n",
    "        \n",
    "        if model_name == 'MPI_ESM1': #100 members, sel can't work for MPI ESM1\n",
    "            model_month = SIA[model_name].sel(time=SIA['time.month']==month_).sel(\n",
    "                time=slice(str(start_yr),str(end_yr)))\n",
    "        else:\n",
    "            model_month = SIA[model_name].sel(time=SIA['time.month']==month_).sel(\n",
    "                time=slice(str(start_yr),str(end_yr))).sel(\n",
    "                member=slice('1',str(mem_len[model_i])))\n",
    "\n",
    "        #detrend all members by the ensemble mean trend\n",
    "        ensemble_coefs = np.polyfit(np.arange(start_yr, end_yr+1), \n",
    "                                    model_month.mean('member').values, 1)\n",
    "        detrend_ensemble_list.append(model_month - (ensemble_coefs[0]\n",
    "                                                    *np.arange(start_yr, end_yr+1) \n",
    "                                                    + ensemble_coefs[1])\n",
    "                                    )\n",
    "\n",
    "        #detrend the individual members with their own trend\n",
    "        yr_list = xr.DataArray(data = np.arange(1979,2021,1), \n",
    "                               coords={'time':model_month['time']}, \n",
    "                               dims=['time'])\n",
    "        \n",
    "        mem_coefs  = np.polyfit(np.arange(start_yr, end_yr+1), \n",
    "                                model_month.transpose().values, 1)\n",
    "        mem_coefs  = xr.DataArray(data = mem_coefs, \n",
    "                                  coords={'coef':['grad', 'intercept'],\n",
    "                                          'member':np.arange(1,mem_len[model_i]+1)}, \n",
    "                                  dims=['coef', 'member'])\n",
    "\n",
    "        detrend_individual_list.append(model_month \n",
    "                                       - (mem_coefs.sel(coef='grad')*yr_list \n",
    "                                          + mem_coefs.sel(coef='intercept'))\n",
    "                                      )\n",
    "        \n",
    "    all_model_detrend_ensemble[model_name]   = xr.concat((detrend_ensemble_list), \n",
    "                                                         dim='time')\n",
    "    all_model_detrend_individual[model_name] = xr.concat((detrend_individual_list), \n",
    "                                                         dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47b1cbbd-e610-48f7-94a6-f5a4caf7bc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save detrended SIA using ensemble trends\n",
    "all_model_detrend_ensemble   = xr.Dataset(all_model_detrend_ensemble)\n",
    "\n",
    "dict_attrs = {'Description': 'Detrended Arctic sea ice area (SIA) for the large'\\\n",
    "                  +'ensemble models: CanESM2, CESM1, CSIRO MK3.6, GFDL CM3, '\\\n",
    "                  +'GFDL ESM2M, MPI ESM1, 1979-2020. Ensemble mean trend is '\\\n",
    "                  +'used to detrend each member.', \n",
    "              'Units'      : 'million square km',\n",
    "              'Timestamp'  : str(datetime.datetime.utcnow().strftime(\n",
    "                  \"%H:%M UTC %a %Y-%m-%d\")),\n",
    "              'Data source': 'CLIVAR Large Ensemble Archive, '\\\n",
    "                  +'doi:10.1038/s41558-020-0731-2',\n",
    "              'Analysis'   : 'https://github.com/chrisrwp/synthetic-ensemble/'\\\n",
    "                  +'SIA/SIA_detrending_resampling.ipynb'}\n",
    "\n",
    "all_model_detrend_ensemble.attrs = dict_attrs\n",
    "all_model_detrend_ensemble.to_netcdf(data_path+'SIA/SIA_detrended/'\\\n",
    "                                     +'CLIVAR_SIA_detrended_ensemble_79-20.nc')\n",
    "\n",
    "#save detrended SIA using individual trends\n",
    "all_model_detrend_individual = xr.Dataset(all_model_detrend_individual)\n",
    "\n",
    "individual_attrs = dict_attrs.copy()\n",
    "individual_attrs['Description'] = 'Detrended Arctic sea ice area (SIA) for '\\\n",
    "    +'the large ensemble models: CanESM2, CESM1, CSIRO MK3.6, GFDL CM3, '\\\n",
    "    +'GFDL ESM2M, MPI ESM1, 1979-2020. Each individual member trend is used '\\\n",
    "    +'to detrend.'\n",
    "\n",
    "all_model_detrend_individual.attrs = individual_attrs\n",
    "all_model_detrend_individual.to_netcdf(\n",
    "    data_path+'SIA/SIA_detrended/CLIVAR_SIA_detrended_individual_79-20.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5b5c23-c093-49bc-b450-51fa54264b55",
   "metadata": {},
   "source": [
    "## Resample models, 1 or 2 year bootstrap size, 1000 times and run it 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c77eb6f-3632-4e98-a644-05400fdf8b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import detrended data\n",
    "# detrend_ensemble   = xr.open_dataset(data_path+'SIA/SIA_detrended/CLIVAR_SIA_detrended_ensemble_79-20.nc')\n",
    "detrend_individual = xr.open_dataset(data_path+'SIA/SIA_detrended/CLIVAR_SIA_detrended_individual_79-20.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1882e9a4-0105-4a1b-80c2-cf76afd676ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-18 15:00:59.040626 CanESM2\n",
      "2022-04-18 15:01:01.373574 CESM1\n",
      "2022-04-18 15:01:03.185813 CSIRO_MK36\n",
      "2022-04-18 15:01:04.629062 GFDL_CM3\n",
      "2022-04-18 15:01:05.556271 GFDL_ESM2M\n",
      "2022-04-18 15:01:06.888336 MPI_ESM1\n"
     ]
    }
   ],
   "source": [
    "#calculate the resamplings of all models and months\n",
    "#to change the bootstrap size, change the function names: [resample_boot2, resample_boot1]\n",
    "# resampled_ensemble_model   = {}\n",
    "resampled_individual_model = {} \n",
    "\n",
    "for model_i, model_name in enumerate(model_names):\n",
    "    print(datetime.datetime.now(), model_name)\n",
    "    \n",
    "#     resampled_ensemble_month   = []\n",
    "    resampled_individual_month = [] \n",
    "    \n",
    "    for month_ in np.arange(1,13):\n",
    "        \n",
    "#         resampled_ensemble_member   = []\n",
    "        resampled_individual_member = [] \n",
    "        \n",
    "        for mem_ in np.arange(1,mem_len[model_i]+1):\n",
    "            #select a 1D array of detrended anomalies, resample these 1000 times for each member\n",
    "            # resampled_ensemble_member.append(\n",
    "            #     resample_boot2(42, detrend_ensemble[model_name].sel(\n",
    "            #         time=detrend_ensemble['time.month']==month_).sel(member=mem_)))\n",
    "            resampled_individual_member.append(\n",
    "                resample_boot1(42, detrend_individual[model_name].sel(\n",
    "                    time=detrend_individual['time.month']==month_).sel(member=mem_)))\n",
    "        \n",
    "        #concatenate all the member output data and append it to the list containing data for all months\n",
    "#         resampled_ensemble_month.append(xr.concat((resampled_ensemble_member), dim='member'))\n",
    "        resampled_individual_month.append(xr.concat((resampled_individual_member), dim='member'))\n",
    "            \n",
    "#     resampled_ensemble_model[model_name] = xr.concat((resampled_ensemble_month), dim='month')\n",
    "#     resampled_ensemble_model[model_name]['member'] = np.arange(1,mem_len[model_i]+1)\n",
    "    resampled_individual_model[model_name] = xr.concat((resampled_individual_month), dim='month')\n",
    "    resampled_individual_model[model_name]['member'] = np.arange(1,mem_len[model_i]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7e442c0c-f796-4034-bfeb-cc985a5861a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the resampled data to NetCDF\n",
    "# resampled_ensemble_model   = xr.Dataset(resampled_ensemble_model)\n",
    "# resampled_ensemble_model['month'] = np.arange(1,13)\n",
    "\n",
    "dict_attrs = {'Description': 'Resampled Arctic sea ice area (SIA) for the large'\\\n",
    "                  +'ensemble models: CanESM2, CESM1, CSIRO MK3.6, GFDL CM3, '\\\n",
    "                  +'GFDL ESM2M, MPI ESM1, 1979-2020. Ensemble mean trend is '\\\n",
    "                  +'used to detrend each member. Resampling is done 1000 times'\\\n",
    "                  +'with a 1 year bootstrap size.', \n",
    "              'Units'      : 'million square km',\n",
    "              'Timestamp'  : str(datetime.datetime.utcnow().strftime(\n",
    "                  \"%H:%M UTC %a %Y-%m-%d\")),\n",
    "              'Data source': 'CLIVAR Large Ensemble Archive, '\\\n",
    "                  +'doi:10.1038/s41558-020-0731-2',\n",
    "              'Analysis'   : 'https://github.com/chrisrwp/synthetic-ensemble/'\\\n",
    "                  +'SIA/SIA_detrending_resampling.ipynb'}\n",
    "\n",
    "# resampled_ensemble_model.attrs = dict_attrs\n",
    "# resampled_ensemble_model.to_netcdf(\n",
    "#     data_path+'SIA/SIA_resampled/CLIVAR_SIA_resampled_ensemble_79-20_run2.nc')\n",
    "\n",
    "#save detrended SIA using individual trends\n",
    "resampled_individual_model = xr.Dataset(resampled_individual_model)\n",
    "resampled_individual_model['month'] = np.arange(1,13)\n",
    "individual_attrs = dict_attrs.copy()\n",
    "\n",
    "# individual_attrs['Description'] = 'Resampled Arctic sea ice area (SIA) for the'\\\n",
    "#     +' large ensemble models: CanESM2, CESM1, CSIRO MK3.6, GFDL CM3, '\\\n",
    "#     +'GFDL ESM2M, MPI ESM1, 1979-2020. Each individual member trend is used '\\\n",
    "#     +'to detrend. Resampling is done 1000 times with a 2 year bootstrap size.'\n",
    "\n",
    "resampled_individual_model.attrs = individual_attrs\n",
    "\n",
    "# resampled_individual_model.to_netcdf(\n",
    "#     data_path+'SIA/SIA_resampled/CLIVAR_SIA_resampled_individual_79-20_run1.nc')\n",
    "\n",
    "resampled_individual_model.std('year_i').to_netcdf(\n",
    "    '/glade/scratch/cwpowell/Synthetic_ensemble_revisions/SIA/SIA_resampled/'\\\n",
    "        +'Sigma_mem_individual_79-20_boot1_run10.nc')\n",
    "\n",
    "resampled_individual_model.mean('year_i').to_netcdf(\n",
    "    '/glade/scratch/cwpowell/Synthetic_ensemble_revisions/SIA/SIA_resampled/'\\\n",
    "        +'Mu_mem_individual_79-20_boot1_run10.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6345f09-ef06-4a9e-a0ee-0a05f557e01e",
   "metadata": {},
   "source": [
    "## Compute SD time with 10 runs for 10,000 resamplings in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ea85648-b325-442c-8a39-d270cfa9f22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs_models = []\n",
    "all_runs_obs = []\n",
    "\n",
    "for run in np.arange(1,11): #loop through the 10 files of 1000 random resamplings each\n",
    "    if run == 1:\n",
    "        resampled_models = xr.open_dataset(data_path+'SIA/SIA_resampled/CLIVAR_SIA_resampled_individual_79-20.nc')\n",
    "        resampled_obs = xr.open_dataset(data_path+'SIA/SIA_resampled/Obs_SIA_resampled_individual_79-20.nc')\n",
    "    else:\n",
    "        resampled_models = xr.open_dataset(data_path+'SIA/SIA_resampled/CLIVAR_SIA_resampled_individual_79-20_run{}.nc'.format(run))\n",
    "        resampled_obs = xr.open_dataset(data_path+'SIA/SIA_resampled/Obs_SIA_resampled_individual_79-20_run{}.nc'.format(run))\n",
    "    \n",
    "    SD_time_models = resampled_models.std('year_i')\n",
    "    SD_time_models['resampling'] = np.arange((run-1)*1000 +1, run*1000 +1) #uniquely index the resamplings\n",
    "    all_runs_models.append(SD_time_models)\n",
    "    \n",
    "    SD_time_obs = resampled_obs.std('year_i')\n",
    "    SD_time_obs['resampling'] = np.arange((run-1)*1000 +1, run*1000 +1) #uniquely index the resamplings\n",
    "    all_runs_obs.append(SD_time_obs)\n",
    "\n",
    "# all_runs_models = xr.concat((all_runs_models), dim='resampling')\n",
    "all_runs_obs    = xr.concat((all_runs_obs), dim='resampling')\n",
    "\n",
    "#compute the standard deviation and mean across resamplings\n",
    "sigma_mem_10000 = all_runs_models.std('resampling')\n",
    "mu_mem_10000    = all_runs_models.mean('resampling')\n",
    "\n",
    "sigma_obs_10000 = all_runs_obs.std('resampling')\n",
    "mu_obs_10000    = all_runs_obs.mean('resampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a39150b-7936-424f-8ec2-ac9f6dcd8bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to netcdf with attributes\n",
    "sigma_attrs_dict = {\n",
    "    'Description': 'Variability of Arctic sea ice area (SIA) of six large '\\\n",
    "        +'ensembles 1979-2020 (CanESM2, CESM1, CSIRO MK3.6, GFDL CM3, '\\\n",
    "        +'GFDL ESM2M, MPI ESM1). Standard deviation with respect to 10000 '\\\n",
    "        +'resamplings with a 2 year bootstrap size. Detrending was based on '\\\n",
    "        +'the single model ensemble mean trend.', \n",
    "    'Units'      : 'million square km',\n",
    "    'Timestamp'  : str(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\")),\n",
    "    'Data source': 'CLIVAR Large Ensemble Archive, doi:10.1038/s41558-020-0731-2',\n",
    "    'Analysis'   : 'https://github.com/chrisrwp/synthetic-ensemble/SIA/'\\\n",
    "        +'SIA_detrending_resampling.ipynb'\n",
    "}\n",
    "\n",
    "mu_attrs_dict = sigma_attrs_dict.copy()\n",
    "mu_attrs_dict['Description'] = 'Variability of Arctic sea ice area (SIA) of '\\\n",
    "    +'six large ensembles 1979-2020 (CanESM2, CESM1, CSIRO MK3.6, GFDL CM3, '\\\n",
    "    +'GFDL ESM2M, MPI ESM1). Mean of 10000 resamplings with a 2 year '\\\n",
    "    +'bootstrap size. Detrending was based on the single model ensemble mean trend.', \n",
    "\n",
    "sigma_mem_10000.attrs = sigma_attrs_dict\n",
    "sigma_mem_10000.to_netcdf(data_path+'SIA/SIA_resampled/Sigma_mem_individual_10000.nc')\n",
    "\n",
    "mu_mem_10000.attrs = mu_attrs_dict\n",
    "mu_mem_10000.to_netcdf(data_path+'SIA/SIA_resampled/Mu_mem_individual_10000.nc')\n",
    "\n",
    "#save sigma and mu obs\n",
    "sigma_obs_attrs = sigma_attrs_dict.copy()\n",
    "sigma_obs_attrs['Description'] = 'Variability of Arctic sea ice area (SIA) of '\\\n",
    "    +'four observational datasets 1979-2020 (six datasets: Climate Data Record'\\\n",
    "    +'(CDR), NASA Bootstrap (BT), NASA Team (NT), Hadley Centre Sea Ice'\\\n",
    "    +'(HadISST1). Standard deviation with respect to the standard'\\\n",
    "    +'deviation with respect to time for each 10000 resamplings with a 2 year'\\\n",
    "    +'bootstrap size. Detrending was based on the trend of the individual dataset.' \n",
    "\n",
    "sigma_obs_attrs['Data source'] = 'DOIs - CRD, BT, NT:10.7265/efmz-2t65, '\\\n",
    "    +'HadISST1:10.1029/2002JD002670'\n",
    "\n",
    "sigma_obs_10000.attrs = sigma_obs_attrs\n",
    "sigma_obs_10000.to_netcdf(\n",
    "    data_path+'SIA/SIA_resampled/Sigma_obs_individual_10000.nc')\n",
    "\n",
    "mu_obs_attrs = sigma_obs_attrs.copy()\n",
    "mu_obs_attrs['Description'] = 'Variability of Arctic sea ice area (SIA) of '\\\n",
    "    +'four observational datasets 1979-2020 (Climate Data Record (CDR), \n",
    "    +'NASA Bootstrap (BT), NASA Team (NT), Hadley Centre Sea Ice (HadISST1).'\\\n",
    "    +'Mean of the standard deviation with respect to time for each 10000 '\\\n",
    "    +'resamplings with a 2 year bootstrap size. Detrending was based on the '\\\n",
    "    +'trend of the individual dataset.'\n",
    "mu_obs_10000.attrs = mu_obs_attrs\n",
    "mu_obs_10000.to_netcdf(data_path+'SIA/SIA_resampled/Mu_obs_individual_10000.nc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9bc83e-f75f-43f6-9a83-e329a4ec3368",
   "metadata": {},
   "source": [
    "# $\\sigma_{LE}$ , $\\sigma_{mem}$ , $\\sigma_{obs}$ calculations\n",
    "## $\\sigma_{LE}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5b52758-82de-4fe2-ba5c-b763d9d48e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load detrended model data\n",
    "detrend_ensemble   = xr.open_dataset(\n",
    "    data_path+'SIA/SIA_detrended/CLIVAR_SIA_detrended_ensemble_79-20.nc')\n",
    "\n",
    "detrend_individual = xr.open_dataset(\n",
    "    data_path+'SIA/SIA_detrended/CLIVAR_SIA_detrended_individual_79-20.nc')\n",
    "\n",
    "#compute standard deviation along the member dimension\n",
    "sigma_LE_ensemble   = detrend_ensemble.groupby('time.month').std('time').std('member')\n",
    "sigma_LE_individual = detrend_individual.groupby('time.month').std('time').std('member')\n",
    "\n",
    "#save to NetCDF\n",
    "attrs_dict = {\n",
    "    'Description': 'Variability of Arctic sea ice area (SIA) of six large '\\\n",
    "        +'ensembles 1979-2020 (CanESM2, CESM1, CSIRO MK3.6, GFDL CM3, GFDL ESM2M, '\\\n",
    "        +'MPI ESM1). Standard deviation with respect to members. Computed on the '\\\n",
    "        +'detrended standard deviations with respect to time for each month. '\\\n",
    "        +'Detrending was based on the single model ensemble mean trend.', \n",
    "    'Units'      : 'million square km',\n",
    "    'Timestamp'  : str(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\")),\n",
    "    'Data source': 'CLIVAR Large Ensemble Archive, doi:10.1038/s41558-020-0731-2',\n",
    "    'Analysis'   : 'https://github.com/chrisrwp/synthetic-ensemble/SIA/'\\\n",
    "    +'SIA_detrending_resampling.ipynb'\n",
    "}\n",
    "\n",
    "sigma_LE_ensemble.attrs = attrs_dict\n",
    "sigma_LE_ensemble.to_netcdf(\n",
    "    data_path+'SIA/SIA_resampled/Sigma_LE_ensemble_79-20.nc')\n",
    "\n",
    "ind_attrs_dict = attrs_dict.copy()\n",
    "ind_attrs_dict['Description'] = 'Variability of Arctic sea ice area (SIA) of '\\\n",
    "    +'six large ensembles 1979-2020 (CanESM2, CESM1, CSIRO MK3.6, GFDL CM3, '\\\n",
    "    +'GFDL ESM2M, MPI ESM1). Standard deviation with respect members. '\\\n",
    "    +'Computed on the detrended standard deviations with respect to time for '\\\n",
    "    +'each month. Detrending was based on the individual member trend.' \n",
    "\n",
    "sigma_LE_individual.attrs = ind_attrs_dict\n",
    "sigma_LE_individual.to_netcdf(\n",
    "    data_path+'SIA/SIA_resampled/Sigma_LE_individual_79-20.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59d6c78-405e-451c-b285-ed6b14a62a1b",
   "metadata": {},
   "source": [
    "## $\\sigma_{mem}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20290a35-4fbe-4338-963e-c2c1c159fab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load resampled model data\n",
    "resampled_ensemble   = xr.open_dataset(\n",
    "    data_path+'SIA/SIA_resampled/CLIVAR_SIA_resampled_ensemble_79-20.nc')\n",
    "resampled_individual = xr.open_dataset(\n",
    "    data_path+'SIA/SIA_resampled/CLIVAR_SIA_resampled_individual_79-20.nc')\n",
    "\n",
    "#compute standard deviation along the resampling dimension\n",
    "sigma_mem_ensemble   = resampled_ensemble.std('year_i').std('resampling')\n",
    "sigma_mem_individual = resampled_individual.std('year_i').std('resampling')\n",
    "\n",
    "#save to NetCDF\n",
    "attrs_dict = {'Description': 'Variability of Arctic sea ice area (SIA) of six '\\\n",
    "                  +'large ensembles 1979-2020 (CanESM2, CESM1, CSIRO MK3.6, '\\\n",
    "                  +'GFDL CM3, GFDL ESM2M, MPI ESM1). Standard deviation with '\\\n",
    "                  +'respect to 1000 resamplings. Computed on the detrended '\\\n",
    "                  +'standard deviations with respect to time for each month. '\\\n",
    "                  +'Detrending was based on the single model ensemble mean trend.', \n",
    "              'Units'      : 'million square km',\n",
    "              'Timestamp'  : str(datetime.datetime.utcnow().strftime(\n",
    "                  \"%H:%M UTC %a %Y-%m-%d\")),\n",
    "              'Data source': 'CLIVAR Large Ensemble Archive, '\\\n",
    "                  +'doi:10.1038/s41558-020-0731-2',\n",
    "              'Analysis'   : 'https://github.com/chrisrwp/synthetic-ensemble/'\\\n",
    "                  +'SIA/SIA_detrending_resampling.ipynb'}\n",
    "\n",
    "sigma_mem_ensemble.attrs = attrs_dict\n",
    "sigma_mem_ensemble.to_netcdf(\n",
    "    data_path+'SIA/SIA_resampled/Sigma_mem_ensemble_79-20.nc')\n",
    "\n",
    "ind_attrs_dict = attrs_dict.copy()\n",
    "ind_attrs_dict['Description'] = 'Variability of Arctic sea ice area (SIA) of '\\\n",
    "    +'six large ensembles 1979-2020 (CanESM2, CESM1, CSIRO MK3.6, GFDL CM3, '\\\n",
    "    +'GFDL ESM2M, MPI ESM1). Standard deviation with respect to 1000 '\\\n",
    "    +'resamplings. Computed on the detrended standard deviations with respect '\\\n",
    "    +'to time for each month. Detrending was based on the individual member trend.' \n",
    "sigma_mem_individual.attrs = ind_attrs_dict\n",
    "sigma_mem_individual.to_netcdf(\n",
    "    data_path+'SIA/SIA_resampled/Sigma_mem_individual_79-20.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8b17a1-5c8b-4001-960e-32577b693652",
   "metadata": {},
   "source": [
    "## $\\sigma_{obs}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7df5874-bf2d-4939-8e06-5dab1c8a82bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load resampled observational data\n",
    "obs_resample_individual = xr.open_dataset(\n",
    "    data_path+'SIA/SIA_resampled/Obs_SIA_resampled_individual_79-20.nc')\n",
    "\n",
    "#compute standard deviation along the resampling dimension\n",
    "sigma_obs_individual = obs_resample_individual.std('year_i').std('resampling')\n",
    "\n",
    "#save to NetCDF\n",
    "attrs_dict = {'Description': 'Variability of Arctic sea ice area (SIA) '\\\n",
    "                  +'observations 1979-2020. Standard deviation with respect to'\\\n",
    "                  +'1000 resamplings. Computed on the detrended standard '\\\n",
    "                  +'deviations with respect to time for each month. Detrending'\\\n",
    "                  +' was based on the mean dataset trend.', \n",
    "              'Units'      : 'million square km',\n",
    "              'Timestamp'  : str(datetime.datetime.utcnow().strftime(\n",
    "                  \"%H:%M UTC %a %Y-%m-%d\")),\n",
    "              'Data source': 'DOIs - CRD, BT, NT:10.7265/efmz-2t65, '\\\n",
    "                  +'HadISST1:10.1029/2002JD002670',\n",
    "              'Analysis'   : 'https://github.com/chrisrwp/synthetic-ensemble/'\\\n",
    "                  +'SIA/SIA_detrending_resampling.ipynb'}\n",
    "\n",
    "#save sigma_obs individual\n",
    "ind_attrs_dict = attrs_dict.copy()\n",
    "ind_attrs_dict['Description'] = 'Variability of Arctic sea ice area (SIA) '\\\n",
    "    +'observations 1979-2020. Standard deviation with respect to 1000 '\\\n",
    "    +'resamplings. Computed on the detrended standard deviations with respect '\\\n",
    "    +'to time for each month. Detrending was based on the individual dataset trend.' \n",
    "\n",
    "sigma_obs_individual.attrs = ind_attrs_dict\n",
    "sigma_obs_individual.to_netcdf(\n",
    "    data_path+'SIA/SIA_resampled/Sigma_obs_individual_79-20.nc')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL-3.7.9",
   "language": "python",
   "name": "npl-3.7.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
