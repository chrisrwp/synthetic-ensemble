{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "380a2761-da4e-43a6-81d1-b1d47442af5c",
   "metadata": {},
   "source": [
    "# Detrending and resampling SIA data, observations and models\n",
    "\n",
    "### Author: Chris Wyburn-Powell, [github](https://github.com/chrisrwp/synthetic-ensemble/SIA/SIA_detrending_resampling.ipynb)\n",
    "\n",
    "**Input**: <br>\n",
    "- Models: Arctic SIA from six models of the CLIVAR Large Ensemble archive (CanESM2, CESM1, CSIRO MK3.6, GFDL CM3, GFDL ESM2M, MPI ESM1), as computed in [another notebook](https://github.com/chrisrwp/synthetic-ensemble/SIA/SIC_to_SIA_models.ipynb)\n",
    "- Observations: Arctic SIA from size observational datasets: Climate Data Record (CDR), NASA Bootstrap (BT), NASA Team (NT), NSIDC Sea Ice Index (SII), Hadley Centre Sea Ice (HadISST1), Merged Hadley NOAA Optimal Interpolation (Merged), as computed in  [another notebook](https://github.com/chrisrwp/synthetic-ensemble/SIA/SIA_calculations_observations.ipynb)\n",
    "\n",
    "**Output**: <br>\n",
    "- Detrended SIA for models and observations using the individual datasets or member or the average observational dataset or ensemble mean\n",
    "- Resampled SIA 1000 times wiht a 2 year bootstrap size\n",
    "- **$\\sigma_{LE}$**  : Standard deviations of detrended models without resampling\n",
    "- **$\\sigma_{mem}$** : Standard deviations of detrended resampled models\n",
    "- **$\\sigma_{obs}$** : Standard deivations of detrended resampled observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7df4a0f-c26e-41b1-a60d-360be5b7404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "058465aa-1d04-4910-b91a-9a1d5d3d67aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/glade/scratch/cwpowell/Synthetic_ensemble/'\n",
    "\n",
    "model_names  = ['CanESM2', 'CESM1', 'CSIRO_MK36', 'GFDL_CM3', 'GFDL_ESM2M', 'MPI_ESM1' ]\n",
    "mem_len      = [50,        40,      30,           20,         30,           100        ]\n",
    "model_starts = [1950,      1920,    1850,         1920,       1950,         1850       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "982b3c6a-34e4-4115-8564-1fb71b6a38e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load observational data\n",
    "CDR  = xr.open_dataset(data_path+'Raw_data/observations/NSIDC_CDR_v4/SIA_SIE_CDR_BT_NT_79-20_filled.nc')\n",
    "SII      = xr.open_dataset(data_path+'Raw_data/observations/NSIDC_sea_ice_index_v3/NSIDC_sea_ice_index_SIA_SIE_79-20_filled_including_pole_hole.nc')\n",
    "HadISST1 = xr.open_dataset(data_path+'Raw_data/observations/HadISST/HadISST1_SIA_SIE_79-20_filled.nc')\n",
    "Merged   = xr.open_dataset(data_path+'Raw_data/observations/merged_Hadley_OI/merged_Hadley_OI_SIA_SIE_79-20.nc')\n",
    "\n",
    "obs_SIA = xr.Dataset({'CDR':CDR['CDR_SIA'].copy(), 'BT':CDR['BT_SIA'].copy(), 'NT':CDR['NT_SIA'].copy(), \n",
    "                     'SII':SII['SIA'].copy(), 'HadISST1':HadISST1['SIA'].copy(), 'Merged':Merged['SIA'].copy()})\n",
    "\n",
    "obs_SIA_keys = list(obs_SIA.keys())\n",
    "\n",
    "#load model data\n",
    "SIA = xr.open_dataset(data_path+'SIA/SIA_SIE_SIV/CLIVAR_SIA_1850_2100_RCP85.nc')\n",
    "# SIE = xr.open_dataset(data_path+'SIA/SIA_SIE_SIV/CLIVAR_SIE_1850_2100_RCP85.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbe1bfe-4f49-4d57-b1ed-ccbdbe32dff9",
   "metadata": {},
   "source": [
    "# Define resampling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b370ec10-3a1e-4cbb-bebc-834f6b4c3e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_boot1(time_period, data):\n",
    "    '''\n",
    "    Resample a 1D time series using a 2 year block boostrap size\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    time_period : integer,\n",
    "        For 1979-2020 use 42 as the total number of years in that time period\n",
    "    data : 1 dimensional xarray dataarray,\n",
    "        For 1979-2020 this is an array of shape [42] \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "        2D xarray dataarray object of 1000 resamplings of the input data, shape: (time_period, 1000)\n",
    "    ''' \n",
    "    \n",
    "    resampled = np.random.choice(data, (time_period, 1000), replace=True)\n",
    "    \n",
    "    return(resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66321625-777a-4bde-a4ae-1c9d496df3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_boot2(time_period, data):\n",
    "    '''\n",
    "    Resample a 1D time series using a 2 year block boostrap size with replacement\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    time_period : integer,\n",
    "        For 1979-2020 use 42 as the total number of years in that time period\n",
    "    data : 1 dimensional xarray dataarray,\n",
    "        For 1979-2020 this is an array of shape [42] \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "        2D xarray dataarray object of 1000 resamplings of the input data, shape: (time_period, 1000)\n",
    "    '''  \n",
    "    #create an xarray dataarray of indexes for half the length of the time period, year_i coordinates 1,3,5...\n",
    "    boot_2_first_ind = xr.DataArray(data   = np.random.randint(0,time_period-2, (1000,int(time_period/2))), \n",
    "                                    coords = {'resampling':np.arange(1,1001,1), 'year_i':np.arange(1,time_period+1,2)},\n",
    "                                    dims   = ['resampling', 'year_i'])\n",
    "\n",
    "    #create an identical dataarray but with each element incremented by 1, year_i coordinates 2,4,6....\n",
    "    boot_2_second_ind = (boot_2_first_ind+1).copy()\n",
    "    boot_2_second_ind['year_i'] = np.arange(2,time_period+2,2)\n",
    "\n",
    "    #concatenate the two arrays with the coordinates in order, this allows a 2 year block boostrap size\n",
    "    all_boot_2_ind = xr.concat((boot_2_first_ind, boot_2_second_ind), dim='year_i').sortby('year_i')\n",
    "    \n",
    "    #create an array with the starting element of the flattened array for each resampling 0, 42, 84...\n",
    "    ind_base = np.repeat(np.arange(0,time_period*1000,time_period),time_period)\n",
    "    \n",
    "    #add together the base indexes (0,42,84...) with the randomly chosen indexes within the original data\n",
    "    ind_1_d = np.ravel(all_boot_2_ind) + ind_base\n",
    "    \n",
    "    #copy the original data 1000 times as a 1D array so it will have the same indexes as we just made for ind_1_d\n",
    "    data_1000 = np.ravel(np.tile(data,(time_period,1000)))\n",
    "    \n",
    "    #select the randomly generated indexes from the flattened copied original data, reshape and save to xarray dataarray\n",
    "    resampled_boot_2 = xr.DataArray(data = np.reshape(data_1000[ind_1_d], (1000, time_period)),\n",
    "                                    coords = {'resampling':np.arange(1,1001,1), 'year_i':np.arange(1,time_period+1,1)},\n",
    "                                    dims   = ['resampling', 'year_i'])\n",
    "\n",
    "    return(resampled_boot_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfab5d94-c7d0-4a96-b525-06bb1acc9779",
   "metadata": {},
   "source": [
    "# Observations\n",
    "## Detrend all observational datasets using average observational trend and individual dataset trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "362cd37e-4959-46f0-b493-cb3c92547e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the average trends\n",
    "start_yr = 1979\n",
    "end_yr   = 2020\n",
    "\n",
    "#calculate the average observations and its trend\n",
    "obs_mean = (obs_SIA['CDR'] + obs_SIA['BT'] + obs_SIA['NT'] + obs_SIA['SII'] + obs_SIA['HadISST1'] + obs_SIA['Merged']) / 6\n",
    "\n",
    "mean_trends = []\n",
    "for month_ in np.arange(1,13,1):\n",
    "    mean_coefs = np.polyfit(np.arange(start_yr, end_yr+1), obs_mean.sel(time=obs_mean['time.month']==month_).values, 1)\n",
    "    mean_trend = (mean_coefs[0]*np.arange(start_yr, end_yr+1) + mean_coefs[1])\n",
    "    mean_trends.append(xr.DataArray(data = mean_trend, coords={'time':obs_mean['time'].sel(time=obs_mean['time.month']==month_)}, dims=['time']))\n",
    "\n",
    "mean_trends = xr.concat((mean_trends), dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "499e5ea8-219b-4c41-b6e6-1923628881af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#detrend observations based on own trend and the mean trend of the 6 datasets\n",
    "obs_detrend_individual = {}\n",
    "obs_detrend_average    = {}\n",
    "\n",
    "for key in obs_SIA_keys:   \n",
    "    detrend_individual_list = []\n",
    "    \n",
    "    for month_ in np.arange(1,13):\n",
    "        coefs = np.polyfit(np.arange(start_yr, end_yr+1), obs_SIA[key].sel(time=obs_SIA['time.month']==month_), 1)\n",
    "        detrend_individual_list.append(-1*(coefs[0]*np.arange(start_yr, end_yr+1) + coefs[1]) + obs_SIA[key].sel(time=obs_SIA['time.month']==month_))\n",
    "        \n",
    "    obs_detrend_individual[key] = xr.concat((detrend_individual_list), dim='time')\n",
    "    obs_detrend_average[key]    = obs_SIA[key] - mean_trends[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92a42fc2-55d5-4408-86b7-e6033bc8cb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#detrend based on deleting a number of values from the time series at random\n",
    "len_rand = 32 #number of randomly chosen elements to be deleted - see figures at end of notebook\n",
    "n_jackknife = 50\n",
    "\n",
    "detrended_jackknife = {}\n",
    "\n",
    "for dataset in obs_SIA_keys:\n",
    "    detrended_jackknife_months = []\n",
    "    \n",
    "    for month_ in np.arange(1,13):\n",
    "        np_data = np.array(obs_SIA[dataset].sel(time=obs_SIA['time.month']==month_).sel(time=slice('1979','2020')).copy())\n",
    "        np_dates = np.arange(1979,2021)\n",
    "\n",
    "        obs_coefs = np.empty((50,2))\n",
    "        for i in range(n_jackknife):\n",
    "            rand_ints = np.random.default_rng().choice(len(np_data), size=len_rand, replace=False)\n",
    "            temp_SIA = np.delete(np_data.copy(), rand_ints)\n",
    "            temp_dates = np.delete(np_dates.copy(), rand_ints)\n",
    "            obs_coefs[i] = np.polyfit(temp_dates, temp_SIA, 1)\n",
    "\n",
    "        obs_data = xr.DataArray(data=np.tile(np_data,(50,1)), coords={'jackknife':np.arange(0,50), 'time':np.arange(1979,2021)}, dims=['jackknife', 'time'])\n",
    "\n",
    "        obs_coefs = xr.DataArray(data=obs_coefs, coords={'jackknife':np.arange(0,50), 'coef':['gradient','intercept']}, dims=['jackknife', 'coef'])\n",
    "\n",
    "        obs_jackknife_trends = obs_coefs.sel(coef='gradient') * obs_data['time'] + obs_coefs.sel(coef='intercept')\n",
    "\n",
    "        detrended_jackknife_months.append(obs_data - obs_jackknife_trends)\n",
    "\n",
    "    detrended_jackknife_dataset = xr.concat((detrended_jackknife_months), dim='month')\n",
    "    detrended_jackknife_dataset['month'] = np.arange(1,13)\n",
    "    detrended_jackknife[dataset] = detrended_jackknife_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1be3517d-0b5e-46ba-b69c-c7713148e914",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save detrended observations to NetCDF\n",
    "dict_attrs = {'Description': 'Detrended Arctic sea ice area (SIA) for six observational datasets 1979-2020: Climate Data Record (CDR), NASA Bootstrap (BT), NASA Team (NT), NSIDC Sea Ice Index (SII), Hadley Centre Sea Ice (HadISST1), Merged Hadley NOAA Optimal Interpolation (Merged). The trend for each month of each dataset is used for detrending.', \n",
    "              'Units'      : 'million square km',\n",
    "              'Timestamp'  : str(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\")),\n",
    "              'Data source': 'DOIs - CRD, BT, NT:10.7265/efmz-2t65, SII:10.7265/N5K072F8, HadISST1:10.1029/2002JD002670, Merged:10.5065/r33v-sv91',\n",
    "              'Analysis'   : 'https://github.com/chrisrwp/synthetic-ensemble/SIA/SIA_detrending_resampling.ipynb'}\n",
    "\n",
    "#save detrended observations by individual trends\n",
    "obs_detrend_individual = xr.Dataset(obs_detrend_individual)\n",
    "obs_detrend_individual.attrs = dict_attrs\n",
    "obs_detrend_individual.to_netcdf(data_path+'SIA/SIA_detrended/Obs_SIA_detrended_individual_79-20.nc')\n",
    "\n",
    "#save detrended observations by average trends of the 6 models\n",
    "ave_attrs = dict_attrs.copy()\n",
    "ave_attrs['Description'] = 'Detrended Arctic sea ice area (SIA) for six observational datasets 1979-2020: Climate Data Record (CDR), NASA Bootstrap (BT), NASA Team (NT), NSIDC Sea Ice Index (SII), Hadley Centre Sea Ice (HadISST1), Merged Hadley NOAA Optimal Interpolation (Merged). The trend calculated from the average of the six datasets is used to detrend the datasets for each month.'\n",
    "\n",
    "obs_detrend_average = xr.Dataset(obs_detrend_average)\n",
    "obs_detrend_average.attrs = ave_attrs\n",
    "obs_detrend_average.to_netcdf(data_path+'SIA/SIA_detrended/Obs_SIA_detrended_average_79-20.nc')\n",
    "\n",
    "#save detrended observations by 50 jacknife simulated members\n",
    "jackknife_attrs = dict_attrs.copy()\n",
    "jackknife_attrs['Description'] = 'Detrended Arctic sea ice area (SIA) for six observational datasets 1979-2020: Climate Data Record (CDR), NASA Bootstrap (BT), NASA Team (NT), NSIDC Sea Ice Index (SII), Hadley Centre Sea Ice (HadISST1), Merged Hadley NOAA Optimal Interpolation (Merged). The trend calculated from 50 jackknifed subsets of the data containing 30 of the 42 time steps.'\n",
    "\n",
    "detrended_jackknife = xr.Dataset(detrended_jackknife)\n",
    "detrended_jackknife.attrs = jackknife_attrs\n",
    "detrended_jackknife.to_netcdf(data_path+'SIA/SIA_detrended/Obs_SIA_detrended_jackknife_79-20.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db55ce73-0b5f-447f-9636-d3e986910305",
   "metadata": {},
   "source": [
    "## Resample all detrended observational data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd74c369-d65c-4e1c-b316-5d8422300eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import detrended data\n",
    "# obs_detrend_average     = xr.open_dataset(data_path+'SIA/SIA_detrended/Obs_SIA_detrended_average_79-20.nc')\n",
    "obs_detrend_individual  = xr.open_dataset(data_path+'SIA/SIA_detrended/Obs_SIA_detrended_individual_79-20.nc')\n",
    "# obs_detrended_jackknife = xr.open_dataset(data_path+'SIA/SIA_detrended/Obs_SIA_detrended_jackknife_79-20.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d11872d7-d1e9-406a-bb08-77e7d93dcb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the resamplings of all observational datasets and months\n",
    "#to change the bootstrap size, change the function names: [resample_boot2, resample_boot1]\n",
    "\n",
    "for run in np.arange(2,11): #make repeated runs to add to randomness\n",
    "    print(datetime.datetime.now(), run)\n",
    "\n",
    "    obs_resample_individual = {}\n",
    "    # obs_resample_average    = {}\n",
    "    # obs_resample_jackknife  = {}\n",
    "\n",
    "    for key in obs_SIA_keys:   \n",
    "        \n",
    "        resampled_individual_month = []\n",
    "    #     resampled_average_month    = []\n",
    "    #     resampled_jackknifes_month = []\n",
    "\n",
    "        for month_ in np.arange(1,13):\n",
    "            resampled_individual_month.append(resample_boot2(42, obs_detrend_individual[key].sel(time=obs_detrend_individual['time.month']==month_)))\n",
    "    #         resampled_average_month.append(resample_boot2(42, obs_detrend_average[key].sel(time=obs_detrend_average['time.month']==month_)))\n",
    "\n",
    "    #         jackknifes = []\n",
    "    #         for jack_n in obs_detrended_jackknife['jackknife']:\n",
    "    #             jackknifes.append(resample_boot2(42, obs_detrended_jackknife[key].sel(jackknife=jack_n).sel(month=month_)))\n",
    "\n",
    "    #         resampled_jackknifes_month.append(xr.concat((jackknifes), dim='jackknife')) \n",
    "\n",
    "\n",
    "        obs_resample_individual[key] = xr.concat((resampled_individual_month), dim='month')\n",
    "    #     obs_resample_average[key]    = xr.concat((resampled_average_month), dim='month')\n",
    "    #     obs_resample_jackknife[key]  = xr.concat((resampled_jackknifes_month), dim='month')\n",
    "\n",
    "    obs_resample_individual = xr.Dataset(obs_resample_individual)\n",
    "    obs_resample_individual['month'] = np.arange(1,13)\n",
    "\n",
    "    # obs_resample_average = xr.Dataset(obs_resample_average)\n",
    "    # obs_resample_average['month'] = np.arange(1,13)\n",
    "\n",
    "    # obs_resample_jackknife = xr.Dataset(obs_resample_jackknife)\n",
    "    # obs_resample_jackknife['month'] = np.arange(1,13)\n",
    "\n",
    "\n",
    "    #save the resampled data to NetCDF\n",
    "    dict_attrs = {'Description': 'Resampled Arctic sea ice area 1979-2020 for six datasets: Climate Data Record (CDR), NASA Bootstrap (BT), NASA Team (NT), NSIDC Sea Ice Index (SII), Hadley Centre Sea Ice (HadISST1), Merged Hadley NOAA Optimal Interpolation (Merged). The trend for each month for each dataset is used for detrending, resampling is done 1000 times with a 2 year bootstrap size.', \n",
    "                  'Units'      : 'million square km',\n",
    "                  'Timestamp'  : str(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\")),\n",
    "                  'Data source': 'DOIs - CRD, BT, NT:10.7265/efmz-2t65, SII:10.7265/N5K072F8, HadISST1:10.1029/2002JD002670, Merged:10.5065/r33v-sv91',\n",
    "                  'Analysis'   : 'https://github.com/chrisrwp/synthetic-ensemble/SIA/SIA_detrending_resampling.ipynb'}\n",
    "\n",
    "    #save resampled SIA using individual trends\n",
    "    obs_resample_individual = xr.Dataset(obs_resample_individual)\n",
    "    obs_resample_individual.attrs = dict_attrs\n",
    "    obs_resample_individual.to_netcdf(data_path+'SIA/SIA_resampled/Obs_SIA_resampled_individual_79-20_run{}.nc'.format(run))\n",
    "\n",
    "    # #save resampled SIA using dataset average trends\n",
    "    # ave_attrs = dict_attrs.copy()\n",
    "    # ave_attrs['Description'] = 'Resampled Arctic sea ice area (SIA) for six observational datasets 1979-2020: Climate Data Record (CDR), NASA Bootstrap (BT), NASA Team (NT), NSIDC Sea Ice Index (SII), Hadley Centre Sea Ice (HadISST1), Merged Hadley NOAA Optimal Interpolation (Merged). The trend calculated from the average of the six datasets is used to detrend the datasets for each month, resampling is done 1000 times with a 2 year bootstrap size.'\n",
    "\n",
    "    # obs_resample_average = xr.Dataset(obs_resample_average)\n",
    "    # obs_resample_average.attrs = ave_attrs\n",
    "    # obs_resample_average.to_netcdf(data_path+'SIA/SIA_resampled/Obs_SIA_resampled_average_79-20.nc')\n",
    "\n",
    "    # #save resampled SIA using dataset jackknife trends\n",
    "    # jackknife_attrs = dict_attrs.copy()\n",
    "    # jackknife_attrs['Description'] = 'Resampled Arctic sea ice area (SIA) for six observational datasets 1979-2020: Climate Data Record (CDR), NASA Bootstrap (BT), NASA Team (NT), NSIDC Sea Ice Index (SII), Hadley Centre Sea Ice (HadISST1), Merged Hadley NOAA Optimal Interpolation (Merged). The trend calculated from 50 jackknifed subsets (30 of the 42 time steps) of the six datasets is used to detrend the datasets for each month, resampling is done 1000 times with a 2 year bootstrap size.'\n",
    "\n",
    "    # obs_resample_jackknife = xr.Dataset(obs_resample_jackknife)\n",
    "    # obs_resample_jackknife.attrs = jackknife_attrs\n",
    "    # obs_resample_jackknife.to_netcdf(data_path+'SIA/SIA_resampled/Obs_SIA_resampled_jackknife_79-20.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e1041b-6df5-4db5-b359-5835c11bfba5",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "## Detrend model data using ensemble mean trends and individual member trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8f7acf9-a727-478b-9921-1200a859ae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_yr = 1979\n",
    "end_yr   = 2020\n",
    "\n",
    "all_model_detrend_ensemble   = {}\n",
    "all_model_detrend_individual = {}\n",
    "\n",
    "for model_i, model_name in enumerate(model_names):\n",
    "    \n",
    "    detrend_ensemble_list  = []\n",
    "    detrend_individual_list = []\n",
    "    \n",
    "    for month_ in np.arange(1,13):\n",
    "        \n",
    "        if model_name == 'MPI_ESM1': #100 elements in member dimension so can't select all of those for MPI ESM1\n",
    "            model_month = SIA[model_name].sel(time=SIA['time.month']==month_).sel(time=slice(str(start_yr),str(end_yr)))\n",
    "        else:\n",
    "            model_month = SIA[model_name].sel(time=SIA['time.month']==month_).sel(time=slice(str(start_yr),str(end_yr))).sel(member=slice('1',str(mem_len[model_i])))\n",
    "\n",
    "        #detrend all members by the ensemble mean trend\n",
    "        ensemble_coefs = np.polyfit(np.arange(start_yr, end_yr+1), model_month.mean('member').values, 1)\n",
    "        detrend_ensemble_list.append(model_month - (ensemble_coefs[0]*np.arange(start_yr, end_yr+1) + ensemble_coefs[1]))\n",
    "\n",
    "        #detrend the individual members with their own trend\n",
    "        yr_list = xr.DataArray(data = np.arange(1979,2021,1), coords={'time':model_month['time']}, dims=['time'])\n",
    "        \n",
    "        mem_coefs  = np.polyfit(np.arange(start_yr, end_yr+1), model_month.transpose().values, 1)\n",
    "        mem_coefs  = xr.DataArray(data = mem_coefs, coords={'coef':['grad', 'intercept'], 'member':np.arange(1,mem_len[model_i]+1)}, dims=['coef', 'member'])\n",
    "\n",
    "        detrend_individual_list.append(model_month - (mem_coefs.sel(coef='grad')*yr_list + mem_coefs.sel(coef='intercept')))\n",
    "        \n",
    "    all_model_detrend_ensemble[model_name]   = xr.concat((detrend_ensemble_list), dim='time')\n",
    "    all_model_detrend_individual[model_name] = xr.concat((detrend_individual_list), dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47b1cbbd-e610-48f7-94a6-f5a4caf7bc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save detrended SIA using ensemble trends\n",
    "all_model_detrend_ensemble   = xr.Dataset(all_model_detrend_ensemble)\n",
    "\n",
    "dict_attrs = {'Description': 'Detrended Arctic sea ice area (SIA) for the large ensemble models: CanESM2, CESM1, CSIRO MK3.6, GFDL CM3, GFDL ESM2M, MPI ESM1, 1979-2020. Ensemble mean trend is used to detrend each member.', \n",
    "              'Units'      : 'million square km',\n",
    "              'Timestamp'  : str(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\")),\n",
    "              'Data source': 'CLIVAR Large Ensemble Archive, doi:10.1038/s41558-020-0731-2',\n",
    "              'Analysis'   : 'https://github.com/chrisrwp/synthetic-ensemble/SIA/SIA_detrending_resampling.ipynb'}\n",
    "\n",
    "all_model_detrend_ensemble.attrs = dict_attrs\n",
    "all_model_detrend_ensemble.to_netcdf(data_path+'SIA/SIA_detrended/CLIVAR_SIA_detrended_ensemble_79-20.nc')\n",
    "\n",
    "#save detrended SIA using individual trends\n",
    "all_model_detrend_individual = xr.Dataset(all_model_detrend_individual)\n",
    "individual_attrs = dict_attrs.copy()\n",
    "individual_attrs['Description'] = 'Detrended Arctic sea ice area (SIA) for the large ensemble models: CanESM2, CESM1, CSIRO MK3.6, GFDL CM3, GFDL ESM2M, MPI ESM1, 1979-2020. Each individual member trend is used to detrend.'\n",
    "all_model_detrend_individual.attrs = individual_attrs\n",
    "all_model_detrend_individual.to_netcdf(data_path+'SIA/SIA_detrended/CLIVAR_SIA_detrended_individual_79-20.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5b5c23-c093-49bc-b450-51fa54264b55",
   "metadata": {},
   "source": [
    "## Resample models, 2 year bootstrap size, 1000 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c77eb6f-3632-4e98-a644-05400fdf8b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import detrended data\n",
    "# detrend_ensemble   = xr.open_dataset(data_path+'SIA/SIA_detrended/CLIVAR_SIA_detrended_ensemble_79-20.nc')\n",
    "detrend_individual = xr.open_dataset(data_path+'SIA/SIA_detrended/CLIVAR_SIA_detrended_individual_79-20.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1882e9a4-0105-4a1b-80c2-cf76afd676ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-20 11:14:09.811449 CanESM2\n",
      "2021-08-20 11:14:14.646354 CESM1\n",
      "2021-08-20 11:14:18.570891 CSIRO_MK36\n",
      "2021-08-20 11:14:21.535959 GFDL_CM3\n",
      "2021-08-20 11:14:23.552693 GFDL_ESM2M\n",
      "2021-08-20 11:14:26.459272 MPI_ESM1\n"
     ]
    }
   ],
   "source": [
    "#calculate the resamplings of all models and months\n",
    "#to change the bootstrap size, change the function names: [resample_boot2, resample_boot1]\n",
    "# resampled_ensemble_model   = {}\n",
    "resampled_individual_model = {} \n",
    "\n",
    "for model_i, model_name in enumerate(model_names):\n",
    "    print(datetime.datetime.now(), model_name)\n",
    "    \n",
    "#     resampled_ensemble_month   = []\n",
    "    resampled_individual_month = [] \n",
    "    \n",
    "    for month_ in np.arange(1,13):\n",
    "        \n",
    "#         resampled_ensemble_member   = []\n",
    "        resampled_individual_member = [] \n",
    "        \n",
    "        for mem_ in np.arange(1,mem_len[model_i]+1):\n",
    "            #select a 1D array of detrended anomalies, resample these 1000 times for each member\n",
    "#             resampled_ensemble_member.append(resample_boot2(42, detrend_ensemble[model_name].sel(time=detrend_ensemble['time.month']==month_).sel(member=mem_)))\n",
    "            resampled_individual_member.append(resample_boot2(42, detrend_individual[model_name].sel(time=detrend_individual['time.month']==month_).sel(member=mem_)))\n",
    "        \n",
    "        #concatenate all the member output data and append it to the list containing data for all months\n",
    "#         resampled_ensemble_month.append(xr.concat((resampled_ensemble_member), dim='member'))\n",
    "        resampled_individual_month.append(xr.concat((resampled_individual_member), dim='member'))\n",
    "            \n",
    "#     resampled_ensemble_model[model_name] = xr.concat((resampled_ensemble_month), dim='month')\n",
    "#     resampled_ensemble_model[model_name]['member'] = np.arange(1,mem_len[model_i]+1)\n",
    "    resampled_individual_model[model_name] = xr.concat((resampled_individual_month), dim='month')\n",
    "    resampled_individual_model[model_name]['member'] = np.arange(1,mem_len[model_i]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e442c0c-f796-4034-bfeb-cc985a5861a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the resampled data to NetCDF\n",
    "# resampled_ensemble_model   = xr.Dataset(resampled_ensemble_model)\n",
    "# resampled_ensemble_model['month'] = np.arange(1,13)\n",
    "\n",
    "dict_attrs = {'Description': 'Resampled Arctic sea ice area (SIA) for the large ensemble models: CanESM2, CESM1, CSIRO MK3.6, GFDL CM3, GFDL ESM2M, MPI ESM1, 1979-2020. Ensemble mean trend is used to detrend each member. Resampling is done 1000 times with a 2 year bootstrap size.', \n",
    "              'Units'      : 'million square km',\n",
    "              'Timestamp'  : str(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\")),\n",
    "              'Data source': 'CLIVAR Large Ensemble Archive, doi:10.1038/s41558-020-0731-2',\n",
    "              'Analysis'   : 'https://github.com/chrisrwp/synthetic-ensemble/SIA/SIA_detrending_resampling.ipynb'}\n",
    "\n",
    "# resampled_ensemble_model.attrs = dict_attrs\n",
    "# resampled_ensemble_model.to_netcdf(data_path+'SIA/SIA_resampled/CLIVAR_SIA_resampled_ensemble_79-20_run2.nc')\n",
    "\n",
    "#save detrended SIA using individual trends\n",
    "resampled_individual_model = xr.Dataset(resampled_individual_model)\n",
    "resampled_individual_model['month'] = np.arange(1,13)\n",
    "individual_attrs = dict_attrs.copy()\n",
    "individual_attrs['Description'] = 'Resampled Arctic sea ice area (SIA) for the large ensemble models: CanESM2, CESM1, CSIRO MK3.6, GFDL CM3, GFDL ESM2M, MPI ESM1, 1979-2020. Each individual member trend is used to detrend. Resampling is done 1000 times with a 2 year bootstrap size.'\n",
    "resampled_individual_model.attrs = individual_attrs\n",
    "resampled_individual_model.to_netcdf(data_path+'SIA/SIA_resampled/CLIVAR_SIA_resampled_individual_79-20_run10.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6345f09-ef06-4a9e-a0ee-0a05f557e01e",
   "metadata": {},
   "source": [
    "## Compute SD time with 10 runs for 10,000 resamplings in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ea85648-b325-442c-8a39-d270cfa9f22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs_models = []\n",
    "all_runs_obs = []\n",
    "\n",
    "for run in np.arange(1,11): #loop through the 10 files of 1000 random resamplings each\n",
    "    if run == 1:\n",
    "        resampled_models = xr.open_dataset(data_path+'SIA/SIA_resampled/CLIVAR_SIA_resampled_individual_79-20.nc')\n",
    "        resampled_obs = xr.open_dataset(data_path+'SIA/SIA_resampled/Obs_SIA_resampled_individual_79-20.nc')\n",
    "    else:\n",
    "        resampled_models = xr.open_dataset(data_path+'SIA/SIA_resampled/CLIVAR_SIA_resampled_individual_79-20_run{}.nc'.format(run))\n",
    "        resampled_obs = xr.open_dataset(data_path+'SIA/SIA_resampled/Obs_SIA_resampled_individual_79-20_run{}.nc'.format(run))\n",
    "    \n",
    "    SD_time_models = resampled_models.std('year_i')\n",
    "    SD_time_models['resampling'] = np.arange((run-1)*1000 +1, run*1000 +1) #uniquely index the resamplings\n",
    "    all_runs_models.append(SD_time_models)\n",
    "    \n",
    "    SD_time_obs = resampled_obs.std('year_i')\n",
    "    SD_time_obs['resampling'] = np.arange((run-1)*1000 +1, run*1000 +1) #uniquely index the resamplings\n",
    "    all_runs_obs.append(SD_time_obs)\n",
    "\n",
    "# all_runs_models = xr.concat((all_runs_models), dim='resampling')\n",
    "all_runs_obs    = xr.concat((all_runs_obs), dim='resampling')\n",
    "\n",
    "#compute the standard deviation and mean across resamplings\n",
    "sigma_mem_10000 = all_runs_models.std('resampling')\n",
    "mu_mem_10000    = all_runs_models.mean('resampling')\n",
    "\n",
    "sigma_obs_10000 = all_runs_obs.std('resampling')\n",
    "mu_obs_10000    = all_runs_obs.mean('resampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a39150b-7936-424f-8ec2-ac9f6dcd8bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to netcdf with attributes\n",
    "sigma_attrs_dict = {'Description': 'Variability of Arctic sea ice area (SIA) of six large ensembles 1979-2020 (CanESM2, CESM1, CSIRO MK3.6, GFDL CM3, GFDL ESM2M, MPI ESM1). Standard deviation with respect to 10000 resamplings with a 2 year bootstrap size. Detrending was based on the single model ensemble mean trend.', \n",
    "                    'Units'      : 'million square km',\n",
    "                    'Timestamp'  : str(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\")),\n",
    "                    'Data source': 'CLIVAR Large Ensemble Archive, doi:10.1038/s41558-020-0731-2',\n",
    "                    'Analysis'   : 'https://github.com/chrisrwp/synthetic-ensemble/SIA/SIA_detrending_resampling.ipynb'}\n",
    "\n",
    "mu_attrs_dict = sigma_attrs_dict.copy()\n",
    "mu_attrs_dict['Description'] = 'Variability of Arctic sea ice area (SIA) of six large ensembles 1979-2020 (CanESM2, CESM1, CSIRO MK3.6, GFDL CM3, GFDL ESM2M, MPI ESM1). Mean of 10000 resamplings with a 2 year bootstrap size. Detrending was based on the single model ensemble mean trend.', \n",
    "\n",
    "sigma_mem_10000.attrs = sigma_attrs_dict\n",
    "sigma_mem_10000.to_netcdf(data_path+'SIA/SIA_resampled/Sigma_mem_individual_10000.nc')\n",
    "\n",
    "mu_mem_10000.attrs = mu_attrs_dict\n",
    "mu_mem_10000.to_netcdf(data_path+'SIA/SIA_resampled/Mu_mem_individual_10000.nc')\n",
    "\n",
    "#save sigma and mu obs\n",
    "sigma_obs_attrs = sigma_attrs_dict.copy()\n",
    "sigma_obs_attrs['Description'] = 'Variability of Arctic sea ice area (SIA) of six observational datasets 1979-2020 (six datasets: Climate Data Record (CDR), NASA Bootstrap (BT), NASA Team (NT), NSIDC Sea Ice Index (SII), Hadley Centre Sea Ice (HadISST1), Merged Hadley NOAA Optimal Interpolation (Merged). Standard deviation with respect to the standard deviation with respect to time for each 10000 resamplings with a 2 year bootstrap size. Detrending was based on the trend of the individual dataset.' \n",
    "sigma_obs_attrs['Data source'] = 'DOIs - CRD, BT, NT:10.7265/efmz-2t65, SII:10.7265/N5K072F8, HadISST1:10.1029/2002JD002670, Merged:10.5065/r33v-sv91'\n",
    "sigma_obs_10000.attrs = sigma_obs_attrs\n",
    "sigma_obs_10000.to_netcdf(data_path+'SIA/SIA_resampled/Sigma_obs_individual_10000.nc')\n",
    "\n",
    "mu_obs_attrs = sigma_obs_attrs.copy()\n",
    "mu_obs_attrs['Description'] = 'Variability of Arctic sea ice area (SIA) of six observational datasets 1979-2020 (six datasets: Climate Data Record (CDR), NASA Bootstrap (BT), NASA Team (NT), NSIDC Sea Ice Index (SII), Hadley Centre Sea Ice (HadISST1), Merged Hadley NOAA Optimal Interpolation (Merged). Mean of the standard deviation with respect to time for each 10000 resamplings with a 2 year bootstrap size. Detrending was based on the trend of the individual dataset.'\n",
    "mu_obs_10000.attrs = mu_obs_attrs\n",
    "mu_obs_10000.to_netcdf(data_path+'SIA/SIA_resampled/Mu_obs_individual_10000.nc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9bc83e-f75f-43f6-9a83-e329a4ec3368",
   "metadata": {},
   "source": [
    "# $\\sigma_{LE}$ , $\\sigma_{mem}$ , $\\sigma_{obs}$ calculations\n",
    "## $\\sigma_{LE}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5b52758-82de-4fe2-ba5c-b763d9d48e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load detrended model data\n",
    "detrend_ensemble   = xr.open_dataset(data_path+'SIA/SIA_detrended/CLIVAR_SIA_detrended_ensemble_79-20.nc')\n",
    "detrend_individual = xr.open_dataset(data_path+'SIA/SIA_detrended/CLIVAR_SIA_detrended_individual_79-20.nc')\n",
    "\n",
    "#compute standard deviation along the member dimension\n",
    "sigma_LE_ensemble   = detrend_ensemble.groupby('time.month').std('time').std('member')\n",
    "sigma_LE_individual = detrend_individual.groupby('time.month').std('time').std('member')\n",
    "\n",
    "#save to NetCDF\n",
    "attrs_dict = {'Description': 'Variability of Arctic sea ice area (SIA) of six large ensembles 1979-2020 (CanESM2, CESM1, CSIRO MK3.6, GFDL CM3, GFDL ESM2M, MPI ESM1). Standard deviation with respect to members. Computed on the detrended standard deviations with respect to time for each month. Detrending was based on the single model ensemble mean trend.', \n",
    "              'Units'      : 'million square km',\n",
    "              'Timestamp'  : str(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\")),\n",
    "              'Data source': 'CLIVAR Large Ensemble Archive, doi:10.1038/s41558-020-0731-2',\n",
    "              'Analysis'   : 'https://github.com/chrisrwp/synthetic-ensemble/SIA/SIA_detrending_resampling.ipynb'}\n",
    "\n",
    "sigma_LE_ensemble.attrs = attrs_dict\n",
    "sigma_LE_ensemble.to_netcdf(data_path+'SIA/SIA_resampled/Sigma_LE_ensemble_79-20.nc')\n",
    "\n",
    "ind_attrs_dict = attrs_dict.copy()\n",
    "ind_attrs_dict['Description'] = 'Variability of Arctic sea ice area (SIA) of six large ensembles 1979-2020 (CanESM2, CESM1, CSIRO MK3.6, GFDL CM3, GFDL ESM2M, MPI ESM1). Standard deviation with respect members. Computed on the detrended standard deviations with respect to time for each month. Detrending was based on the individual member trend.' \n",
    "sigma_LE_individual.attrs = ind_attrs_dict\n",
    "sigma_LE_individual.to_netcdf(data_path+'SIA/SIA_resampled/Sigma_LE_individual_79-20.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59d6c78-405e-451c-b285-ed6b14a62a1b",
   "metadata": {},
   "source": [
    "## $\\sigma_{mem}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20290a35-4fbe-4338-963e-c2c1c159fab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load resampled model data\n",
    "resampled_ensemble   = xr.open_dataset(data_path+'SIA/SIA_resampled/CLIVAR_SIA_resampled_ensemble_79-20.nc')\n",
    "resampled_individual = xr.open_dataset(data_path+'SIA/SIA_resampled/CLIVAR_SIA_resampled_individual_79-20.nc')\n",
    "\n",
    "#compute standard deviation along the resampling dimension\n",
    "sigma_mem_ensemble   = resampled_ensemble.std('year_i').std('resampling')\n",
    "sigma_mem_individual = resampled_individual.std('year_i').std('resampling')\n",
    "\n",
    "#save to NetCDF\n",
    "attrs_dict = {'Description': 'Variability of Arctic sea ice area (SIA) of six large ensembles 1979-2020 (CanESM2, CESM1, CSIRO MK3.6, GFDL CM3, GFDL ESM2M, MPI ESM1). Standard deviation with respect to 1000 resamplings. Computed on the detrended standard deviations with respect to time for each month. Detrending was based on the single model ensemble mean trend.', \n",
    "              'Units'      : 'million square km',\n",
    "              'Timestamp'  : str(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\")),\n",
    "              'Data source': 'CLIVAR Large Ensemble Archive, doi:10.1038/s41558-020-0731-2',\n",
    "              'Analysis'   : 'https://github.com/chrisrwp/synthetic-ensemble/SIA/SIA_detrending_resampling.ipynb'}\n",
    "\n",
    "sigma_mem_ensemble.attrs = attrs_dict\n",
    "sigma_mem_ensemble.to_netcdf(data_path+'SIA/SIA_resampled/Sigma_mem_ensemble_79-20.nc')\n",
    "\n",
    "ind_attrs_dict = attrs_dict.copy()\n",
    "ind_attrs_dict['Description'] = 'Variability of Arctic sea ice area (SIA) of six large ensembles 1979-2020 (CanESM2, CESM1, CSIRO MK3.6, GFDL CM3, GFDL ESM2M, MPI ESM1). Standard deviation with respect to 1000 resamplings. Computed on the detrended standard deviations with respect to time for each month. Detrending was based on the individual member trend.' \n",
    "sigma_mem_individual.attrs = ind_attrs_dict\n",
    "sigma_mem_individual.to_netcdf(data_path+'SIA/SIA_resampled/Sigma_mem_individual_79-20.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8b17a1-5c8b-4001-960e-32577b693652",
   "metadata": {},
   "source": [
    "## $\\sigma_{obs}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7df5874-bf2d-4939-8e06-5dab1c8a82bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load resampled observational data\n",
    "obs_resample_average    = xr.open_dataset(data_path+'SIA/SIA_resampled/Obs_SIA_resampled_average_79-20.nc')\n",
    "obs_resample_individual = xr.open_dataset(data_path+'SIA/SIA_resampled/Obs_SIA_resampled_individual_79-20.nc')\n",
    "obs_resample_jackknife  = xr.open_dataset(data_path+'SIA/SIA_resampled/Obs_SIA_resampled_jackknife_79-20.nc')\n",
    "\n",
    "#compute standard deviation along the resampling dimension\n",
    "sigma_obs_average    = obs_resample_average.std('year_i').std('resampling')\n",
    "sigma_obs_individual = obs_resample_individual.std('year_i').std('resampling')\n",
    "sigma_obs_jackknife  = obs_resample_jackknife.std('year_i').std('resampling')\n",
    "\n",
    "#save to NetCDF\n",
    "attrs_dict = {'Description': 'Variability of Arctic sea ice area (SIA) observations 1979-2020. Standard deviation with respect to 1000 resamplings. Computed on the detrended standard deviations with respect to time for each month. Detrending was based on the mean dataset trend.', \n",
    "              'Units'      : 'million square km',\n",
    "              'Timestamp'  : str(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\")),\n",
    "              'Data source': 'DOIs - CRD, BT, NT:10.7265/efmz-2t65, SII:10.7265/N5K072F8, HadISST1:10.1029/2002JD002670, Merged:10.5065/r33v-sv91',\n",
    "              'Analysis'   : 'https://github.com/chrisrwp/synthetic-ensemble/SIA/SIA_detrending_resampling.ipynb'}\n",
    "\n",
    "#save sigma_obs average\n",
    "sigma_obs_average.attrs = attrs_dict\n",
    "sigma_obs_average.to_netcdf(data_path+'SIA/SIA_resampled/Sigma_obs_average_79-20.nc')\n",
    "\n",
    "#save sigma_obs individual\n",
    "ind_attrs_dict = attrs_dict.copy()\n",
    "ind_attrs_dict['Description'] = 'Variability of Arctic sea ice area (SIA) observations 1979-2020. Standard deviation with respect to 1000 resamplings. Computed on the detrended standard deviations with respect to time for each month. Detrending was based on the individual dataset trend.' \n",
    "sigma_obs_individual.attrs = ind_attrs_dict\n",
    "sigma_obs_individual.to_netcdf(data_path+'SIA/SIA_resampled/Sigma_obs_individual_79-20.nc')\n",
    "\n",
    "#save sigma_obs jackknife\n",
    "jackknife_attrs_dict = attrs_dict.copy()\n",
    "jackknife_attrs_dict['Description'] = 'Variability of Arctic sea ice area (SIA) observations 1979-2020. Standard deviation with respect to 1000 resamplings. Computed on the detrended standard deviations with respect to time for each month. Detrending was based on 50 jackknifed subsets (30 of the 42 time steps) of the six datasets.' \n",
    "sigma_obs_jackknife.attrs = jackknife_attrs_dict\n",
    "sigma_obs_jackknife.to_netcdf(data_path+'SIA/SIA_resampled/Sigma_obs_jackknife_79-20.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45a4528-bda3-4804-8dac-b38a8f5e03f6",
   "metadata": {},
   "source": [
    "# Investigate detrending observations with member mean from models - didn't work very well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51e68a8b-b0a0-421e-b3a5-d0c5105ee3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_print_names = ['CanESM2', 'CESM1', 'CSIRO MK36', 'GFDL CM3', 'GFDL ESM2M', 'MPI ESM1'] #for printing on graphs\n",
    "colors = ['m',     'b',   'g',        'orange',  'k',        'tab:olive' ]\n",
    "obs_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "\n",
    "month_names = ['January', 'February', 'March', 'April', 'May', 'June', 'July', \n",
    "               'August', 'September', 'October', 'November', 'December']\n",
    "\n",
    "month_names_short = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "160c2575-7ee6-4b67-89f8-e9eb9193bda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_detrend_ensemble = xr.open_dataset(data_path+'SIA/SIA_detrended/CLIVAR_SIA_detrended_ensemble_79-20.nc')\n",
    "all_model_detrend_individual = xr.open_dataset(data_path+'SIA/SIA_detrended/CLIVAR_SIA_detrended_individual_79-20.nc')\n",
    "obs_detrend_individual = xr.open_dataset(data_path+'SIA/SIA_detrended/Obs_SIA_detrended_individual_79-20.nc')\n",
    "\n",
    "start_yr = 1979\n",
    "end_yr = 2020\n",
    "trend_ens = {}\n",
    "\n",
    "yr_xr = xr.DataArray(data = np.arange(start_yr, end_yr+1), coords={'time':np.arange(start_yr, end_yr+1)}, dims=['time'])\n",
    "\n",
    "for model_i, model_name in enumerate(model_names):\n",
    "    detrend_ensemble_list  = []\n",
    "    \n",
    "    for month_ in np.arange(1,13):\n",
    "        \n",
    "        if model_name == 'MPI_ESM1': #100 elements in member dimension so can't select all of those for MPI ESM1\n",
    "            model_month_ = SIA[model_name].sel(time=SIA['time.month']==month_).sel(time=slice(str(start_yr),str(end_yr)))\n",
    "        else:\n",
    "            model_month_ = SIA[model_name].sel(time=SIA['time.month']==month_).sel(time=slice(str(start_yr),str(end_yr))).sel(member=slice('1',str(mem_len[model_i])))\n",
    "\n",
    "        #detrend all members by the ensemble mean trend\n",
    "        model_month = model_month_.copy()\n",
    "        model_month['time'] = np.arange(start_yr, end_yr+1)\n",
    "        \n",
    "        ensemble_coefs = model_month.mean('member').polyfit(dim='time', deg=1)\n",
    "        ens_trend = (ensemble_coefs['polyfit_coefficients'].sel(degree=1) * yr_xr + ensemble_coefs['polyfit_coefficients'].sel(degree=0))\n",
    "        ens_trend['time'] = model_month_['time']\n",
    "        detrend_ensemble_list.append(ens_trend)\n",
    "\n",
    "    trend_ens[model_name] = xr.concat((detrend_ensemble_list), dim='time')\n",
    "    trend_ens[model_name] = trend_ens[model_name].sortby('time')\n",
    "    \n",
    "trend_ens = xr.Dataset(trend_ens)\n",
    "\n",
    "#detrend obs\n",
    "\n",
    "detrended_obs = {}\n",
    "for dataset in list(obs_SIA.keys()):\n",
    "    for model_name in model_names:\n",
    "        month_data = []\n",
    "        for month_ in np.arange(1,13):\n",
    "            month_data.append(obs_SIA[dataset].sel(time=obs_SIA['time.month']==month_) - trend_ens[model_name].sel(time=trend_ens['time.month']==month_))\n",
    "\n",
    "        detrended_obs[str(model_name)+'_'+str(dataset)] = xr.concat((month_data), dim='time')\n",
    "\n",
    "    detrended_obs = xr.Dataset(detrended_obs)\n",
    "\n",
    "detrend_obs_SD_time = detrended_obs.groupby('time.month').std('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bf11924-2d23-47c3-b16f-0bb6235c3e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the standard deviaton of anomalies when obs datasets are detrended by \n",
    "#the ensemble mean, and the members detrended by ensemble mean\n",
    "\n",
    "x_ = [0,0,0,1,1,1]\n",
    "y_ = [0,1,2,0,1,2]\n",
    "\n",
    "month_ = 3\n",
    "\n",
    "fig, axes = plt.subplots(2,3,figsize=[14,7])\n",
    "\n",
    "for model_i, model_name in enumerate(model_names):\n",
    "    for data_i, dataset in enumerate(list(obs_SIA.keys())):\n",
    "        axes[x_[model_i]][y_[model_i]].axvline(detrend_obs_SD_time[str(model_name)+'_'+str(dataset)].sel(month=month_), c=obs_colors[data_i], linestyle='--', linewidth=2, label=dataset)\n",
    "\n",
    "    axes[x_[model_i]][y_[model_i]].hist(all_model_detrend_ensemble[model_name].sel(time=all_model_detrend_ensemble['time.month']==month_).std('time'), \n",
    "                                        bins=np.arange(0.15,0.8,0.01), density=True, color='0.5', label=model_print_names[model_i]);\n",
    "\n",
    "    mean_mem = all_model_detrend_ensemble[model_name].sel(time=all_model_detrend_ensemble['time.month']==month_).std('time').mean()\n",
    "    SD_mem   = all_model_detrend_ensemble[model_name].sel(time=all_model_detrend_ensemble['time.month']==month_).std('time').std()\n",
    "\n",
    "    if x_[model_i] == 1:\n",
    "        axes[x_[model_i]][y_[model_i]].set_xlabel('Standard deviation of anomalies')\n",
    "    axes[x_[model_i]][y_[model_i]].set_ylabel('Normalized frequency')\n",
    "    axes[x_[model_i]][y_[model_i]].set_title(model_print_names[model_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5614e58-aa07-49ab-b359-a2aa5739a158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % difference plot of ens vers ind for observational datasets and models\n",
    "month_ = 9\n",
    "\n",
    "model_diffs = np.empty((6))\n",
    "for model_i, model_name in enumerate(model_names):\n",
    "    ind_SD = all_model_detrend_individual[model_name].sel(time=all_model_detrend_individual['time.month']==month_).std('time').mean('member')\n",
    "    ens_SD = all_model_detrend_ensemble[model_name].sel(time=all_model_detrend_ensemble['time.month']==month_).std('time').mean('member')\n",
    "    model_diffs[model_i] = ((ens_SD-ind_SD)/ind_SD)\n",
    "\n",
    "obs_diffs = np.empty((6,6))\n",
    "for data_i, dataset in enumerate(list(obs_SIA.keys())):\n",
    "    for model_i, model_name in enumerate(model_names):\n",
    "        ind_SD = obs_detrend_individual[dataset].sel(time=obs_detrend_individual['time.month']==month_).std('time')\n",
    "        ens_SD = detrend_obs_SD_time['{}_{}'.format(model_name, dataset)].sel(month=month_)\n",
    "        obs_diffs[data_i][model_i] = ((ens_SD-ind_SD)/ind_SD)\n",
    "\n",
    "\n",
    "for data_i, dataset in enumerate(list(obs_SIA.keys())):\n",
    "    plt.bar(np.arange(0,6)+(0.1*data_i), obs_diffs[data_i]*100, width=0.1, label=dataset)\n",
    "\n",
    "plt.bar(np.arange(0.6,6.6), model_diffs*100, width=0.1, label='CLIVAR', color='k')\n",
    "\n",
    "plt.bar(np.arange(6,6.61,0.1), np.append(np.mean(obs_diffs, axis=1), np.mean(model_diffs))*100, width=0.1, color=obs_colors)\n",
    "\n",
    "# plt.legend()\n",
    "plt.xticks(np.arange(0,7), np.append(model_print_names, 'Average'), rotation = 45)\n",
    "plt.ylabel('% Difference Ens - Ind')\n",
    "plt.xlabel('Model');\n",
    "plt.title(month_names[month_-1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebd5e98-42f8-4a47-bb10-d94320d51d2a",
   "metadata": {},
   "source": [
    "# Make plot of Jackknife anomalies for obs and ensemble anomalies for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d76d798-f984-4a45-84b7-2eaea5460bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine the number of elements to be deleted - 32 seems to fit best\n",
    "x_ = [0,0,0,1,1,1,2,2,2,3,3,3]\n",
    "y_ = [0,1,2,0,1,2,0,1,2,0,1,2]\n",
    "\n",
    "fig, axes = plt.subplots(4,3,figsize=[14,10])\n",
    "\n",
    "for i, month_ in enumerate(np.arange(1,13)):\n",
    "    for model_i, model_name in enumerate(model_names):\n",
    "        pdf_vals = PDF(all_coefs.sel(coef='gradient').sel(model=model_name))\n",
    "        axes[x_[i]][y_[i]].plot(pdf_vals[0], pdf_vals[1], color=colors[model_i])\n",
    "    \n",
    "    for data_ in ave_grad['dataset']:\n",
    "        pdf_vals = PDF(all_runs_grad.sel(dataset=data_).sel(month=month_))\n",
    "        axes[x_[i]][y_[i]].plot(pdf_vals[0], pdf_vals[1], color='r', alpha=0.5, linestyle='--')\n",
    "        \n",
    "    axes[x_[i]][y_[i]].set_ylim(bottom=0)\n",
    "    axes[x_[i]][y_[i]].set_xlim(-0.1, 0.01)    \n",
    "    axes[x_[i]][y_[i]].set_title(month_names[i])\n",
    "    \n",
    "    if x_[i] == 3:\n",
    "        axes[x_[i]][y_[i]].set_xlabel('Gradient')\n",
    "    if y_[i] == 0:\n",
    "        axes[x_[i]][y_[i]].set_ylabel('Normalized Frequency')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL-3.7.9",
   "language": "python",
   "name": "npl-3.7.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
