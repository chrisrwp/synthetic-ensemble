{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d10778ff-e06a-4529-a0f1-c1997d8e516c",
   "metadata": {},
   "source": [
    "# Filtering and resampling SIA data, observations and models\n",
    "\n",
    "### Author: Chris Wyburn-Powell, [github](https://github.com/chrisrwp/synthetic-ensemble/SIA/SIA_filtering_resampling.ipynb)\n",
    "\n",
    "**Input**: <br>\n",
    "- Models: Arctic SIA from six models of the CLIVAR Large Ensemble archive (CanESM2, CESM1, CSIRO MK3.6, GFDL CM3, GFDL ESM2M, MPI ESM1), as computed in [another notebook](https://github.com/chrisrwp/synthetic-ensemble/SIA/SIC_to_SIA_models.ipynb)\n",
    "- Observations: Arctic SIA from 4 observational datasets: Climate Data Record (CDR), NASA Bootstrap (BT), NASA Team (NT), and Hadley Centre Sea Ice (HadISST1), as computed in  [another notebook](https://github.com/chrisrwp/synthetic-ensemble/SIA/SIA_calculations_observations.ipynb)\n",
    "\n",
    "**Output**: <br>\n",
    "- Detrended SIA for models and observations using the individual datasets or member or the average observational dataset or ensemble mean\n",
    "- Resampled SIA 10,000 times wiht a 2 year bootstrap size\n",
    "- **$\\sigma_{LE}$**  : Standard deviations of detrended models without resampling\n",
    "- **$\\sigma_{mem}$** : Standard deviations of detrended resampled models\n",
    "- **$\\sigma_{obs}$** : Standard deivations of detrended resampled observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "978ec14b-2980-4b5d-a4db-1875b8be086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import xarray as xr\n",
    "import scipy.signal as signal \n",
    "import datetime\n",
    "import scipy.stats as stats\n",
    "import math as m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb66965-3bfa-41c0-959f-e105d418ffcd",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b13324f6-a3a1-4cc9-a08d-e22e2cd59452",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/glade/scratch/cwpowell/Synthetic_ensemble/'\n",
    "\n",
    "model_names  = ['CanESM2', 'CESM1', 'CSIRO_MK36', 'GFDL_CM3', 'GFDL_ESM2M', 'MPI_ESM1' ]\n",
    "mem_len      = [50,        40,      30,           20,         30,           100        ]\n",
    "model_starts = [1950,      1920,    1850,         1920,       1950,         1850       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea714060-a8be-4b94-aceb-c2eee9963a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load observational data\n",
    "CDR  = xr.open_dataset(data_path+'Raw_data/observations/NSIDC_CDR_v4/SIA_SIE_CDR_BT_NT_79-20_filled.nc')\n",
    "HadISST1 = xr.open_dataset(data_path+'Raw_data/observations/HadISST/HadISST1_SIA_SIE_79-20_filled.nc')\n",
    "\n",
    "obs_SIA = xr.Dataset({'CDR':CDR['CDR_SIA'].copy(), 'BT':CDR['BT_SIA'].copy(), \n",
    "                      'NT':CDR['NT_SIA'].copy(), 'HadISST1':HadISST1['SIA'].copy()})\n",
    "\n",
    "obs_SIA_keys = list(obs_SIA.keys())\n",
    "\n",
    "#load model data\n",
    "SIA = xr.open_dataset(data_path+'SIA/SIA_SIE_SIV/CLIVAR_SIA_1850_2100_RCP85.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caac9c07-084e-4a9e-8c1c-176178dd75b0",
   "metadata": {},
   "source": [
    "# Define functions for resampling and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18e2e828-d540-40e0-936d-7f7f360a60e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_boot1(time_period, data):\n",
    "    '''\n",
    "    Resample a 1D time series using a 2 year block boostrap size\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    time_period : integer,\n",
    "        For 1979-2020 use 42 as the total number of years in that time period\n",
    "    data : 1 dimensional xarray dataarray,\n",
    "        For 1979-2020 this is an array of shape [42] \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "        2D xarray dataarray object of 1000 resamplings of the input data, shape: (time_period, 1000)\n",
    "    ''' \n",
    "    \n",
    "    resampled = np.random.choice(data, (time_period, 1000), replace=True)\n",
    "    \n",
    "    return(resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36d331f3-c235-4fb3-80d1-a730e07fe74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_boot2(time_period, data, resamp_n):\n",
    "    '''\n",
    "    Resample a 1D time series using a 2 year block boostrap size with replacement\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    time_period : integer,\n",
    "        For 1979-2020 use 42 as the total number of years in that time period\n",
    "    data : 1 dimensional xarray dataarray,\n",
    "        For 1979-2020 this is an array of shape [42] \n",
    "    resamp_n: int\n",
    "        Number of resamplings\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "        2D xarray dataarray object of n resamplings of the input data, shape: (time_period, resamp_n)\n",
    "    '''  \n",
    "    #create an xarray dataarray of indexes for half the length of the time period, year_i coordinates 1,3,5...\n",
    "    boot_2_first_ind = xr.DataArray(data   = np.random.randint(0,time_period-2, (resamp_n,int(time_period/2))), \n",
    "                                    coords = {'resampling':np.arange(1,resamp_n+1,1), 'year_i':np.arange(1,time_period+1,2)},\n",
    "                                    dims   = ['resampling', 'year_i'])\n",
    "\n",
    "    #create an identical dataarray but with each element incremented by 1, year_i coordinates 2,4,6....\n",
    "    boot_2_second_ind = (boot_2_first_ind+1).copy()\n",
    "    boot_2_second_ind['year_i'] = np.arange(2,time_period+2,2)\n",
    "\n",
    "    #concatenate the two arrays with the coordinates in order, this allows a 2 year block boostrap size\n",
    "    all_boot_2_ind = xr.concat((boot_2_first_ind, boot_2_second_ind), dim='year_i').sortby('year_i')\n",
    "    \n",
    "    #create an array with the starting element of the flattened array for each resampling 0, 42, 84...\n",
    "    ind_base = np.repeat(np.arange(0,time_period*resamp_n,time_period),time_period)\n",
    "    \n",
    "    #add together the base indexes (0,42,84...) with the randomly chosen indexes within the original data\n",
    "    ind_1_d = np.ravel(all_boot_2_ind) + ind_base\n",
    "    \n",
    "    #copy the original data 1000 times as a 1D array so it will have the same indexes as we just made for ind_1_d\n",
    "    data_1000 = np.ravel(np.tile(data,(time_period,resamp_n)))\n",
    "    \n",
    "    #select the randomly generated indexes from the flattened copied original data, reshape and save to xarray dataarray\n",
    "    resampled_boot_2 = xr.DataArray(data = np.reshape(data_1000[ind_1_d], (resamp_n, time_period)),\n",
    "                                    coords = {'resampling':np.arange(1,resamp_n+1,1), 'year_i':np.arange(1,time_period+1,1)},\n",
    "                                    dims   = ['resampling', 'year_i'])\n",
    "\n",
    "    return(resampled_boot_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "893c762d-2284-4f2d-a26c-fe76726319c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filt_lowpass(data, sample_freq, cutoff, order):\n",
    "    '''\n",
    "    Filter a 1D time series using a lowpass Butterworth filter. \n",
    "    Uses scipy.signal.butter and scipy.signal.filtfilt\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : 1 dimensional xarray dataarray,\n",
    "        For 1979-2020 this is an array of shape [42] \n",
    "    sample_freq: float,\n",
    "        The sampling frequency of the input data, typically sample_freq=1 [year]\n",
    "    cutoff: float,     \n",
    "        The fraction of the nyquist frequency. To filter with a 2-year lowpass filter with sample_freq=1, cutoff=0.25\n",
    "    order: int\n",
    "        The order of the Butterworth filter, typically 4-6\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "        1D numpy array of the same shape as the input data\n",
    "    '''  \n",
    "    \n",
    "    nyquist = sample_freq / 2 # 0.5 times the sampling frequency\n",
    "    b, a = signal.butter(order, cutoff, btype='lowpass') #low pass filter\n",
    "    filtered = signal.filtfilt(b, a, data) #apply the filter forward and backward\n",
    "    \n",
    "    return(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00162c74-fb4e-4c83-a598-2ed1a0c6f364",
   "metadata": {},
   "source": [
    "# Filter\n",
    "## Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99c6779c-f74e-4095-80c8-9b621c7f9157",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_filt_2yr = {}\n",
    "for key in obs_SIA_keys:  \n",
    "    all_month_filtered = []\n",
    "    for month_ in np.arange(1,13):\n",
    "        filt_2_yr = filt_lowpass(data=obs_SIA[key].sel(time=obs_SIA['time.month']==month_), \n",
    "                                 sample_freq=1, cutoff=0.25, order=5)\n",
    "\n",
    "        all_month_filtered.append(obs_SIA[key].sel(time=obs_SIA['time.month']==month_) - filt_2_yr)\n",
    "\n",
    "\n",
    "    obs_filt_2yr[key] = (xr.concat((all_month_filtered), dim='time'))\n",
    "obs_filt_2yr = xr.Dataset(obs_filt_2yr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f64e7e-06d1-4885-9cd0-9522976045eb",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a4194f8-2217-4967-a621-6bc1fa81e963",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_yr = 1979\n",
    "end_yr   = 2020\n",
    "\n",
    "all_model_filt_2yr = {}\n",
    "\n",
    "for model_i, model_name in enumerate(model_names):\n",
    "    \n",
    "    filt_2yr_list = []\n",
    "    \n",
    "    for month_ in np.arange(1,13):\n",
    "        \n",
    "        if model_name == 'MPI_ESM1': #100 elements in member dimension so can't select all of those for MPI ESM1\n",
    "            model_month = SIA[model_name].sel(time=SIA['time.month']==month_).sel(time=slice(str(start_yr),str(end_yr)))\n",
    "        else:\n",
    "            model_month = SIA[model_name].sel(time=SIA['time.month']==month_).sel(time=slice(str(start_yr),str(end_yr))).sel(member=slice('1',str(mem_len[model_i])))\n",
    "        \n",
    "        #filter all members by the ensemble mean trend\n",
    "        filt_2_yr_month = filt_lowpass(data=model_month, sample_freq=1, cutoff=0.25, order=5)\n",
    "\n",
    "        #detrend the individual members with the filtered time series\n",
    "        filt_2yr_list.append(model_month - filt_2_yr_month)\n",
    "        \n",
    "    all_model_filt_2yr[model_name] = xr.concat((filt_2yr_list), dim='time')\n",
    "    \n",
    "all_model_filt_2yr = xr.Dataset(all_model_filt_2yr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe0a056-2235-4305-8aa8-a2391cdaafe2",
   "metadata": {},
   "source": [
    "## Resample all detrended observational data sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1abb3ad5-e3ed-4814-9615-04025ceab6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the resamplings of all observational datasets and months\n",
    "#to change the bootstrap size, change the function names: [resample_boot2, resample_boot1]\n",
    "\n",
    "obs_resample_filt_2yr = {}\n",
    "\n",
    "for key in obs_SIA_keys:   \n",
    "\n",
    "    resampled_month = []\n",
    "\n",
    "    for month_ in np.arange(1,13):\n",
    "        resampled_month.append(resample_boot2(42, obs_filt_2yr[key].sel(time=obs_filt_2yr['time.month']==month_), 10000))\n",
    "\n",
    "\n",
    "    obs_resample_filt_2yr[key] = xr.concat((resampled_month), dim='month')\n",
    "\n",
    "\n",
    "obs_resample_filt_2yr = xr.Dataset(obs_resample_filt_2yr)\n",
    "obs_resample_filt_2yr['month'] = np.arange(1,13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceae6360-bcbc-45db-b21d-95fe0f32a055",
   "metadata": {},
   "source": [
    "## Resampling all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "84019c7b-bf9a-4cd0-9a63-261299980c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-16 15:59:38.032553 CanESM2\n",
      "2022-03-16 16:00:15.607590 CESM1\n",
      "2022-03-16 16:00:45.177528 CSIRO_MK36\n",
      "2022-03-16 16:01:07.482627 GFDL_CM3\n",
      "2022-03-16 16:01:22.427990 GFDL_ESM2M\n",
      "2022-03-16 16:01:44.811492 MPI_ESM1\n"
     ]
    }
   ],
   "source": [
    "mem_resample_filt_2yr = {}\n",
    "\n",
    "for model_i, model_name in enumerate(model_names):\n",
    "    print(datetime.datetime.now(), model_name)\n",
    "    \n",
    "    resampled_month = []\n",
    "    for month_ in np.arange(1,13):\n",
    "        \n",
    "        resampled_month_model = []\n",
    "        for member_ in np.arange(1,mem_len[model_i]+1):\n",
    "            resampled_month_model.append(resample_boot2(42, all_model_filt_2yr[model_name].sel(time=all_model_filt_2yr['time.month']==month_).sel(member=member_), 10000))\n",
    "        \n",
    "        resampled_month.append(xr.concat((resampled_month_model),dim='member').std('year_i')) \n",
    "\n",
    "    mem_resample_filt_2yr[model_name] = xr.concat((resampled_month), dim='month')\n",
    "    mem_resample_filt_2yr[model_name]['member'] = np.arange(1,mem_len[model_i]+1)\n",
    "\n",
    "mem_resample_filt_2yr = xr.Dataset(mem_resample_filt_2yr)\n",
    "mem_resample_filt_2yr['month'] = np.arange(1,13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07646c51-bc01-4898-8639-8a267d1bd7e3",
   "metadata": {},
   "source": [
    "### Compute $\\sigma$ and $\\mu$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3e182062-f6c9-4f97-b7ba-86a6f60bd726",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_obs_10000 = obs_resample_filt_2yr.std('year_i').std('resampling')\n",
    "mu_obs_10000    = obs_resample_filt_2yr.std('year_i').mean('resampling')\n",
    "\n",
    "sigma_mem_10000 = mem_resample_filt_2yr.std('resampling')\n",
    "mu_mem_10000    = mem_resample_filt_2yr.mean('resampling')\n",
    "\n",
    "sigma_LE_10000 = all_model_filt_2yr.groupby('time.month').std('time').std('member')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8973003-1768-478e-8026-bbffb7171cfa",
   "metadata": {},
   "source": [
    "### Save $\\sigma$ and $\\mu$ calculations to NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cd56e92a-9110-491a-9b97-03bd5451c406",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_mem_10000.attrs = {'Description': 'Resampled Arctic sea ice area (SIA) for the large ensemble models: CanESM2, CESM1, CSIRO MK3.6, GFDL CM3, GFDL ESM2M, MPI ESM1, 1979-2020. Standard deviation across resampling year and across resampling. Detrended by a Butterworth lowpass filter with a 2 year cutoff. Resampling is done 10000 times with a 2 year bootstrap size.', \n",
    "                         'Units'      : 'million square km',\n",
    "                         'Timestamp'  : str(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\")),\n",
    "                         'Data source': 'CLIVAR Large Ensemble Archive, doi:10.1038/s41558-020-0731-2',\n",
    "                         'Analysis'   : 'https://github.com/chrisrwp/synthetic-ensemble/SIA/SIA_filtering_resampling.ipynb'}\n",
    "\n",
    "sigma_mem_10000.to_netcdf('/glade/scratch/cwpowell/Synthetic_ensemble_revisions/SIA/SIA_resampled/Sigma_mem_2yr_filter_10000.nc')\n",
    "\n",
    "\n",
    "mu_mem_10000.attrs = {'Description': 'Resampled Arctic sea ice area (SIA) for the large ensemble models: CanESM2, CESM1, CSIRO MK3.6, GFDL CM3, GFDL ESM2M, MPI ESM1, 1979-2020. Standard deviation across resampling year and mean of resamplings. Detrended by a Butterworth lowpass filter with a 2 year cutoff. Resampling is done 10000 times with a 2 year bootstrap size.', \n",
    "                      'Units'      : 'million square km',\n",
    "                      'Timestamp'  : str(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\")),\n",
    "                      'Data source': 'CLIVAR Large Ensemble Archive, doi:10.1038/s41558-020-0731-2',\n",
    "                      'Analysis'   : 'https://github.com/chrisrwp/synthetic-ensemble/SIA/SIA_filtering_resampling.ipynb'}\n",
    "\n",
    "mu_mem_10000.to_netcdf('/glade/scratch/cwpowell/Synthetic_ensemble_revisions/SIA/SIA_resampled/Mu_mem_2yr_filter_10000.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a738a2ea-4e73-4316-983a-343a57cabf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_obs_10000.attrs = {'Description': 'Resampled Arctic sea ice area (SIA) for the four observational datasets: Climate Data Record (CDR), NASA Bootstrap (BT), NASA Team (NT), Hadley Centre Sea Ice (HadISST1), years 1979-2020. Standard deviation across resampling year and across resampling. Detrended by a Butterworth lowpass filter with a 2 year cutoff. Resampling is done 10000 times with a 2 year bootstrap size.', \n",
    "                         'Units'      : 'million square km',\n",
    "                         'Timestamp'  : str(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\")),\n",
    "                         'Data source': 'DOIs - CDR, BT, NT:10.7265/efmz-2t65, HadISST1:10.1029/2002JD002670',\n",
    "                         'Analysis'   : 'https://github.com/chrisrwp/synthetic-ensemble/SIA/SIA_filtering_resampling.ipynb'}\n",
    "\n",
    "sigma_obs_10000.to_netcdf('/glade/scratch/cwpowell/Synthetic_ensemble_revisions/SIA/SIA_resampled/Sigma_obs_2yr_filter_10000.nc')\n",
    "\n",
    "\n",
    "mu_obs_10000.attrs = {'Description': 'Resampled Arctic sea ice area (SIA) for the four observational datasets: Climate Data Record (CDR), NASA Bootstrap (BT), NASA Team (NT), Hadley Centre Sea Ice (HadISST1), years 1979-2020. Standard deviation across resampling year and mean of resamplings. Detrended by a Butterworth lowpass filter with a 2 year cutoff. Resampling is done 10000 times with a 2 year bootstrap size.', \n",
    "                      'Units'      : 'million square km',\n",
    "                      'Timestamp'  : str(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\")),\n",
    "                      'Data source': 'DOIs - CDR, BT, NT:10.7265/efmz-2t65, HadISST1:10.1029/2002JD002670',\n",
    "                      'Analysis'   : 'https://github.com/chrisrwp/synthetic-ensemble/SIA/SIA_filtering_resampling.ipynb'}\n",
    "\n",
    "mu_obs_10000.to_netcdf('/glade/scratch/cwpowell/Synthetic_ensemble_revisions/SIA/SIA_resampled/Mu_obs_2yr_filter_10000.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0a7e775c-5b13-49b5-bfc2-45ac90b48f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_LE_10000.attrs = {'Description': 'Variability of Arctic sea ice area (SIA) for the four the large ensemble models: CanESM2, CESM1, CSIRO MK3.6, GFDL CM3, GFDL ESM2M, MPI ESM1, 1979-2020. Standard deviation with respect members. Computed on the detrended standard deviations with respect to time for each month, then the standard deviation across members is taken. Detrended by a Butterworth lowpass filter with a 2 year cutoff.', \n",
    "                        'Units'      : 'million square km',\n",
    "                        'Timestamp'  : str(datetime.datetime.utcnow().strftime(\"%H:%M UTC %a %Y-%m-%d\")),\n",
    "                        'Data source': 'CLIVAR Large Ensemble Archive, doi:10.1038/s41558-020-0731-20',\n",
    "                        'Analysis'   : 'https://github.com/chrisrwp/synthetic-ensemble/SIA/SIA_filtering_resampling.ipynb'}\n",
    "\n",
    "sigma_LE_10000.to_netcdf('/glade/scratch/cwpowell/Synthetic_ensemble_revisions/SIA/SIA_resampled/Sigma_LE_2yr_filter_10000.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0d822a-dd64-4fd3-8c02-9c184e7b7743",
   "metadata": {},
   "source": [
    "### Load data made from linear detrened resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12983028-b3cd-4bf9-92ed-e5e81212175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_LE_individual = xr.open_dataset(data_path+'SIA/SIA_resampled/Sigma_LE_individual_79-20.nc')\n",
    "sigma_mem_individual = xr.open_dataset(data_path+'SIA/SIA_resampled/Sigma_mem_individual_10000.nc')\n",
    "sigma_obs_individual = xr.open_dataset(data_path+'SIA/SIA_resampled/Sigma_obs_individual_10000.nc')\n",
    "\n",
    "mu_mem_individual = xr.open_dataset(data_path+'SIA/SIA_resampled/Mu_mem_individual_10000.nc')\n",
    "mu_obs_individual = xr.open_dataset(data_path+'SIA/SIA_resampled/Mu_obs_individual_10000.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e601978-ee10-41a1-9342-4b45d52572f1",
   "metadata": {},
   "source": [
    "# Remake Figure 10 and mem/obs ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "98dee7c4-3f41-4d40-bd28-dc9ff4e2f683",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot sigma ratios with median and interquartile ranges - Figure 10\n",
    "LE_mem = 1\n",
    "\n",
    "upper_quart = np.array(member_numbers)*0.75\n",
    "lower_quart = np.array(member_numbers)*0.25\n",
    "\n",
    "sig_LE  = sigma_LE_individual.copy()\n",
    "sig_mem = sigma_mem_individual.copy()\n",
    "sig_obs = sigma_obs_individual.copy()\n",
    "\n",
    "for obs_dataset in list(sigma_obs_10000.keys()):    \n",
    "\n",
    "    fig = plt.figure(figsize=[11.5,7])\n",
    "    plt.axhline(1, c='0.5', linewidth=2)\n",
    "\n",
    "    for model_i, model_name in enumerate(model_names):\n",
    "\n",
    "        #define the upper and lower quarties of sigma_mem members\n",
    "        upper = sig_mem[model_name].where(sig_mem[model_name].rank('member')==m.floor(upper_quart[model_i])).max('member')\n",
    "        lower = sig_mem[model_name].where(sig_mem[model_name].rank('member')==m.ceil(lower_quart[model_i])).max('member')\n",
    "\n",
    "        if LE_mem == 1: #plot LE/mem\n",
    "            plt.plot(month_names_short, sig_mem[model_name].median('member')/sig_LE[model_name], \n",
    "                     c=colors[model_i], linewidth=2.5, marker='o', markersize=6)\n",
    "\n",
    "            plt.fill_between(month_names_short, upper/sig_LE[model_name], \n",
    "                             lower/sig_LE[model_name], color=colors[model_i], alpha=0.1)\n",
    "\n",
    "        else: #plot mem/obs\n",
    "            plt.plot(month_names_short, sig_mem[model_name].median('member')/sig_obs[obs_dataset].values, \n",
    "                     c=colors[model_i], linewidth=2, marker='o')\n",
    "\n",
    "            plt.fill_between(month_names_short, lower/sig_obs[obs_dataset].values, \n",
    "                             upper/sig_obs[obs_dataset].values, color=colors[model_i], alpha=0.1)\n",
    "\n",
    "    #########################################################################\n",
    "\n",
    "    plt.xticks(np.arange(0,12,1))\n",
    "    plt.grid()\n",
    "    plt.xlim(0,11)\n",
    "    if LE_mem == 1:\n",
    "        plt.ylim(0.41,1.15) #0.4,1.2 for interquartile range\n",
    "    else:\n",
    "        plt.ylim(0.3,2.4) #0.3, 2.6 for interquartile range\n",
    "    plt.xlabel('Month', fontsize=18)\n",
    "    if LE_mem == 1:\n",
    "        plt.ylabel('Resampled member relative to'+'\\n'+r'Large Ensemble ($\\bar{\\sigma}_{mem} \\ / \\ \\sigma_{LE}$)', fontsize=18)\n",
    "    else:\n",
    "        plt.ylabel('Model relative to observations', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "\n",
    "    legend_elements = [Patch(facecolor=colors[0], label='CanESM2'),\n",
    "                       Patch(facecolor=colors[1], label='CESM1'),\n",
    "                       Patch(facecolor=colors[2], label='CSIRO MK36'),\n",
    "                       Patch(facecolor=colors[3], label='GFDL CM3'),\n",
    "                       Patch(facecolor=colors[4], label='GFDL ESM2M'),\n",
    "                       Patch(facecolor=colors[5], label='MPI ESM1'),]\n",
    "\n",
    "    extra_legend = plt.legend(handles=legend_elements, bbox_to_anchor=(0.5, -0.24), loc='lower center', borderaxespad=-0.25, ncol=3, fontsize=14)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # if LE_mem == 1:\n",
    "    #     fig.savefig(data_path+'SIA/figures/Resampled_figures/Ratio_LE_mem_medians_iq_range_{}.png'.format(ind_ens), \n",
    "    #                 bbox_inches='tight', dpi=400)\n",
    "    #     fig.savefig(data_path+'SIA/figures/Resampled_figures/Ratio_LE_mem_medians_iq_range_{}.pdf'.format(ind_ens), bbox_inches='tight')\n",
    "    # else:\n",
    "    #     fig.savefig(data_path+'SIA/figures/Resampled_figures/Ratio_mem_obs_{}_medians_iq_range_{}.png'.format(obs_dataset, ind_ens), dpi=400)\n",
    "#     plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06960d47-7f89-4ada-bbbe-4f9d078bdfba",
   "metadata": {},
   "source": [
    "## Compare $\\sigma_{obs}$ and $\\sigma_{mem}$ from detrending and filtering - Figure 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "feb3224d-af94-49d0-b74a-da4e9ed6faa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "month_names_short = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "colors = ['m',     'b',   'g',        'orange',  'k',        'tab:olive' ]\n",
    "member_numbers      = [50,        40,      30,           20,         30,           100        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "49b61833-471c-41c4-9649-563c30aea4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_mu = 'mu'\n",
    "\n",
    "if sigma_mu == 'sigma':\n",
    "    mem = sigma_mem_individual.copy()\n",
    "    obs = sigma_obs_individual.to_array().sel(variable=['CDR','BT','NT','HadISST1'])\n",
    "else:\n",
    "    mem = mu_mem_individual.copy()\n",
    "    obs = mu_obs_individual.to_array().sel(variable=['CDR','BT','NT','HadISST1'])\n",
    "    \n",
    "fig = plt.figure(figsize=[14,6])\n",
    "\n",
    "for model_i, model_name in enumerate(model_names):\n",
    "    boxplot_model = np.empty((member_numbers[model_i],12))\n",
    "    \n",
    "    for memb_i, memb in enumerate(np.arange(1,member_numbers[model_i]+1)):    \n",
    "        boxplot_model[memb_i] = mem[model_name].sel(member=memb).values\n",
    "    \n",
    "    b_plot = plt.boxplot(boxplot_model, widths=0.07, positions=np.arange(0.735+model_i*0.1,12.735+model_i*0.1,1), \n",
    "                         whis=(0,100), labels=month_names_short, patch_artist=True);\n",
    "    \n",
    "    #set the colors\n",
    "    for patch in b_plot['boxes']: \n",
    "        patch.set_facecolor(colors[model_i]) \n",
    "    \n",
    "    for element in ['boxes', 'whiskers', 'fliers', 'means', 'medians', 'caps']:\n",
    "        plt.setp(b_plot[element], color=colors[model_i], linewidth=1.5)\n",
    "        \n",
    "    plt.setp(b_plot['medians'], color='0.8', linewidth=2)\n",
    "    \n",
    "marker_list = ['o',8,9,'d','s']\n",
    "for var_i in range(4):\n",
    "    for month_ in np.arange(1,13):\n",
    "        plt.plot([-0.35+month_, 0.35+month_], [obs.isel(variable=var_i).sel(month=month_), obs.isel(variable=var_i).sel(month=month_)], c='r', alpha=1, zorder=9)\n",
    "#     plt.scatter(np.arange(0.6,12.6), obs.isel(variable=var_i), c='r', marker=marker_list[var_i])\n",
    "\n",
    "legend_elements = [Patch(facecolor=colors[0], label='CanESM2'),\n",
    "                   Patch(facecolor=colors[1], label='CESM1'),\n",
    "                   Patch(facecolor=colors[2], label='CSIRO MK3.6'),\n",
    "                   Patch(facecolor=colors[3], label='GFDL CM3'),\n",
    "                   Patch(facecolor=colors[4], label='GFDL ESM2M'),\n",
    "                   Patch(facecolor=colors[5], label='MPI ESM1'),\n",
    "                   Patch(facecolor='r', label='Observations')]\n",
    "\n",
    "extra_legend = plt.legend(handles=legend_elements, bbox_to_anchor=(0.01, 0.97), loc='upper left', borderaxespad=0, ncol=2, fontsize=14)\n",
    "plt.gca().add_artist(extra_legend);\n",
    "    \n",
    "plt.xticks(np.arange(1,13), fontsize=16)\n",
    "plt.xlabel('Month', fontsize=18)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "if sigma_mu == 'sigma':\n",
    "    plt.ylim(0.01,0.142) #for sigma\n",
    "    plt.ylabel(r'$\\bar{\\sigma}_{mem} \\ or \\ \\sigma_{obs} \\ \\ [10^6 \\ km^2]$', fontsize=18);\n",
    "else:\n",
    "    plt.ylim(0.1,0.85) #for mu\n",
    "    plt.ylabel(r'$\\bar{\\mu}_{mem} \\ or \\ \\mu_{obs} \\ \\ [10^6 \\ km^2]$', fontsize=18);\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL-3.7.9",
   "language": "python",
   "name": "npl-3.7.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
